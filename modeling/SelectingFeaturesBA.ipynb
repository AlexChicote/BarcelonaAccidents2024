{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest,f_classif,chi2, mutual_info_classif, VarianceThreshold, RFE, SelectFromModel\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier#, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import python_files.functions_barcelona_Correlations as fb3\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 15, 53, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents=pd.read_csv('./data/accidents_weather_eng_2023.csv')\n",
    "def creating_target(row):\n",
    "    return 1 if row['num_deaths']+row['num_severly_injured']>0 else 0\n",
    "accidents['target']=accidents.apply(creating_target,axis=1)\n",
    "\n",
    "\n",
    "cat_columns=[]\n",
    "num_columns=[]\n",
    "to_drop=['index','num_incident', 'num_severly_injured','num_deaths',\\\n",
    "         'num_minorly_injured','num_victims','street_code', 'dates','datetimes','utm_x','utm_y','district_code']\n",
    "for col in accidents:\n",
    "    if 'Unnamed' in col:\n",
    "        accidents=accidents.drop(col,axis=1)\n",
    "for col in accidents.columns:\n",
    "    if col in to_drop:\n",
    "        accidents=accidents.drop(col,axis=1)\n",
    "    elif 'bins' in col:\n",
    "        cat_columns.append(col)\n",
    "    elif ('vehicle_' in col): \n",
    "        cat_columns.append(col)\n",
    "    elif 'seniority' in col:\n",
    "        num_columns.append(col)\n",
    "    elif 'license' in col:\n",
    "        pass #license is discarded due to the fact that the information it provides is already \n",
    "        # contained in vehicles\n",
    "    elif col =='target':\n",
    "        pass\n",
    "    elif 'num' in col or '_count' in col:\n",
    "        num_columns.append(col)\n",
    "    elif accidents[col].nunique()<76:\n",
    "        cat_columns.append(col)\n",
    "    elif accidents[col].dtypes==float:\n",
    "        num_columns.append(col)\n",
    "len(cat_columns),len(num_columns),len(accidents.columns),len(accidents.columns)-len(cat_columns)-len(num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "street_name object 9312\n",
      "license object 1506\n",
      "datetime object 67652\n",
      "target int64 2\n"
     ]
    }
   ],
   "source": [
    "pending=[x for x in accidents.columns if x not in cat_columns+num_columns]\n",
    "for col in pending:\n",
    "    print(col,accidents[col].dtypes, accidents[col].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='start'></a>\n",
    "\n",
    "# Selecting Features:\n",
    "1. [**Numerical Features**.](#num_fea)\n",
    "    - [FILTER: Variance Threashold.](#num_vt) Univariate features are eliminated\n",
    "    - [FILTER: ANOVA](#anova)\n",
    "    - [FILTER: Pearson, Kendall, Spearman Correlation.](#num_corr)\n",
    "    - [FILTER: Information Gain.](#inf_gain)\n",
    "    - [WRAPPER: Recursive Feature Elimination.](#num_rfe)\n",
    "    - [EMBEDDED: RandomForestClassifier](#num_rf)\n",
    "    - [EMBEDDED: Lasso.](#num_lasso)\n",
    "3. [**Categorical Features**.](#cat_fea)\n",
    "    - [FILTER: Variance Threashold.](#cat_vt)\n",
    "    - [FILTER: Chi Square and Mutual Information](#chi_sq)\n",
    "    - [FILTER: Cramer's V, Theil's U Correlation.](#cat_corr)\n",
    "    - [FILTER: Mutual Information/Information Gain.](#mut_info)\n",
    "    - [WRAPPER: Recursive Feature Elimination.](#cat_rfe)\n",
    "    - [EMBEDDED: RandomForestClassifier](#cat_rf)\n",
    "    - [EMBEDDED: Lasso.](#cat_lasso)\n",
    "5. Analysis Selected Features. In the case of the num_features, it looks like if the method used is based on eliminating features or it is a filter method we end up choosing the same 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='num_fea'></a>\n",
    "1. **Numerical Features**.\n",
    "\n",
    "[back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_avg 1.0 temp_min\n",
      "temp_max 1.0 temp_avg\n",
      "windspeed 0.87 max_windspeed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['num_vehicles',\n",
       " 'age_driver',\n",
       " 'license_seniority',\n",
       " 'temp_max',\n",
       " 'relative_humidity',\n",
       " 'precipitation',\n",
       " 'windspeed',\n",
       " 'wind_direction',\n",
       " 'pressure',\n",
       " 'solar_radiation',\n",
       " 'street_name_count',\n",
       " 'neighborhood_count']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations= abs(accidents[num_columns].corr())\n",
    "correlations=correlations.replace(1,0)\n",
    "for col in num_columns:\n",
    "    #print(correlations[col])\n",
    "    if correlations[col].max()>0.8:\n",
    "        print(col, round(correlations[col].max(),2),correlations[col].sort_values(ascending=False).index[0])\n",
    "        num_columns.remove(correlations[col].sort_values(ascending=False).index[0])\n",
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_avg 1.0 temp_min\n",
      "temp_max 1.0 temp_avg\n",
      "temp_min 1.0 temp_avg\n",
      "windspeed 0.87 max_windspeed\n",
      "max_windspeed 0.87 windspeed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['num_vehicles',\n",
       " 'age_driver',\n",
       " 'license_seniority',\n",
       " 'temp_avg',\n",
       " 'relative_humidity',\n",
       " 'precipitation',\n",
       " 'windspeed',\n",
       " 'wind_direction',\n",
       " 'pressure',\n",
       " 'solar_radiation',\n",
       " 'street_name_count',\n",
       " 'neighborhood_count']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations= abs(accidents[num_columns].corr())\n",
    "correlations=correlations.replace(1,0)\n",
    "for col in num_columns:\n",
    "    #print(correlations[col])\n",
    "    if correlations[col].max()>0.8:\n",
    "        print(col, round(correlations[col].max(),2),correlations[col].sort_values(ascending=False).index[0])\n",
    "#They are strongly correlated therefore I eliminate temp_min,temp_max and max_windspeed\n",
    "to_remove=['temp_min','temp_max','max_windspeed']\n",
    "for col in to_remove:\n",
    "    if col in num_columns:\n",
    "        num_columns.remove(col)\n",
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To avoid further problems when using ordinal encoder. I decided to go to a classic train_test split\n",
    "X_train_num, X_test_num, y_train, y_test=train_test_split(accidents[num_columns],accidents.target,test_size=0.1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='num_vt'></a>\n",
    "1. **Numerical Features**.\n",
    "    - FILTER: Variance Threashold.\n",
    "   \n",
    "[back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt=VarianceThreshold()\n",
    "vt.fit(X_train_num)\n",
    "[num_columns[col[0]] for col in enumerate(vt.get_support()) if  not col[1]]\n",
    " ##=======>>No changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anova'></a>\n",
    "1. **Numerical Features**.\n",
    "    - FILTER: ANOVA.\n",
    "   \n",
    "[back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numerical_chosen=[]\n",
    "def select_features(X_train, y_train, X_test,score_func=f_classif):\n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func=score_func, k='all')\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    " \n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train_num, y_train, X_test_num)\n",
    "# what are scores for the features\n",
    "sorted_columns=sorted([x for x in zip(num_columns,fs.scores_)], key=lambda x: x[1],reverse=True)\n",
    "anova_sel=[col[0] for col in sorted_columns[:5]]\n",
    "numerical_chosen.extend(anova_sel)\n",
    "# for i in range(len(sorted_columns)):\n",
    "#     print(f'Feature {sorted_columns[i][0]}:{sorted_columns[i][1]}')\n",
    "# plot the scores\n",
    "cols=[a for a,b in sorted_columns]\n",
    "scores=[b for a,b in sorted_columns]\n",
    "plt.barh(cols[::-1], scores[::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='num_corr'></a>\n",
    "1. **Numerical Features**.\n",
    "    - FILTER: Pearson, Kendall and Spearman Correlations.\n",
    "   \n",
    "[back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Selection:  \n",
      " ['num_vehicles', 'age_driver', 'solar_radiation']\n",
      "Kendall Selection:  \n",
      " ['num_vehicles', 'solar_radiation', 'age_driver']\n",
      "Spearman Selection:  \n",
      " ['num_vehicles', 'solar_radiation', 'age_driver']\n"
     ]
    }
   ],
   "source": [
    "pearson_sel=list(abs(accidents[num_columns +['target']].corr()['target']).sort_values(ascending=False)[1:4].index)\n",
    "print('Pearson Selection: ','\\n',pearson_sel)\n",
    "numerical_chosen.extend(pearson_sel)\n",
    "kendall_sel=list(abs(accidents[num_columns +['target']].corr(method='kendall')['target']).sort_values(ascending=False)[1:4].index)\n",
    "numerical_chosen.extend(kendall_sel)\n",
    "print('Kendall Selection: ','\\n',kendall_sel)\n",
    "spearman_sel=list(abs(accidents[num_columns +['target']].corr(method='spearman')['target']).sort_values(ascending=False)[1:4].index)\n",
    "numerical_chosen.extend(spearman_sel)\n",
    "print('Spearman Selection: ','\\n',spearman_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='inf_gain'></a>\n",
    "1. **Numerical Features**.\n",
    "    - FILTER: Information Gain.\n",
    "   \n",
    "[back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['num_vehicles', 'neighborhood_count', 'age_driver']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances=mutual_info_classif(X_train_num, y_train)\n",
    "info_gain_sel=list(pd.DataFrame(importances,columns=['InformationGain'],index=num_columns).sort_values('InformationGain',ascending=False).index[:3])\n",
    "numerical_chosen.extend(info_gain_sel)\n",
    "info_gain_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='num_rfe'></a>\n",
    "1. **Numerical Features**.\n",
    "    - WRAPPER: Recursive Feature Elimination.\n",
    "   \n",
    "[back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three Selected by RFE:  \n",
      " ['num_vehicles', 'age_driver', 'solar_radiation']\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression()\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train_num)\n",
    "X_test_minmax=min_max_scaler.transform(X_test_num)\n",
    "for n_cols in range(1,X_train_num.shape[1]):\n",
    "\n",
    "    rfe=RFE(lr,n_features_to_select=n_cols)\n",
    "    rfe.fit(X_train_minmax,y_train)\n",
    "    #print([num_columns[x[0]] for x in enumerate(rfe.ranking_) if x[1]==1])\n",
    "rfe=RFE(lr,n_features_to_select=3)\n",
    "rfe.fit(X_train_minmax,y_train)\n",
    "rfe_sel=[num_columns[x[0]] for x in enumerate(rfe.ranking_) if x[1]==1]\n",
    "numerical_chosen.extend(rfe_sel)\n",
    "print('Three Selected by RFE: ','\\n', rfe_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='num_rf'></a>\n",
    "1. **Numerical Features**.\n",
    "    - EMBEDDED: Random Forest Classifier.\n",
    "   \n",
    "[back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three Selected by RandomForest:  \n",
      " ['num_vehicles', 'street_name_count', 'precipitation']\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=100, random_state=2024)\n",
    "rf.fit(X_train_num,y_train)\n",
    "rf_sel=sorted([x[0] for x in zip(num_columns,rf.feature_importances_)],key=lambda x:x[1],reverse=True)[:3]\n",
    "numerical_chosen.extend(rf_sel)\n",
    "print('Three Selected by RandomForest: ','\\n', rf_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='num_lasso'></a>\n",
    "1. **Numerical Features**.\n",
    "    - EMBEDDED: Lasso.\n",
    "   \n",
    "[back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "6\n",
      "0.0007000000000000001\n",
      "6\n",
      "0.0004000000000000001\n",
      "6\n",
      "0.0001\n",
      "3\n",
      "YEAH\n",
      "3 \n",
      " ['pressure', 'solar_radiation', 'street_name_count']\n",
      "Three Selected by Lasso:  \n",
      " ['pressure', 'solar_radiation', 'street_name_count']\n"
     ]
    }
   ],
   "source": [
    "# Lasso\n",
    "for c in np.linspace(0.001,0.0001,4):\n",
    "    print(c)\n",
    "    lr=LogisticRegression(C=c,penalty='l1',solver='liblinear').fit(X_train_num,y_train)\n",
    "    selector = SelectFromModel(estimator=lr,prefit=True)\n",
    "    num_features=len([x[0] for x in zip(num_columns,selector.get_support()) if x[1]])\n",
    "    print(num_features)\n",
    "    # if num_features == 6:\n",
    "    #     print(num_features,'\\n',[x[0] for x in zip(num_columns,selector.get_support()) if x[1]])\n",
    "    if num_features <=3:\n",
    "        print('YEAH')\n",
    "        print(num_features,'\\n',[x[0] for x in zip(num_columns,selector.get_support()) if x[1]])\n",
    "        lasso_sel=[x[0] for x in zip(num_columns,selector.get_support()) if x[1]]\n",
    "        break\n",
    "numerical_chosen.extend(lasso_sel)\n",
    "print('Three Selected by Lasso: ','\\n', lasso_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numerical_features': Counter({'num_vehicles': 7,\n",
       "          'age_driver': 6,\n",
       "          'solar_radiation': 6,\n",
       "          'street_name_count': 2,\n",
       "          'windspeed': 1,\n",
       "          'license_seniority': 1,\n",
       "          'neighborhood_count': 1,\n",
       "          'precipitation': 1,\n",
       "          'pressure': 1})}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Numerical selected\n",
    "numerical_chosen=Counter(numerical_chosen)\n",
    "model_dict={}\n",
    "model_dict['numerical_features']=numerical_chosen\n",
    "# with open('./data/model_charac.pkl', 'wb') as f:\n",
    "#     pickle.dump(model_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cat_fea'></a>\n",
    "2. **Categorical Features**.\n",
    "\n",
    "[back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat=accidents[cat_columns].copy()\n",
    "y=accidents.target\n",
    "X_train_cat, X_test_cat, y_train, y_test=train_test_split(accidents[cat_columns],accidents.target,test_size=0.1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cat_vt'></a>\n",
    "1. **Categorical Features**.\n",
    "    - FILTER: Variance Threashold.\n",
    "   \n",
    "[back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs_cat(X):\n",
    "    oe = OrdinalEncoder()\n",
    "    oe.fit(X)\n",
    "    X_enc = oe.transform(X)\n",
    "    return X_enc\n",
    "X_cat_enc=prepare_inputs_cat(X_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt=VarianceThreshold()\n",
    "vt.fit(X_cat_enc)\n",
    "[num_columns[col[0]] for col in enumerate(vt.get_support()) if  not col[1]]\n",
    " ##=======>>No changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='chi_sq'></a>\n",
    "\n",
    "2. **Categorical Features**.\n",
    "    - FILTER: Chi Square.\n",
    "   \n",
    "[back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categorical_chosen=[]\n",
    "def select_features_cat(X, y,score_func=f_classif):\n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func=score_func, k='all')\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X, y)\n",
    "    # transform train input data\n",
    "    X_fs = fs.transform(X)\n",
    "    return X_fs, fs\n",
    " \n",
    "# feature selection\n",
    "X_fs, fs = select_features_cat(X_cat_enc, y,chi2)\n",
    "# what are scores for the features\n",
    "sorted_columns=sorted([x for x in zip(cat_columns,fs.scores_)], key=lambda x: x[1],reverse=True)\n",
    "chi2_sel=[col[0] for col in sorted_columns[:5]]\n",
    "categorical_chosen.extend(chi2_sel)\n",
    "# for i in range(len(sorted_columns)):\n",
    "#     print(f'Feature {sorted_columns[i][0]}:{sorted_columns[i][1]}')\n",
    "# plot the scores\n",
    "cols=[a for a,b in sorted_columns]\n",
    "scores=[b for a,b in sorted_columns]\n",
    "plt.barh(cols[::-1], scores[::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cat_corr'></a>\n",
    "\n",
    "2. **Categorical Features**.\n",
    "    - FILTER: Cramers V, Theils U Correlations.\n",
    "   \n",
    "[back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected by Cramers V:  \n",
      " ['accident_type', 'vehicle_brand_name', 'people_role_pedestrian']\n",
      "Selected by Theils U:  \n",
      " ['people_role_pedestrian', 'vehicle_model', 'vehicle_brand_name']\n"
     ]
    }
   ],
   "source": [
    "cramers, theils = [],[]\n",
    "for col in cat_columns:\n",
    "    correlation_c=fb3.cramers_corrected_stat(accidents[col],accidents.target)\n",
    "    correlation_u=fb3.theils_u(accidents[col],accidents.target)\n",
    "    #print(col, 'cramers', correlation_c)\n",
    "    cramers.append((col,correlation_c))\n",
    "    #print(col,'theils', correlation_u)\n",
    "    theils.append((col,correlation_u))\n",
    "cram_sel=[col[0] for col in sorted(cramers,key=lambda x:x[1],reverse=True)[0:3]]\n",
    "categorical_chosen.extend(cram_sel)\n",
    "print('Selected by Cramers V: ', '\\n',cram_sel)\n",
    "thei_sel=[col[0] for col in sorted(theils,key=lambda x:x[1],reverse=True)[:3]]\n",
    "categorical_chosen.extend(thei_sel)\n",
    "print('Selected by Theils U: ', '\\n',thei_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mut_info'></a>\n",
    "\n",
    "2. **Categorical Features**.\n",
    "    - FILTER: Mutual Information/Information Gain.\n",
    "   \n",
    "[back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature selection\n",
    "X_fs, fs = select_features_cat(X_cat_enc, y,mutual_info_classif)\n",
    "# what are scores for the features\n",
    "sorted_columns=sorted([x for x in zip(cat_columns,fs.scores_)], key=lambda x: x[1],reverse=True)\n",
    "mut_sel=[col[0] for col in sorted_columns[:5]]\n",
    "categorical_chosen.extend(mut_sel)\n",
    "# for i in range(len(sorted_columns)):\n",
    "#     print(f'Feature {sorted_columns[i][0]}:{sorted_columns[i][1]}')\n",
    "# plot the scores\n",
    "cols=[a for a,b in sorted_columns]\n",
    "scores=[b for a,b in sorted_columns]\n",
    "plt.barh(cols[::-1], scores[::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cat_rfe'></a>\n",
    "\n",
    "2. **Categorical Features**.\n",
    "    - WRAPPER: Recursive Feature Elimination.\n",
    "   \n",
    "[back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_cols \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,X_cat_enc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m      7\u001b[0m     rfe\u001b[38;5;241m=\u001b[39mRFE(lr,n_features_to_select\u001b[38;5;241m=\u001b[39mn_cols)\n\u001b[0;32m----> 8\u001b[0m     rfe\u001b[38;5;241m.\u001b[39mfit(X_cat_enc,y)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#print([num_columns[x[0]] for x in enumerate(rfe.ranking_) if x[1]==1])\\\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_cols\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_rfe.py:251\u001b[0m, in \u001b[0;36mRFE.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the RFE model and then the underlying estimator on the selected features.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_rfe.py:299\u001b[0m, in \u001b[0;36mRFE._fit\u001b[0;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting estimator with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m features.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m np\u001b[38;5;241m.\u001b[39msum(support_))\n\u001b[0;32m--> 299\u001b[0m estimator\u001b[38;5;241m.\u001b[39mfit(X[:, features], y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# Get importance and rank them\u001b[39;00m\n\u001b[1;32m    302\u001b[0m importances \u001b[38;5;241m=\u001b[39m _get_feature_importances(\n\u001b[1;32m    303\u001b[0m     estimator,\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_getter,\n\u001b[1;32m    305\u001b[0m     transform_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquare\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    306\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1291\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1289\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1291\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, prefer\u001b[38;5;241m=\u001b[39mprefer)(\n\u001b[1;32m   1292\u001b[0m     path_func(\n\u001b[1;32m   1293\u001b[0m         X,\n\u001b[1;32m   1294\u001b[0m         y,\n\u001b[1;32m   1295\u001b[0m         pos_class\u001b[38;5;241m=\u001b[39mclass_,\n\u001b[1;32m   1296\u001b[0m         Cs\u001b[38;5;241m=\u001b[39m[C_],\n\u001b[1;32m   1297\u001b[0m         l1_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratio,\n\u001b[1;32m   1298\u001b[0m         fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept,\n\u001b[1;32m   1299\u001b[0m         tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[1;32m   1300\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m   1301\u001b[0m         solver\u001b[38;5;241m=\u001b[39msolver,\n\u001b[1;32m   1302\u001b[0m         multi_class\u001b[38;5;241m=\u001b[39mmulti_class,\n\u001b[1;32m   1303\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[1;32m   1304\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m   1305\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1306\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[1;32m   1307\u001b[0m         coef\u001b[38;5;241m=\u001b[39mwarm_start_coef_,\n\u001b[1;32m   1308\u001b[0m         penalty\u001b[38;5;241m=\u001b[39mpenalty,\n\u001b[1;32m   1309\u001b[0m         max_squared_sum\u001b[38;5;241m=\u001b[39mmax_squared_sum,\n\u001b[1;32m   1310\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1311\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[1;32m   1312\u001b[0m     )\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m class_, warm_start_coef_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(classes_, warm_start_coef)\n\u001b[1;32m   1314\u001b[0m )\n\u001b[1;32m   1316\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:450\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    446\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C\n\u001b[1;32m    447\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[1;32m    448\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[1;32m    449\u001b[0m ]\n\u001b[0;32m--> 450\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m optimize\u001b[38;5;241m.\u001b[39mminimize(\n\u001b[1;32m    451\u001b[0m     func,\n\u001b[1;32m    452\u001b[0m     w0,\n\u001b[1;32m    453\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL-BFGS-B\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    454\u001b[0m     jac\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    455\u001b[0m     args\u001b[38;5;241m=\u001b[39m(X, target, sample_weight, l2_reg_strength, n_threads),\n\u001b[1;32m    456\u001b[0m     options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miprint\u001b[39m\u001b[38;5;124m\"\u001b[39m: iprint, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgtol\u001b[39m\u001b[38;5;124m\"\u001b[39m: tol, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_iter},\n\u001b[1;32m    457\u001b[0m )\n\u001b[1;32m    458\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[1;32m    459\u001b[0m     solver,\n\u001b[1;32m    460\u001b[0m     opt_res,\n\u001b[1;32m    461\u001b[0m     max_iter,\n\u001b[1;32m    462\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[1;32m    463\u001b[0m )\n\u001b[1;32m    464\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_minimize.py:710\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    707\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    708\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m    711\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    714\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py:365\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    359\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m func_and_grad(x)\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl()\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_optimize.py:77\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_if_needed(x, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_optimize.py:71\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 71\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfun(x, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:278\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    276\u001b[0m     weights, intercept \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_intercept(coef)\n\u001b[0;32m--> 278\u001b[0m loss, grad_pointwise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_loss\u001b[38;5;241m.\u001b[39mloss_gradient(\n\u001b[1;32m    279\u001b[0m     y_true\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    280\u001b[0m     raw_prediction\u001b[38;5;241m=\u001b[39mraw_prediction,\n\u001b[1;32m    281\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    282\u001b[0m     n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    284\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    285\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml2_penalty(weights, l2_reg_strength)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/_loss/loss.py:257\u001b[0m, in \u001b[0;36mBaseLoss.loss_gradient\u001b[0;34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    256\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m ReadonlyArrayWrapper(sample_weight)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcloss\u001b[38;5;241m.\u001b[39mloss_gradient(\n\u001b[1;32m    258\u001b[0m     y_true\u001b[38;5;241m=\u001b[39my_true,\n\u001b[1;32m    259\u001b[0m     raw_prediction\u001b[38;5;241m=\u001b[39mraw_prediction,\n\u001b[1;32m    260\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    261\u001b[0m     loss_out\u001b[38;5;241m=\u001b[39mloss_out,\n\u001b[1;32m    262\u001b[0m     gradient_out\u001b[38;5;241m=\u001b[39mgradient_out,\n\u001b[1;32m    263\u001b[0m     n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[1;32m    264\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(max_iter=3000)\n",
    "# min_max_scaler = MinMaxScaler()\n",
    "# X_cat_minmax = min_max_scaler.fit_transform(X_cat_enc)\n",
    "#X_test_minmax=min_max_scaler.transform(X_test_num)\n",
    "for n_cols in range(1,X_cat_enc.shape[1]):\n",
    "\n",
    "    rfe=RFE(lr,n_features_to_select=n_cols)\n",
    "    rfe.fit(X_cat_enc,y)\n",
    "    #print([num_columns[x[0]] for x in enumerate(rfe.ranking_) if x[1]==1])\\\n",
    "    if n_cols%10==0:\n",
    "        print(n_cols)\n",
    "rfe=RFE(lr,n_features_to_select=3)\n",
    "rfe.fit(X_cat_enc,y)\n",
    "rfe_sel=[cat_columns[x[0]] for x in enumerate(rfe.ranking_) if x[1]==1]\n",
    "categorical_chosen.extend(rfe_sel)\n",
    "print('Three Selected by RFE: ','\\n', rfe_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cat_rf'></a>\n",
    "\n",
    "2. **Categorical Features**.\n",
    "    - EMBEDDED: Random Forest Classifier.\n",
    "   \n",
    "[back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three Selected by RandomForest:  \n",
      " ['street_name_bins', 'driver_u_25', 'crossing_street']\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=100, random_state=2024)\n",
    "rf.fit(X_cat_enc,y)\n",
    "rf_sel=sorted([x[0] for x in zip(cat_columns,rf.feature_importances_)],key=lambda x:x[1],reverse=True)[:3]\n",
    "categorical_chosen.extend(rf_sel)\n",
    "print('Three Selected by RandomForest: ','\\n', rf_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cat_lasso'></a>\n",
    "\n",
    "2. **Numerical Features**.\n",
    "    - EMBEDDED: Lasso.\n",
    "   \n",
    "[back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "7\n",
      "3\n",
      "YEAH\n",
      "3 \n",
      " ['neighborhood', 'day', 'hour']\n",
      "Three Selected by Lasso:  \n",
      " ['neighborhood', 'day', 'hour']\n"
     ]
    }
   ],
   "source": [
    "# Lasso\n",
    "for c in np.linspace(0.001,0.00001,4):\n",
    "    #print(c)\n",
    "    lr=LogisticRegression(C=c,penalty='l1',solver='liblinear').fit(X_cat_enc,y)\n",
    "    selector = SelectFromModel(estimator=lr,prefit=True)\n",
    "    num_features=len([x[0] for x in zip(cat_columns,selector.get_support()) if x[1]])\n",
    "    print(num_features)\n",
    "    # if num_features == 6:\n",
    "    #     print(num_features,'\\n',[x[0] for x in zip(cat_columns,selector.get_support()) if x[1]])\n",
    "    if num_features <=3:\n",
    "        print('YEAH')\n",
    "        print(num_features,'\\n',[x[0] for x in zip(cat_columns,selector.get_support()) if x[1]])\n",
    "        lasso_sel=[x[0] for x in zip(cat_columns,selector.get_support()) if x[1]]\n",
    "        break\n",
    "categorical_chosen.extend(lasso_sel)\n",
    "print('Three Selected by Lasso: ','\\n', lasso_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Numerical selected\n",
    "categorical_chosen=Counter(categorical_chosen)\n",
    "model_dict['categorical_chosen']=categorical_chosen\n",
    "with open('./data/model_charac.pkl', 'wb') as f:\n",
    "    pickle.dump(model_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'people_role_pedestrian': 4,\n",
       "         'accident_type': 3,\n",
       "         'cause': 3,\n",
       "         'driver_u_25': 2,\n",
       "         'neighborhood': 2,\n",
       "         'ped_cause': 2,\n",
       "         'gender_driver_male': 2,\n",
       "         'gender_driver_female': 1,\n",
       "         'people_role_driver': 1,\n",
       "         'neighborhood_bins': 1,\n",
       "         'street_name_bins': 1,\n",
       "         'crossing_street': 1,\n",
       "         'day': 1,\n",
       "         'hour': 1})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contingency tables ans Stacked column charts!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###SELECTING CATEGORICAL ONES\n",
    "accidents['people_role_pass']=[x if x<6 else 10 for x in accidents.people_role_pass]\n",
    "accidents['vehicles_bus']=[x if x<7 else 10 for x in accidents.vehicles_bus]\n",
    "accidents['vehicles_car']=[x if x<7 else 10 for x in accidents.vehicles_car]\n",
    "accidents['vehicles_misc_vehicle']=[x if x<6 else 10 for x in accidents.vehicles_car]\n",
    "accidents['vehicles_motorcycle']=[x if x<4 else 7 for x in accidents.vehicles_motorcycle]\n",
    "accidents['vehicles_van']=[x if x<3 else 6 for x in accidents.vehicles_van]\n",
    "accidents['gender_driver_female']=[x if x<3 else 3 for x in accidents.gender_driver_female]\n",
    "\n",
    "X=accidents[cat_columns].copy()\n",
    "#X['people_role_pass']=[x if x<6 else 10 for x in X.people_role_pass]\n",
    "# X['vehicles_bus']=[x if x<7 else 10 for x in X.vehicles_bus]\n",
    "# X['vehicles_car']=[x if x<7 else 10 for x in X.vehicles_car]\n",
    "# X['vehicles_misc_vehicle']=[x if x<6 else 10 for x in X.vehicles_car]\n",
    "# X['vehicles_motorcycle']=[x if x<4 else 7 for x in X.vehicles_motorcycle]\n",
    "# X['vehicles_van']=[x if x<3 else 6 for x in X.vehicles_van]\n",
    "# X['gender_driver_female']=[x if x<3 else 3 for x in X.gender_driver_female]\n",
    "# y=accidents.target\n",
    "\n",
    "def prepare_inputs(X_train, X_test):\n",
    "    oe = OrdinalEncoder()\n",
    "    oe.fit(X_train)\n",
    "    X_train_enc = oe.transform(X_train)\n",
    "    X_test_enc = oe.transform(X_test)\n",
    "    return X_train_enc, X_test_enc\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    fs = SelectKBest(score_func=chi2, k='all')\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1,stratify=y)\n",
    "# prepare inputs\n",
    "X_train,X_test=prepare_inputs(X_train,X_test)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "sorted_columns=sorted([x for x in zip(cat_columns,fs.scores_)], key=lambda x: x[1],reverse=True)\n",
    "# for i in range(len(sorted_columns)):\n",
    "#     print(f'Feature {sorted_columns[i][0]}:{sorted_columns[i][1]}')\n",
    "# plot the scores\n",
    "cols=[a for a,b in sorted_columns]\n",
    "scores=[b for a,b in sorted_columns]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.barh(cols[::-1], scores[::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/model_charac.pkl', 'rb') as f:\n",
    "    data_pickled=pickle.load(f)\n",
    "data_pickled.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Numerical selected\n",
    "\n",
    "model_dict['categorical_features']=cols[:5]\n",
    "model_dict['categorical_features']\n",
    "with open('../data/model_charac.pkl', 'wb') as f:\n",
    "    pickle.dump(model_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing num_vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents['num_vehicles_aggr']=[x if x <7 else 'the rest' for x in accidents.num_vehicles]\n",
    "df_num_vehicles=pd.crosstab(accidents.target,accidents.num_vehicles_aggr, normalize='columns')\n",
    "df_num_vehicles.style.map(lambda x: 'background-color : red' if x<baseline_up and x>baseline_down else 'background-color :green')\n",
    "idents['num_vehicles_aggr']=[x if x <7 else 'the rest' for x in accidents.num_vehicles]\n",
    "df_num_vehicles=pd.crosstab(accidents.target,accidents.num_vehicles_aggr, normalize='columns')\n",
    "df_num_vehicles.style.map(lambda x: 'background-color : green' if x>baseline_up or x<baseline_down else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing only 1 and 2 vehicles\n",
    "\n",
    "new_accidents=accidents[accidents.num_vehicles.isin([1,2])]\n",
    "colors={}\n",
    "for j in range(new_accidents.num_vehicles_aggr.nunique()):\n",
    "    rand_colors = [\"#\"+''.join([random.choice('ABCDEF0123456789') for i in range(6)])]\n",
    "    colors[j]=rand_colors\n",
    "\n",
    "props = {}\n",
    "for x in [0, 1]:\n",
    "    for y, col in colors.items():\n",
    "        props[(x, y)] ={'color': col}\n",
    "        \n",
    "mosaic(new_accidents, ['target', 'num_vehicles_aggr'],\n",
    "       labelizer=lambda k: '',\n",
    "       properties=props);\n",
    "# props={}\n",
    "# props[(0,'Yes')]={'facecolor':'red', 'edgecolor':'white'}\n",
    "# props[(0,'No')]={'facecolor':'red', 'edgecolor':'white'}\n",
    "# props[(1,'Yes')]={'facecolor':'xkcd:aqua','edgecolor':'white'}\n",
    "# props[(1,'No')]=        {'facecolor':'xkcd:aqua','edgecolor':'white'}\n",
    "# labelizer=lambda k:{(0,'Yes'):357,(1,'Yes'):31,(0,'No'):130,(1,'No'):80}[k]\n",
    "# mosaic(accidents,['target','num_vehicles_aggr'],labelizer=labelizer,properties=props)\n",
    "pd.crosstab(accidents.target,accidents.num_vehicles_aggr,normalize='columns').iloc[1].plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accidents[accidents.age_driver==-1].shape\n",
    "\n",
    "import seaborn as sns\n",
    "sns.boxplot(x='target',y='age_driver',data=accidents);\n",
    "\n",
    "age=accidents.age_driver\n",
    "age_1=accidents[accidents['target'] == 1].age_driver\n",
    "age_0=accidents[accidents['target'] == 0].age_driver\n",
    "age_0.mean(), age_1.mean(),age.mean(),age_0.std(), age_1.std(),age.std()\n",
    "\n",
    "plt.hist(accidents[accidents.age_driver>0][accidents.target==0].age_driver,);\n",
    "\n",
    "accidents[(accidents['target'] == 0) & (accidents.age_driver>0)].age_driver\n",
    "\n",
    "plt.hist(accidents[(accidents['target'] == 0) & (accidents.age_driver>0)].age_driver);\n",
    "\n",
    "plt.hist(accidents[(accidents['target'] == 1) & (accidents.age_driver>0)].age_driver);\n",
    "\n",
    "plt.hist(accidents[accidents['target'] == 0].age_driver, label='Not', color='green', alpha=0.3, bins='scott')\n",
    "plt.hist(accidents[accidents['target'] == 1].age_driver, label='Severe', color='red', alpha=0.5, bins=14)\n",
    "plt.legend()\n",
    "plt.title('Histogram of Age target')\n",
    "plt.xlabel(\"Driver's Age\");\n",
    "sns.histplot(data=accidents, x=\"age_driver\", hue=\"target\", multiple='layer', element='step', binwidth=2, palette=['red', 'green']);\n",
    "\n",
    "# Perform Two-Sided T-Test comparing mean values of Loan and Non-loan classes\n",
    "print('Probability value of age_driver coming from same distribution:',\n",
    "      round(ttest_ind(accidents[(accidents['target'] == 0) & (accidents.age_driver>0)].age_driver,\\\n",
    "                                accidents[(accidents['target'] == 1) & (accidents.age_driver>0)].age_driver).pvalue, 4))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define a function for quickly plotting categorical features\n",
    "def cat_pairplot(plt_data=accidents[num_columns], y_feat='target'):\n",
    "    # Create a list of all feature names\n",
    "    feat_cols = list(plt_data.columns)\n",
    "    \n",
    "    # Make each plot on a pairplot-like graph with subplots, 2 wide\n",
    "    num_rows = int(len(feat_cols)/2)\n",
    "    f, axs = plt.subplots(nrows=num_rows, ncols=2,\n",
    "                          figsize=(14, 7*num_rows),\n",
    "                          sharey='row')\n",
    "    # Add additional vertical space between subplots\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    \n",
    "    # Iterate and illustrate a histogram for each categorical feature, colored with response\n",
    "    for i in range(len(feat_cols)):\n",
    "        sns.histplot(ax=axs[int(i/2), i%2], data=plt_data, x=feat_cols[i], hue=y_feat, multiple=\"dodge\", shrink=0.8)\n",
    "        axs[int(i/2), i%2].set_title(f'Histogram of \\'{feat_cols[i]}\\' Status against Voter Response');\n",
    "        # Rotat x-ticks for better readability\n",
    "        axs[int(i/2), i%2].tick_params(labelrotation=20, pad=1)\n",
    "        \n",
    "cat_pairplot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_up=accidents.target.value_counts(normalize=True).values[0]\n",
    "baseline_down=accidents.target.value_counts(normalize=True).values[1]\n",
    "baseline_up,baseline_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cramers, theils = [],[]\n",
    "for col in cat_columns:\n",
    "    correlation_c=fb3.cramers_corrected_stat(accidents[col],accidents.target)\n",
    "    correlation_u=fb3.theils_u(accidents[col],accidents.target)\n",
    "    #print(col, 'cramers', correlation_c)\n",
    "    cramers.append((col,correlation_c))\n",
    "    #print(col,'theils', correlation_u)\n",
    "    theils.append((col,correlation_u))\n",
    "sorted(cramers,key=lambda x:x[1],reverse=True)[0:3], sorted(theils,key=lambda x:x[1],reverse=True)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(theils,key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corre_cat_col=cols[:5]\n",
    "###Permutations: order matters\n",
    "###Combinartions: Order does not matter\n",
    "from itertools import permutations\n",
    "for perm in [x for x in permutations(corre_cat_col,2)]:\n",
    "    correlation_c=fb3.cramers_corrected_stat(accidents[perm[0]],accidents[perm[1]])\n",
    "    correlation_u=fb3.theils_u(accidents[perm[0]],accidents[perm[1]])\n",
    "    if correlation_c >0.8:\n",
    "        print(perm, 'cramers', correlation_c)\n",
    "    if correlation_u >0.8:\n",
    "        print(perm,'theils', correlation_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=accidents[cat_columns].copy()\n",
    "y=accidents.target\n",
    "def prepare_inputs(X_train, X_test):\n",
    "    oe = OrdinalEncoder()\n",
    "    oe.fit(X_train)\n",
    "    X_train_enc = oe.transform(X_train)\n",
    "    X_test_enc = oe.transform(X_test)\n",
    "    return X_train_enc, X_test_enc\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "prepare_inputs(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_dict=fb2.feature_dict\n",
    "scale_pipe = make_pipeline(StandardScaler())\n",
    "log_pipe = make_pipeline(PowerTransformer())\n",
    "categorical_pipe = make_pipeline(OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))\n",
    "to_scale=[fea for fea in selected_features if fea in feature_dict['numerical_features']]\n",
    "to_ohe=[fea for fea in selected_features if fea in feature_dict['ordinal_categorical_features']+feature_dict['cardinal_categorical_features']]\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"scale\", scale_pipe, to_scale),\n",
    "        #(\"log_transform\", log_pipe, to_log),\n",
    "        (\"oh_encode\", categorical_pipe, to_ohe),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb2.models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_df=pd.DataFrame()\n",
    "kf = RepeatedStratifiedKFold(n_splits=5, random_state=random_state, )\n",
    "\n",
    "for model in fb2.models_list:\n",
    "    pipe = Pipeline_imb([('resample', fb2.over.SMOTE(random_state=random_state)), \n",
    "                 ('clf', model[1])])\n",
    "    final_pipe=Pipeline([('transformer', transformer),('pipe',pipe)])\n",
    "    scores=fb2.cross_validate(final_pipe, X_train, y_train, scoring=fb2.metrics, cv=kf)\n",
    "    for key in scores:\n",
    "        scores_df.loc[model[0],key]=scores[key].mean() \n",
    "    print(model[0])\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##trying different models\n",
    "# X_train_std,X_test_std=fb2.preprocessing_fetures(train,test,numerical_features,categorical_features,scaler=True)\n",
    "# print(X_train_std.shape,X_test_std.shape)\n",
    "scores_df=pd.DataFrame()\n",
    "kf = RepeatedStratifiedKFold(n_splits=5, random_state=random_state, )\n",
    "for model in fb2.models_list:\n",
    "    pipe = Pipeline_imb([(\"prep\", transformer),('resample', fb2.over.SMOTE(random_state=random_state)), \n",
    "                 ('clf', model[1])])\n",
    "    scores=fb2.cross_validate(pipe, X_train.values, y_train.values, scoring=fb2.metrics, cv=kf)\n",
    "    for key in scores:\n",
    "        scores_df.loc[model[0],key]=scores[key].mean() \n",
    "    print(model[0])\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##using only randomforest with oversampling\n",
    "X_train_std,X_test_std=fb2.preprocessing_fetures(train,test,numerical_features,categorical_features,scaler=True)\n",
    "scores_over=pd.DataFrame()\n",
    "kf = StratifiedKFold(n_splits=5, random_state=random_state, shuffle=True)\n",
    "for sampling in fb2.oversamplings.keys():\n",
    "    print(sampling)\n",
    "#fb2.models_list[1][1]\n",
    "    pipe = Pipeline([('resample', fb2.oversamplings[sampling]),\n",
    "                      \n",
    "                     ('clf', fb2.models_list[1][1])])\n",
    "    scores=fb2.cross_validate(pipe, X_train_std, y_train, scoring=fb2.metrics, cv=kf)\n",
    "    for key in scores:\n",
    "        scores_over.loc[sampling,key]=scores[key].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pickled['results_uver_rf_pipeline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##using only randomforest with undersampling\n",
    "scores_under=pd.DataFrame()\n",
    "kf = StratifiedKFold(n_splits=5, random_state=random_state, shuffle=True)\n",
    "for sampling in fb2.undersamplings.keys():\n",
    "    print(sampling)\n",
    "#fb2.models_list[1][1]\n",
    "    pipe = Pipeline([('resample', fb2.undersamplings[sampling]), \n",
    "                     ('clf', fb2.models_list[1][1])])\n",
    "    scores=fb2.cross_validate(pipe, X_train_std, y_train, scoring=fb2.metrics, cv=kf)\n",
    "    for key in scores:\n",
    "        scores_under.loc[sampling,key]=scores[key].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##using only randomforest with over under\n",
    "\n",
    "scores_combo=pd.DataFrame()\n",
    "kf = StratifiedKFold(n_splits=5, random_state=random_state, shuffle=True)\n",
    "for sampling in fb2.over_undersamplings.keys():\n",
    "    print(sampling)\n",
    "#fb2.models_list[1][1]\n",
    "    pipe = Pipeline([('resample', fb2.over_undersamplings[sampling]),\n",
    "                     ('standarization', StandardScaler()), \n",
    "                     ('clf', fb2.models_list[1][1])])\n",
    "    scores=fb2.cross_validate(pipe, X_train, y_train, scoring=fb2.metrics, cv=kf)\n",
    "    for key in scores:\n",
    "        scores_combo.loc[sampling,key]=scores[key].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validate_scores={}\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "pipe = Pipeline([('resample', fb2.over.SMOTE(random_state=random_state)),\n",
    "                 ('standarization', StandardScaler()), \n",
    "                 ('clf', RandomForestClassifier(n_estimators=100, random_state=13))])\n",
    "#imba_pipeline = make_pipeline(SMOTE(random_state=42), RandomForestClassifier(n_estimators=100, random_state=13))\n",
    "scores=cross_val_score(pipe, X_train, y_train, scoring='roc_auc', cv=kf)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##using only randomforest with undersampling and oversampling\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "scores_under_over=pd.DataFrame()\n",
    "kf = StratifiedKFold(n_splits=5, random_state=random_state, shuffle=True)\n",
    "# for sampling in fb2.oversamplings.keys():\n",
    "#     print(sampling)\n",
    "# #fb2.models_list[1][1]\n",
    "pipe = Pipeline([('undersample', fb2.undersamplings['OSS']),\n",
    "                ('oversample', fb2.oversamplings['ROS']),\n",
    "                 ('standarization', StandardScaler()), \n",
    "                 ('clf', fb2.models_list[1][1])])\n",
    "scores=fb2.cross_validate(pipe, X_train, y_train, scoring=fb2.metrics, cv=kf)\n",
    "for key in scores_under_over:\n",
    "    scores_under_over.loc[0,key]=scores[key].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Selection so far\n",
    "#features\n",
    "numerical_features=['num_vehicles','hood_count',]\n",
    "categorical_features=['district','pedestrian','shift','weekend',]\n",
    "##model\n",
    "models_list.append(('rf',RandomForestClassifier(class_weight='balanced', max_depth=3, n_estimators=10, max_features=3, random_state=random_state))\n",
    " ##pipeline   \n",
    "RandomOverSampler, SMoteTomek,OneSidedSelection,StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1=[pred[1] for pred in predictions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [4, 6, 10, 12],\n",
    "}\n",
    "new_params = {'clf__' + key: params[key] for key in params}\n",
    "kf = StratifiedKFold(n_splits=5, random_state=random_state, shuffle=True)\n",
    "pipe = Pipeline([('undersample', fb2.undersamplings['OSS']),\n",
    "                ('oversample', fb2.oversamplings['ROS']),\n",
    "                 ('standarization', StandardScaler()), \n",
    "                 ('clf', RandomForestClassifier(class_weight='balanced',random_state=fb2.random_state))])\n",
    "grid_imba = GridSearchCV(pipe, param_grid=new_params, cv=kf, scoring='roc_auc',\n",
    "                        return_train_score=True)\n",
    "grid_imba.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_imba.best_params_, grid_imba.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=random_state, shuffle=True)\n",
    "pipe = Pipeline([('undersample', fb2.undersamplings['OSS']),\n",
    "                ('oversample', fb2.oversamplings['ROS']),\n",
    "                 ('standarization', StandardScaler()), \n",
    "                 ('clf', RandomForestClassifier(class_weight='balanced',\n",
    "                                                random_state=fb2.random_state,max_depth=12,\n",
    "                                               n_estimators=100))])\n",
    "scores=fb2.cross_validate(pipe, X_train, y_train, scoring=fb2.metrics, cv=kf)\n",
    "for key in scores:\n",
    "    print(key,scores[key].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "pipe.fit(X_train,y_train)\n",
    "predictions=pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as m\n",
    "m.recall_score(y_test,predictions),m.precision_score(y_test,predictions),m.accuracy_score(y_test,predictions),m.roc_auc_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###class weight\n",
    "X_train=fb2.X_train\n",
    "y_train=fb2.y_train\n",
    "X_test=fb2.X_test\n",
    "y_test=fb2.y_test\n",
    "# numerical_features=fb2.numerical_features\n",
    "# categorical_features=fb2.categorical_features\n",
    "numerical_features=['num_vehicles','hood_count',]\n",
    "categorical_features=['district','pedestrian','shift','weekend',]\n",
    "\n",
    "\n",
    "X_train,X_test=fb2.preprocessing_fetures(X_train,X_test,numerical_features,categorical_features)\n",
    "# fb2.undersampling(X_train,y_train)\n",
    "# X_train.shape, y_train.shape\n",
    "models_list=fb2.models_list\n",
    "models=fb2.models\n",
    "random_state=fb2.random_state\n",
    "\n",
    "accuracies=[]\n",
    "recalls=[]\n",
    "precisions=[]\n",
    "aucs=[]\n",
    "for model in models_list:\n",
    "    scores = fb2.scoring_model(X_train,X_test,y_train,y_test,model[1])\n",
    "    recalls.append(scores[0])\n",
    "    precisions.append(scores[1])\n",
    "    accuracies.append(scores[2])\n",
    "    aucs.append(scores[3])\n",
    "results=pd.DataFrame()\n",
    "results['recall']=recalls\n",
    "results['precision']=precisions\n",
    "results['accuracy']=accuracies\n",
    "results['auc']=aucs\n",
    "results.index=[model[0] for model in models_list]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies=[]\n",
    "recalls=[]\n",
    "precisions=[]\n",
    "aucs=[]\n",
    "undersamplings=fb2.undersamplings\n",
    "\n",
    "for key in undersamplings.keys():\n",
    "    print(key)\n",
    "    start=time.time()\n",
    "    X_under, y_under= undersampling_dataset(X_train,y_train,model=undersamplings[key])\n",
    "    end=time.time()\n",
    "    print(key,round((end-start)/60,2),'minutes')\n",
    "    scores=fb2.scoring_model(X_under,X_test,y_under,y_test,models_dict['forest']['name'])\n",
    "    recalls.append(scores[0])\n",
    "    precisions.append(scores[1])\n",
    "    accuracies.append(scores[2])\n",
    "    aucs.append(scores[3])\n",
    "results_under=pd.DataFrame()\n",
    "results_under['recall']=recalls\n",
    "results_under['precision']=precisions\n",
    "results_under['accuracy']=accuracies\n",
    "results_under['auc']=aucs\n",
    "results_under.index=list(undersamplings.keys())\n",
    "results_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output_pickle.pkl', 'rb') as f:\n",
    "    data_pickled=pickle.load(f)\n",
    "data_pickled['results_under_w/rf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "end=tiime.time()\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end=tiime.time()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Package the variables we want to export\n",
    "data = {\n",
    "    'results_under_w/rf': results_under,  # Record what was vectorized\n",
    "    'results_w/models': results,\n",
    "    'results_over': results_over,\n",
    "    \n",
    "              # For encoding additional test data\n",
    "    \n",
    "    'X_train': X_train,        # Train\n",
    "    'y_train': y_train,\n",
    "    \n",
    "    \n",
    "    }\n",
    "\n",
    "\n",
    "# 'wb' - Write + Binary File\n",
    "with open('output_pickle.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(string):\n",
    "    index = 0\n",
    "    compressed = \"\"\n",
    "    len_str = len(string)\n",
    "    while index != len_str:\n",
    "        count = 1\n",
    "        while (index < len_str-1) and (string[index] == string[index+1]):\n",
    "            count = count + 1\n",
    "            index = index + 1\n",
    "        if count == 1:\n",
    "            compressed += str(string[index])\n",
    "        else:\n",
    "            compressed += str(string[index]) + str(count)\n",
    "        index = index + 1\n",
    "    return compressed\n",
    "\n",
    "\n",
    "string= \"djjjjjjjjppjjjjjjjjjjjrhejrejj\"\n",
    "\n",
    "print(compress(string))\n",
    "\n",
    "if len(compress(string)) > len(string):\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pickled['results_uver_under_rf_pipeline']=scores_under_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pickled.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('output_pickle.pkl', 'rb') as f:\n",
    "#     data_pickled=pickle.load(f)\n",
    "# data_pickled['results_over_under']=results_over_under\n",
    "with open('output_pickle.pkl', 'wb') as f:\n",
    "    pickle.dump(data_pickled, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies=[]\n",
    "recalls=[]\n",
    "precisions=[]\n",
    "aucs=[]\n",
    "oversamplings=fb2.oversamplings\n",
    "oversampling_dataset=fb2.oversampling_dataset\n",
    "\n",
    "for key in oversamplings.keys():\n",
    "    print(key)\n",
    "    start=time.time()\n",
    "    X_under, y_under= oversampling_dataset(X_train,y_train,model=oversamplings[key])\n",
    "    end=time.time()\n",
    "    print(key,round((end-start)/60,2),'minutes')\n",
    "    scores=fb2.scoring_model(X_under,X_test,y_under,y_test,models_dict['forest']['name'])\n",
    "    recalls.append(scores[0])\n",
    "    precisions.append(scores[1])\n",
    "    accuracies.append(scores[2])\n",
    "    aucs.append(scores[3])\n",
    "results_over=pd.DataFrame()\n",
    "results_over['recall']=recalls\n",
    "results_over['precision']=precisions\n",
    "results_over['accuracy']=accuracies\n",
    "results_over['auc']=aucs\n",
    "results_over.index=list(oversamplings.keys())\n",
    "results_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pickled['results_over_w/rf'][data_pickled['results_over_w/rf']['auc']>0.58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies=[]\n",
    "recalls=[]\n",
    "precisions=[]\n",
    "aucs=[]\n",
    "over_undersamplings=fb2.over_undersamplings\n",
    "#over_undersampling_dataset=fb2.over_undersampling_dataset\n",
    "\n",
    "for key in over_undersamplings.keys():\n",
    "    print(key)\n",
    "    start=time.time()\n",
    "    X_under, y_under= oversampling_dataset(X_train,y_train,model=over_undersamplings[key])\n",
    "    end=time.time()\n",
    "    print(key,round((end-start)/60,2),'minutes')\n",
    "    scores=fb2.scoring_model(X_under,X_test,y_under,y_test,models_dict['forest']['name'])\n",
    "    recalls.append(scores[0])\n",
    "    precisions.append(scores[1])\n",
    "    accuracies.append(scores[2])\n",
    "    aucs.append(scores[3])\n",
    "results_over_under=pd.DataFrame()\n",
    "results_over_under['recall']=recalls\n",
    "results_over_under['precision']=precisions\n",
    "results_over_under['accuracy']=accuracies\n",
    "results_over_under['auc']=aucs\n",
    "results_over_under.index=list(over_undersamplings.keys())\n",
    "results_over_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from imblearn.pipeline import Pipeline\n",
    " \n",
    "\n",
    "# over = ...\n",
    "# under = ...\n",
    "# define pipeline\n",
    "#pipeline = Pipeline(steps=[('o', over), ('u', under)])\n",
    "#oversamplings['SVMSMOTE']\n",
    "undersamplings=fb2.undersamplings\n",
    "#undersamplings['NCL']\n",
    "###########################\n",
    "model = models_dict['forest']['name']\n",
    "# define resampling\n",
    "over = oversamplings['SVMSMOTE']\n",
    "under = undersamplings['NCL']\n",
    "# define pipeline\n",
    "pipeline = Pipeline(steps=[('o', over), ('u', under), ('m', model)])\n",
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "# summarize performance\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "pred=pipeline.predict(X_test)\n",
    "print(\"Accuracy: \",accuracy_score(y_test,pred),'\\n')\n",
    "print(\"Recall :\", recall_score(y_test,pred))\n",
    "print(\"auc: \", roc_auc_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training and test data\n",
    "numerical_features=['num_vehicles','hood_count',]\n",
    "categorical_features=['district','pedestrian','shift','weekend',]\n",
    "\n",
    "accidents['hour']=accidents.hour.astype(str)\n",
    "accidents['year']=accidents.year.astype(str)\n",
    "acc_20=accidents[accidents.year=='2020']\n",
    "acc_19=accidents[accidents.year=='2019']\n",
    "test=accidents[accidents.year.isin(['2019','2020'])]\n",
    "train=accidents[~accidents.year.isin(['2019','2020'])]\n",
    "\n",
    "X_train=pd.concat([train[numerical_features],pd.get_dummies(train[categorical_features],drop_first=True)],axis=1)\n",
    "y_train=train.target\n",
    "X_test=pd.concat([test[numerical_features],pd.get_dummies(test[categorical_features],drop_first=True)],axis=1)\n",
    "y_test=test.target\n",
    "ratio_strategy=0.8\n",
    "smote = SMOTE(sampling_strategy=ratio_strategy,random_state = 99)\n",
    "X_train_over, y_train_over = smote.fit_resample(X_train, y_train)\n",
    "# Instantiate the visualizer with the classification model\n",
    "model = GradientBoostingClassifier(random_state=44)\n",
    "# visualizer = ROCAUC(model, classes=[\"no_injuries\", \"injuries\"])\n",
    "\n",
    "# visualizer.fit(X_train_over, y_train_over)        # Fit the training data to the visualizer\n",
    "# visualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "# visualizer.show()                       # Finalize and show the figure\n",
    "model.fit(X_train_over,y_train_over)\n",
    "\n",
    "print('f2_score: ',fbeta_score(y_test,model.predict(X_test),beta=2))\n",
    "recall= recall_score(y_test,model.predict(X_test))\n",
    "print('Recall: ', recall)\n",
    "\n",
    "infile = open('../scores/scores.pkl','rb')\n",
    "scores_dict = pickle.load(infile)\n",
    "infile.close()\n",
    "# scores_dict={}\n",
    "# scores_dict['scores']={}\n",
    "# scores_dict['features']=[]\n",
    "# scores_dict['params']={}\n",
    "best_recall=scores_dict['recall']['score']\n",
    "#best_recall=0\n",
    "best_auc=scores_dict['auc']['score']\n",
    "#best_auc=0\n",
    "accuracy=accuracy_score(y_test,model.predict(X_test))\n",
    "print('Accuracy: ', accuracy)\n",
    "print('Cohen-Kappa :', cohen_kappa_score(y_test,model.predict(X_test)))\n",
    "auc=roc_auc_score(y_test,model.predict(X_test))\n",
    "print('AUC :', auc)\n",
    "if recall > best_recall:\n",
    "    \n",
    "    scores_dict['recall']['score']=recall\n",
    "    scores_dict['recall'].update( {'features' : numerical_features+categorical_features} )\n",
    "   \n",
    "    scores_dict['recall']['params']['smote']=ratio_strategy\n",
    "    scores_dict['recall']['params']['model']=model\n",
    "    scores_dict['recall']['params']['accuracy']=accuracy\n",
    "    best_recall=recall\n",
    "    outfile = open('../scores/scores.pkl','wb')\n",
    "    pickle.dump(scores_dict,outfile)\n",
    "    outfile.close()    \n",
    "    print('Recall improved: ', round(recall,4))\n",
    "    \n",
    "\n",
    "if auc > best_auc:\n",
    "  \n",
    "    scores_dict['auc']['score']=auc\n",
    "    scores_dict['auc'].update( {'features' : numerical_features+categorical_features} )\n",
    "   \n",
    "    scores_dict['auc']['params']['smote']=ratio_strategy\n",
    "    scores_dict['auc']['params']['model']=model\n",
    "    scores_dict['auc']['params']['accuracy']=accuracy\n",
    "    best_auc=auc\n",
    "    outfile = open('../scores/scores.pkl','wb')\n",
    "    pickle.dump(scores_dict,outfile)\n",
    "    outfile.close()\n",
    "\n",
    "    print('auc improved: ', round(auc,2))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choosing_ratio_strategy(ratio_strategy):    \n",
    "    numerical_features=['num_vehicles','hood_count',]\n",
    "    categorical_features=['district','pedestrian','shift','weekend',]\n",
    "\n",
    "    accidents['hour']=accidents.hour.astype(str)\n",
    "    accidents['year']=accidents.year.astype(str)\n",
    "    acc_20=accidents[accidents.year=='2020']\n",
    "    acc_19=accidents[accidents.year=='2019']\n",
    "    test=accidents[accidents.year.isin(['2019','2020'])]\n",
    "    train=accidents[~accidents.year.isin(['2019','2020'])]\n",
    "\n",
    "    X_train=pd.concat([train[numerical_features],pd.get_dummies(train[categorical_features],drop_first=True)],axis=1)\n",
    "    y_train=train.target\n",
    "    X_test=pd.concat([test[numerical_features],pd.get_dummies(test[categorical_features],drop_first=True)],axis=1)\n",
    "    y_test=test.target\n",
    "    print('Ratio: ', ratio_strategy)\n",
    "    smote = SMOTE(sampling_strategy=ratio_strategy,random_state = 99)\n",
    "    X_train_over, y_train_over = smote.fit_resample(X_train, y_train)\n",
    "    # Instantiate the visualizer with the classification model\n",
    "    ss=StandardScaler()\n",
    "    X_train=ss.fit_transform(X_train_over)\n",
    "    X_test=ss.transform(X_test)\n",
    "    model = GradientBoostingClassifier(random_state=44)\n",
    "    \n",
    "    model.fit(X_train, y_train_over) \n",
    "    #preds=[1 if x[1] >0.45 else 0 for x in model.predict_proba(X_test)]\n",
    "    predictions=model.predict(X_test)\n",
    "    recall= recall_score(y_test,predictions)\n",
    "    print('Recall: ', recall)\n",
    "\n",
    "    accuracy=accuracy_score(y_test,predictions)\n",
    "    print('Accuracy: ', accuracy)\n",
    "    auc=roc_auc_score(y_test,predictions)\n",
    "    print('AUC :', auc)\n",
    "for x in np.linspace(0.5,.9,5):\n",
    "    choosing_ratio_strategy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0 if value='TurboTax' else 1 for value in df.column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf=confusion_matrix(y_test,visualizer.predict(X_test))\n",
    "proba_1=[x[1] for x in model.predict_proba(X_test)]\n",
    "def threshold_clac(threshold, proba_1, y_test):\n",
    "    preds=[1 if x>threshold else 0 for x in proba_1]\n",
    "    return recall_score(y_test,preds), roc_auc_score(y_test,preds), accuracy_score(y_test,preds)\n",
    "for t in np.linspace(0.1,.5,5):\n",
    "    print(t,threshold_clac(t,proba_1,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(threshold_clac(0.45,proba_1,y_test))\n",
    "probas=[x[1] for x in visualizer.predict_proba(X_test)]\n",
    "preds=[1 if x>.45 else 0 for x in probas]\n",
    "cf=confusion_matrix(y_test,model.predict(X_test))\n",
    "pd.DataFrame(cf, columns=['pred_0','pred_1'],index=['actual_0','actual_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choosing_model(model,scoring='recall'):    \n",
    "    numerical_features=['num_vehicles','hood_count',]\n",
    "    categorical_features=['district','pedestrian','shift','weekend',]\n",
    "\n",
    "    accidents['hour']=accidents.hour.astype(str)\n",
    "    accidents['year']=accidents.year.astype(str)\n",
    "    acc_20=accidents[accidents.year=='2020']\n",
    "    acc_19=accidents[accidents.year=='2019']\n",
    "    test=accidents[accidents.year.isin(['2019','2020'])]\n",
    "    train=accidents[~accidents.year.isin(['2019','2020'])]\n",
    "\n",
    "    X_train=pd.concat([train[numerical_features],pd.get_dummies(train[categorical_features],drop_first=True)],axis=1)\n",
    "    y_train=train.target\n",
    "    X_test=pd.concat([test[numerical_features],pd.get_dummies(test[categorical_features],drop_first=True)],axis=1)\n",
    "    y_test=test.target\n",
    "    ratio_strategy=0.7\n",
    "    smote = SMOTE(sampling_strategy=ratio_strategy,random_state = 99)\n",
    "    X_train_over, y_train_over = smote.fit_resample(X_train, y_train)\n",
    "    ss=StandardScaler()\n",
    "    X_train=ss.fit_transform(X_train_over)\n",
    "    X_test=ss.transform(X_test)\n",
    "    # Instantiate the visualizer with the classification model\n",
    "    #model = GradientBoostingClassifier(random_state=44)\n",
    "    print(model)\n",
    "    scoring=scoring\n",
    "    kfold=KFold(n_splits=5, random_state=random_state,shuffle=True)\n",
    "\n",
    "    return cross_val_score(model,X_train,y_train,cv=kfold,scoring=scoring)\n",
    "    \n",
    "\n",
    "random_state=3456\n",
    "models_list=[]\n",
    "models_list.append(('logreg',LogisticRegression(C= 1, random_state=random_state)))\n",
    "models_list.append(('rf',RandomForestClassifier(class_weight='balanced', max_depth=3, n_estimators=10, max_features=3, random_state=random_state)))\n",
    "models_list.append(('lda', LinearDiscriminantAnalysis()))\n",
    "models_list.append(('linearsvc',LinearSVC(C=1.0, random_state=random_state, class_weight='balanced')))\n",
    "models_list.append(('gbc', GradientBoostingClassifier(random_state=random_state)))\n",
    "models_list.append(('XGBoost',XGBClassifier(random_state=random_state)))\n",
    "results=[]\n",
    "names=[]\n",
    "for name,model in models_list:\n",
    "    print(name)\n",
    "    results.append(choosing_model(model))\n",
    "    names.append(name)\n",
    "    #print(type(key))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies=[]\n",
    "for name in names:\n",
    "    accuracies.append(resultats[name]['accuracy'])\n",
    "\n",
    "fig=plt.figure()\n",
    "fig.suptitle('Accuracy')\n",
    "ax=fig.add_subplot(111)\n",
    "plt.boxplot(accuracies)\n",
    "ax.set_xticklabels(names)\n",
    "\n",
    "recalls=[]\n",
    "for name in names:\n",
    "    recalls.append(resultats[name]['recall'])\n",
    "\n",
    "fig=plt.figure()\n",
    "fig.suptitle('Recall')\n",
    "ax=fig.add_subplot(111)\n",
    "plt.boxplot(recalls)\n",
    "ax.set_xticklabels(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features=['num_vehicles','hood_count',]\n",
    "categorical_features=['district','pedestrian','shift','weekend',]\n",
    "\n",
    "accidents['hour']=accidents.hour.astype(str)\n",
    "accidents['year']=accidents.year.astype(str)\n",
    "acc_20=accidents[accidents.year=='2020']\n",
    "acc_19=accidents[accidents.year=='2019']\n",
    "test=accidents[accidents.year.isin(['2019','2020'])]\n",
    "train=accidents[~accidents.year.isin(['2019','2020'])]\n",
    "\n",
    "X_train=pd.concat([train[numerical_features],pd.get_dummies(train[categorical_features],drop_first=True)],axis=1)\n",
    "y_train=train.target\n",
    "X_test=pd.concat([test[numerical_features],pd.get_dummies(test[categorical_features],drop_first=True)],axis=1)\n",
    "y_test=test.target\n",
    "ratio_strategy=0.7\n",
    "smote = SMOTE(sampling_strategy=ratio_strategy,random_state = 99)\n",
    "X_train_over, y_train_over = smote.fit_resample(X_train, y_train)\n",
    "ss=StandardScaler()\n",
    "x_train=ss.fit_transform(X_train_over)\n",
    "X_test=ss.transform(X_test)\n",
    "# Instantiate the visualizer with the classification model\n",
    "model = RandomForestClassifier(class_weight='balanced', max_depth=3, n_estimators=10, max_features=3, random_state=random_state)\n",
    "#print(model)\n",
    "visualizer = ROCAUC(model, classes=[\"no_injuries\", \"injuries\"])\n",
    "visualizer.fit(X_train, y_train)\n",
    "#preds=[1 if x[1] >0.45 else 0 for x in visualizer.predict_proba(X_test)]\n",
    "\n",
    "recall= recall_score(y_test,visualizer.predict(X_test))\n",
    "print('Recall: ', recall)\n",
    "\n",
    "accuracy=accuracy_score(y_test,preds)\n",
    "print('Accuracy: ', accuracy)\n",
    "auc=roc_auc_score(y_test,preds)\n",
    "print('AUC :', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf=confusion_matrix(y_test,visualizer.predict(X_test))\n",
    "proba_1=[x[1] for x in visualizer.predict_proba(X_test)]\n",
    "def threshold_clac(threshold, proba_1, y_test):\n",
    "    preds=[1 if x>threshold else 0 for x in proba_1]\n",
    "    return recall_score(y_test,preds), roc_auc_score(y_test,preds), accuracy_score(y_test,preds)\n",
    "for t in np.linspace(0.1,.5,5):\n",
    "    print(t,threshold_clac(t,proba_1,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=visualizer.predict(X_test)\n",
    "tp=0\n",
    "tn=0\n",
    "fp=0\n",
    "fn=0\n",
    "conf_matrix=pd.Series(['tp' if (x[0]==x[1]) and (x[0]==1) else 'tn' if x[0]==x[1] else 'fn' if x[0]==1 and x[1]==0 else 'fp' for x in zip(y_test,preds)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives=X_test.iloc[conf_matrix[conf_matrix=='fn'].index]\n",
    "(false_negatives[[x for x in false_negatives.columns if 'district' in x]].sum()).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives.groupby('district')['neighborhood'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=accidents.drop('target',axis=1).copy()\n",
    "numerical_f=accidents.select_dtypes(exclude='object').columns\n",
    "categorical_f=accidents.select_dtypes(include='object').columns\n",
    "X=pd.concat([accidents[numerical_f],pd.get_dummies(accidents[categorical_f],drop_first=True)],axis=1)\n",
    "y=accidents.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ExtraTreesClassifier(n_estimators=100)\n",
    "model.fit(X,y)\n",
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fimp=model.feature_importances_\n",
    "len(fimp), X.shape\n",
    "x=dict(zip(X.columns, fimp))\n",
    "sorted(x.items(), key=lambda item: item[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###FUNCTIONS\n",
    "\n",
    "\n",
    "def sorting_by_corr(dataframe, features, target):\n",
    "    \n",
    "    \"\"\"Sorting all features by its correlation with target\"\"\"\n",
    "    \n",
    "    \n",
    "    data = dataframe[features].copy()\n",
    "    data.reset_index(inplace=True)\n",
    "    nova_data = pd.DataFrame()\n",
    "    \n",
    "    for item in data[features].select_dtypes(exclude=['int', 'float']).columns:\n",
    "            \n",
    "        prova = pd.get_dummies(data[item])\n",
    "        nova_data = pd.concat([nova_data,prova], axis=1)\n",
    "        \n",
    "    for item in data[features].select_dtypes(include=['int', 'float']).columns:\n",
    "        nova_data[item] = data[item]\n",
    "    nova_data[target] = dataframe[target]    \n",
    "     \n",
    "    correlation = nova_data.corr()\n",
    "    \n",
    "    \n",
    "    correlation[target] = [x if x >= 0 else (-1) * x for x in correlation[target]]\n",
    "            \n",
    "    \n",
    "    all_features = list(correlation[target].sort_values(ascending=False)[1::].index)\n",
    "    final_df = nova_data[all_features]\n",
    "    return all_features, final_df\n",
    "\n",
    "\n",
    "def changing_threshold(proba, threshold_majority):\n",
    "    \n",
    "    \"\"\"recalculating predictions based on threshold\"\"\"\n",
    "    \n",
    "    return [0 if x[0] >= threshold_majority else 1 for x in proba]\n",
    "\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "            TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "            FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "            TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "            FN += 1\n",
    "\n",
    "    return TP, FP, TN, FN\n",
    "\n",
    "\n",
    "def selecting_features(dataframe, target, features):\n",
    "    \n",
    "    \"\"\"Function to select features through combinationa\"\"\"\n",
    "    \n",
    "    data = dataframe[features].copy()\n",
    "    data.reset_index(inplace=True)\n",
    "    for item in features:\n",
    "        if data[item].dtypes == 'object':\n",
    "            #print(item, data[item].dtypes, 'object')\n",
    "            prova = pd.get_dummies(data[item], drop_first=True)\n",
    "            data = pd.concat([data,prova], axis=1)\n",
    "            data.drop(item, axis=1, inplace=True)\n",
    "\n",
    "    X = np.array(data)\n",
    "    y = dataframe[target]\n",
    "    y = (np.where (y > 0, 1, 0))\n",
    "    y = np.reshape(y, len(y))\n",
    "    \n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1, stratify=y)\n",
    "    \n",
    "    \n",
    "    X_resampled, y_resampled = SMOTE(ratio=0.3, random_state=2018).fit_sample(X_train, y_train)\n",
    "\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_resampled)\n",
    "    X_train_std = ss.transform(X_resampled)\n",
    "    X_test_std = ss.transform(X_test)\n",
    "    \n",
    "    \n",
    "    clf = LogisticRegression()        \n",
    "    clf.fit(X_train_std, y_resampled)\n",
    "    score = clf.score(X_test_std, y_test)\n",
    "    pred = clf.predict(X_test_std)\n",
    "    prob = clf.predict_proba(X_test_std)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    fbeta = fbeta_score(y_test, pred, beta=0.5)\n",
    "    \n",
    "    return accuracy, recall, precision, f1, fbeta, prob, y_test\n",
    "\n",
    "\n",
    "def selecting_features_corr(dataframe, target, features):\n",
    "    \n",
    "    \"\"\"It is a similar function thatn the one with combinations. In this case, features\n",
    "    are already separated and dummied\"\"\"\n",
    "    \n",
    "    data = dataframe[features].copy()\n",
    "    data.reset_index(inplace=True)\n",
    "\n",
    "    X = np.array(data)\n",
    "    y = dataframe[target]\n",
    "    y = (np.where (y > 0, 1, 0))\n",
    "    y = np.reshape(y, len(y))\n",
    "    \n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1, stratify=y)\n",
    "    \n",
    "    \n",
    "    X_resampled, y_resampled = SMOTE(ratio=0.3, random_state=2018).fit_sample(X_train, y_train)\n",
    "\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_resampled)\n",
    "    X_train_std = ss.transform(X_resampled)\n",
    "    X_test_std = ss.transform(X_test)\n",
    "    \n",
    "    \n",
    "    clf = LogisticRegression()        \n",
    "    clf.fit(X_train_std, y_resampled)\n",
    "    score = clf.score(X_test_std, y_test)\n",
    "    pred = clf.predict(X_test_std)\n",
    "    prob = clf.predict_proba(X_test_std)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    fbeta = fbeta_score(y_test, pred, beta=0.5)\n",
    "    \n",
    "    return accuracy, recall, precision, f1, fbeta, prob, pred\n",
    "\n",
    "### Pickling resultat\n",
    "\n",
    "def pickling_resultat(resultat):\n",
    "    \n",
    "    for i in resultat.keys():\n",
    "        with open('resultat{}.pkl'.format(i), 'wb') as picklefile:\n",
    "            pickle.dump(resultat[i], picklefile)\n",
    "            \n",
    "def depickling_resultat(amount_features):\n",
    "    resultat = {}\n",
    "    for i in range (1, amount_features + 1):\n",
    "        \n",
    "        with open('resultat{}.pkl'.format(i), 'rb') as f:\n",
    "            resultat[i] = pickle.load(f)\n",
    "    return resultat\n",
    "\n",
    "def selecting_model(dataframe, target, features, model):\n",
    "    \n",
    "    data = dataframe[features].copy()\n",
    "    data.reset_index(inplace=True)\n",
    "    for item in features:\n",
    "        if data[item].dtypes == 'object':\n",
    "            #print(item, data[item].dtypes, 'object')\n",
    "            prova = pd.get_dummies(data[item], drop_first=True)\n",
    "            data = pd.concat([data,prova], axis=1)\n",
    "            data.drop(item, axis=1, inplace=True)\n",
    "\n",
    "    X = np.array(data)\n",
    "    y = dataframe[target]\n",
    "    y = (np.where (y > 0, 1, 0))\n",
    "    y = np.reshape(y, len(y))\n",
    "    \n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1, stratify=y)\n",
    "    \n",
    "    \n",
    "    X_resampled, y_resampled = SMOTE(ratio=0.3, random_state=2018).fit_sample(X_train, y_train)\n",
    "\n",
    "    #print('Labels counts in y:', np.bincount(y), (np.bincount(y)[1]/np.bincount(y)[0]))\n",
    "    #print('Labels counts in y_train:', np.bincount(y_train), (np.bincount(y_train)[1]/np.bincount(y_train)[0]))\n",
    "    #print('Labels counts in y_test:', np.bincount(y_test), (np.bincount(y_test)[1]/np.bincount(y_test)[0]))\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_resampled)\n",
    "    X_train_std = ss.transform(X_resampled)\n",
    "    X_test_std = ss.transform(X_test)\n",
    "    \n",
    "\n",
    "                \n",
    "    model.fit(X_train_std, y_resampled)\n",
    "    pred = model.predict(X_test_std)\n",
    "    #prob = clf.predict_proba(X_test_std)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "        \n",
    "    return accuracy, recall, precision, f1, pred, y_test\n",
    "    \n",
    "    \n",
    "def preprocessing_features(df, features):\n",
    "    \n",
    "    \"Getting ready the features for the model\"\n",
    "    \n",
    "    data = df[features].copy()\n",
    "    data.reset_index(inplace=True)\n",
    "    for item in features:\n",
    "        if data[item].dtypes == 'object':\n",
    "            #print(item, data[item].dtypes)\n",
    "            prova = pd.get_dummies(data[item], drop_first=True)\n",
    "            data = pd.concat([data,prova], axis=1)\n",
    "            data.drop(item, axis=1, inplace=True)\n",
    "\n",
    "    features_array = np.array(data)\n",
    "    \n",
    "    return features_array    \n",
    "\n",
    "\n",
    "def selecting_model_oversampling(train,test, features, model):\n",
    "    \n",
    "    train.majority = train[train.victims_alert == 0]\n",
    "    train.minority = train[train.victims_alert == 1]\n",
    "\n",
    "    train_minority_upsampled = resample(train_minority, \n",
    "                                     replace=True,     # sample with replacement\n",
    "                                     n_samples=len(train_majority),    # to match majority class\n",
    "                                     random_state=1) # reproducible results\n",
    "\n",
    "    train_upsampled = pd.concat([train_majority, train_minority_upsampled])\n",
    "\n",
    "    y = train_upsampled.victims_alert\n",
    "    X = preprocessing_features(train_upsampled, features)\n",
    "    y_test = test.victims_alert\n",
    "    X_test = preprocessing_features(test, features)\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X)\n",
    "    X_train_std = ss.transform(X)\n",
    "    X_test_std = ss.transform(X_test)       \n",
    "    clf = model.fit(X_train_std, y)\n",
    "    pred = clf.predict(X_test_std)\n",
    "    \n",
    "    return pred, y_test\n",
    "    \n",
    "    \n",
    "def selecting_model_downsampling(train,test, features, model):\n",
    "    \n",
    "    train.majority = train[train.victims_alert == 0]\n",
    "    train.minority = train[train.victims_alert == 1]\n",
    "\n",
    "    train_majority_downsampled = resample(train_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=len(train_minority),     # to match minority class\n",
    "                                 random_state=1) # reproducible results\n",
    "\n",
    "    train_downsampled = pd.concat([train_minority, train_majority_downsampled])\n",
    "    \n",
    "    y = train_downsampled.victims_alert\n",
    "    X = preprocessing_features(train_downsampled, features)\n",
    "    y_test = test.victims_alert\n",
    "    X_test = preprocessing_features(test, features)\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X)\n",
    "    X_train_std = ss.transform(X)\n",
    "    X_test_std = ss.transform(X_test)       \n",
    "    clf = model.fit(X_train_std, y)\n",
    "    pred = clf.predict(X_test_std)\n",
    "    \n",
    "    return pred, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Values to keep all the time\n",
    "metrics = ['recall', 'precision', 'f1_score', 'roc_auc', 'accuracy']\n",
    "random_state = 1\n",
    "baseline = 1 - df['victims_alert'].sum()/df.shape[0]\n",
    "\n",
    "features = []\n",
    "pickle_files = ['accuracy_features.pkl', 'f1_features.pkl',\\\n",
    "                'precision_features.pkl', 'recall_features.pkl']\n",
    "\n",
    "dict_features = {}\n",
    "count = 0\n",
    "for item in pickle_files:\n",
    "    \n",
    "    with open(item, 'rb') as f:\n",
    "        list_features = pickle.load(f)\n",
    "        count = count + len(list_features)\n",
    "        dict_features[item[0:-4]] = count\n",
    "        dict_features[item[0:-4] + \"_list\"] = list_features\n",
    "\n",
    "    for i in list_features:\n",
    "        features.append(i)\n",
    "dict_features.keys(), metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {'log_reg': {'name': LogisticRegression(C= 100, random_state=random_state)},\n",
    "'forest':{'name': RandomForestClassifier(class_weight='balanced', max_depth=5, n_estimators=10, max_features=1, random_state=random_state)}, \n",
    "'gbc': {'name': GradientBoostingClassifier(random_state=random_state, learning_rate=0.01)},\n",
    "       'linearsvc':{'name': LinearSVC(C=1.0, random_state=random_state, class_weight='balanced')},\\\n",
    "              'Perceptron': {'name': Perceptron(class_weight='balanced', random_state=random_state)},\n",
    "              'MLPClassifier': {'name': MLPClassifier(random_state=random_state)}}\n",
    "for i in models_dict.keys():\n",
    "    print(models_dict[i]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Try with different models\n",
    "metrics = ['recall', 'precision', 'f1_score', 'roc_auc', 'accuracy']\n",
    "for key in models_dict.keys():\n",
    "    models_dict[key].update({key: None for key in metrics}) \n",
    "\n",
    "\n",
    "for key in models_dict.keys():\n",
    "    \n",
    "    accuracies = []\n",
    "    recalls =[]\n",
    "    precisions = []\n",
    "    f1s = []\n",
    "    roc_aucs = []\n",
    "    count = 0\n",
    "    for i in features:\n",
    "        \n",
    "        count = count + 1\n",
    "        a, r, p, f, pred, y_test = selecting_model(df,target, i, models_dict[key]['name'])\n",
    "        \n",
    "        accuracies.append(a)\n",
    "        recalls.append(r)\n",
    "        precisions.append(p)\n",
    "        f1s.append(f)\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        roc_aucs.append(roc_auc)\n",
    "        if count%10 == 0:\n",
    "            print(count)\n",
    "        \n",
    "    models_dict[key]['accuracy'] = accuracies\n",
    "    models_dict[key]['recall'] = recalls\n",
    "    models_dict[key]['precision'] = precisions\n",
    "    models_dict[key]['f1_score'] = f1s\n",
    "    models_dict[key]['roc_auc'] = roc_aucs\n",
    "    print(key)\n",
    "with open('dictionary_models.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(models_dict, picklefile)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dictionary_models.pkl', 'rb') as f:\n",
    "    models_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_models_and_metrics(n_rows, n_columns, name_metric):\n",
    "\n",
    "    fig, ax = plt.subplots(n_rows,n_columns, figsize=(10,10))\n",
    "    x_axis = [x for x in range(1, len(models_dict[key][name_metric]) + 1)]\n",
    "    models = [y for y in models_dict.keys()]\n",
    "    count = 0\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(2):\n",
    "\n",
    "            ax[i, j].plot(x_axis, models_dict[models[count]][name_metric])\n",
    "            ax[i, j].legend([models[count]])\n",
    "            count = count + 1\n",
    "    fig.suptitle(name_metric.title(), fontsize=15); # or plt.suptitle('Main title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name_metric in metrics:\n",
    "    n_rows = 3\n",
    "    n_columns = 2\n",
    "    #name_metric = 'accuracy'\n",
    "\n",
    "    plotting_models_and_metrics(n_rows, n_columns, name_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in models_dict.keys():\n",
    "    \n",
    "    x_axis = [x for x in range(1, len(models_dict[key]['recall']) + 1)]\n",
    "    plt.plot(x_axis,models_dict[key]['recall']);\n",
    "    plt.title('Recall')\n",
    "plt.legend(models_dict.keys());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in models_dict.keys():\n",
    "    \n",
    "    x_axis = [x for x in range(1, len(models_dict[key]['precision']) + 1)]\n",
    "    plt.plot(x_axis,models_dict[key]['precision']);\n",
    "    plt.title('Precision')\n",
    "plt.legend(models_dict.keys());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in models_dict.keys():\n",
    "    \n",
    "    x_axis = [x for x in range(1, len(models_dict[key]['f1_score']) + 1)]\n",
    "    plt.plot(x_axis,models_dict[key]['f1_score']);\n",
    "    plt.title('F1 Score')\n",
    "plt.legend(models_dict.keys());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in models_dict.keys():\n",
    "    \n",
    "    x_axis = [x for x in range(1, len(models_dict[key]['roc_auc']) + 1)]\n",
    "    plt.plot(x_axis,models_dict[key]['roc_auc']);\n",
    "    plt.title('Roc auc')\n",
    "plt.legend(models_dict.keys());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see the high per metric\n",
    "maxims = {}\n",
    "\n",
    "for item in metrics:\n",
    "    maxims[item] = [0, '']\n",
    "    \n",
    "    \n",
    "for key in models_dict.keys():\n",
    "    \n",
    "    print('Accuracy: ', key,max(models_dict[key]['accuracy']))\n",
    "    print(\"Recall: \", key, max(models_dict[key]['recall']))\n",
    "    for metric in metrics:\n",
    "        \n",
    "        if max(models_dict[key][metric]) >= maxims[metric][0]:\n",
    "            maxims[metric][0] = round(max(models_dict[key][metric]),6)\n",
    "            maxims[metric][1] = key\n",
    "    \n",
    "maxims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models_dict[maxims['roc_auc'][1]]['roc_auc'] = [round(x,6) for x in models_dict[maxims['roc_auc'][1]]['roc_auc']]\n",
    "fea_index = models_dict[maxims['roc_auc'][1]]['roc_auc'].index(maxims['roc_auc'][0])\n",
    "\n",
    "a, r, p, f1, pred, y_test = selecting_model(df, target, features[fea_index], models_dict[maxims['roc_auc'][1]]['name'])\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Analyzing best Roc_auc\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "fn\n",
    "\n",
    "from sklearn.metrics import auc, precision_recall_curve, average_precision_score\n",
    "fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area ={})'.format(round(roc_auc, 4)))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "print(\"Flase Negatives: \", fn)\n",
    "print(\"Amount of ones predicted: \", pred.sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run it the first time only\n",
    "msk = np.random.rand(len(df)) < 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Oversampling minority\n",
    "\n",
    "with open('mask.pkl', 'rb') as f:\n",
    "    msk = pickle.load(f)\n",
    "\n",
    "#msk = np.random.rand(len(df)) < 0.75\n",
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "    \n",
    "\n",
    "train_majority = train[train.victims_alert==0]\n",
    "\n",
    "train_minority = train[train.victims_alert==1]\n",
    " \n",
    "# Upsample minority class\n",
    "train_minority_upsampled = resample(train_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(train_majority),    # to match majority class\n",
    "                                 random_state=1) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "train_upsampled = pd.concat([train_majority, train_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "train_upsampled.victims_alert.value_counts()\n",
    "\n",
    "\"\"\"y = train_upsampled.victims_alert\n",
    "X = preprocessing_features(train_upsampled, features[10])\n",
    "y_test = test.victims_alert\n",
    "X_test = preprocessing_features(test, features[10]) \"\"\"\n",
    "models_dict_oversampling = {key: None for key in models_dict.keys()}\n",
    "\n",
    "\n",
    "for key in models_dict_oversampling.keys():\n",
    "    models_dict_oversampling[key] = {key: None for key in metrics}\n",
    "\n",
    "\n",
    "\n",
    "for key in models_dict.keys():\n",
    "    \n",
    "    print(key)\n",
    "    accuracies = []\n",
    "    recalls = []\n",
    "    precisions = []\n",
    "    f1s = []\n",
    "    roc_aucs = []\n",
    "    count = 0\n",
    "    \n",
    "    for i in features:\n",
    "        \n",
    "        count = count + 1\n",
    "        y = train_upsampled.victims_alert\n",
    "        X = preprocessing_features(train_upsampled, i)\n",
    "        y_test = test.victims_alert\n",
    "        X_test = preprocessing_features(test, i)\n",
    "        ss = StandardScaler()\n",
    "        ss.fit(X)\n",
    "        X_train_std = ss.transform(X)\n",
    "        X_test_std = ss.transform(X_test)          \n",
    "        clf = models_dict[key]['name'].fit(X_train_std, y)\n",
    "        pred = clf.predict(X_test_std)\n",
    "        accuracy = accuracy_score(y_test, pred)\n",
    "        recall = recall_score(y_test,pred)\n",
    "        f1 = f1_score(y_test, pred)\n",
    "        precision = precision_score(y_test,pred)\n",
    "        accuracies.append(accuracy)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        f1s.append(f1)\n",
    "        fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        roc_aucs.append(roc_auc)\n",
    "        if count%10 == 0:\n",
    "            print(count)\n",
    "        \n",
    "    models_dict_oversampling[key]['accuracy'] = accuracies\n",
    "    models_dict_oversampling[key]['recall'] = recalls\n",
    "    models_dict_oversampling[key]['precision'] = precisions\n",
    "    models_dict_oversampling[key]['f1_score'] = f1s\n",
    "    models_dict_oversampling[key]['roc_auc'] = roc_aucs\n",
    "with open('mask.pkl', 'wb') as f:\n",
    "    pickle.dump(msk, f)\n",
    "with open('oversampling_models.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(models_dict_oversampling, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('oversampling_models.pkl', 'rb') as picklefile:\n",
    "    models_dict_oversampling = pickle.load(picklefile)\n",
    "models_dict_oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxims_oversampling = {}\n",
    "for item in metrics:\n",
    "    maxims_oversampling[item] = [0, '']\n",
    "    \n",
    "    \n",
    "for key in models_dict_oversampling.keys():\n",
    "    \n",
    "    print('Accuracy: ', key,max(models_dict_oversampling[key]['accuracy']))\n",
    "    print(\"Recall: \", key, max(models_dict_oversampling[key]['recall']))\n",
    "    for metric in metrics:\n",
    "        \n",
    "        if metric != 'recall':\n",
    "        \n",
    "            if max(models_dict_oversampling[key][metric]) >= maxims_oversampling[metric][0]:\n",
    "                maxims_oversampling[metric][0] = round(max(models_dict_oversampling[key][metric]),6)\n",
    "                maxims_oversampling[metric][1] = key\n",
    "        else:\n",
    "            if (max(models_dict_oversampling[key][metric]) >= maxims_oversampling[metric][0]) and (max(models_dict_oversampling[key][metric]) < 1):\n",
    "                maxims_oversampling[metric][0] = round(max(models_dict_oversampling[key][metric]),6)\n",
    "                maxims_oversampling[metric][1] = key\n",
    "maxims_oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Analyzingthe best roc_auc\n",
    "\n",
    "models_dict_oversampling[maxims_oversampling['roc_auc'][1]]['roc_auc'] = [round(x,6) for x in models_dict_oversampling[maxims_oversampling['roc_auc'][1]]['roc_auc']]\n",
    "fea_index = models_dict_oversampling[maxims_oversampling['roc_auc'][1]]['roc_auc'].index(maxims_oversampling['roc_auc'][0])\n",
    "\n",
    "pred, y_test = selecting_model_oversampling(train, test, features[fea_index], models_dict[maxims_oversampling['roc_auc'][1]]['name'])\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Recall: \", recall_score(y_test, pred),  \"ROC-AUC: \", roc_auc)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area ={})'.format(round(roc_auc, 4)))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "print(\"Flase Negatives: \", fn)\n",
    "print(\"Amount of ones predicted: \", pred.sum()/len(y_test))\n",
    "print(\"Features: \", features[fea_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Analyzingthe best recall\n",
    "to_consider = 'recall'\n",
    "models_dict_oversampling[maxims_oversampling[to_consider][1]][to_consider] = [round(x,6) for x in models_dict_oversampling[maxims_oversampling[to_consider][1]][to_consider]]\n",
    "fea_index = models_dict_oversampling[maxims_oversampling[to_consider][1]][to_consider].index(maxims_oversampling[to_consider][0])\n",
    "\n",
    "pred, y_test = selecting_model_oversampling(train, test, features[fea_index], models_dict[maxims_oversampling[to_consider][1]]['name'])\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Recall: \", recall_score(y_test, pred),  \"ROC-AUC: \", roc_auc)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area ={})'.format(round(roc_auc, 4)))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "print(\"Flase Negatives: \", fn)\n",
    "print(\"Amount of ones predicted: \", pred.sum()/len(y_test))\n",
    "print(\"Features: \", features[fea_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Downsampling\n",
    "\n",
    "train_majority_downsampled = resample(train_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=len(train_minority),     # to match minority class\n",
    "                                 random_state=1) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "train_downsampled = pd.concat([train_majority_downsampled, train_minority])\n",
    " \n",
    "# Display new class counts\n",
    "\n",
    "models_dict_downsampling = {key: None for key in models_dict.keys()}\n",
    "\n",
    "\n",
    "for key in models_dict_downsampling.keys():\n",
    "    models_dict_downsampling[key] = {key: None for key in metrics}\n",
    "\n",
    "\n",
    "\n",
    "for key in models_dict.keys():\n",
    "    \n",
    "    print(key)\n",
    "    accuracies = []\n",
    "    recalls =[]\n",
    "    precisions = []\n",
    "    f1s = []\n",
    "    roc_aucs = []\n",
    "    count = 0\n",
    "    \n",
    "    for i in features:\n",
    "        \n",
    "        count = count + 1\n",
    "        y = train_downsampled.victims_alert\n",
    "        X = preprocessing_features(train_downsampled, i)\n",
    "        y_test = test.victims_alert\n",
    "        X_test = preprocessing_features(test, i)\n",
    "        ss = StandardScaler()\n",
    "        ss.fit(X)\n",
    "        X_train_std = ss.transform(X)\n",
    "        X_test_std = ss.transform(X_test)          \n",
    "        clf = models_dict[key]['name'].fit(X_train_std, y)\n",
    "        pred = clf.predict(X_test_std)\n",
    "        accuracy = accuracy_score(y_test, pred)\n",
    "        recall = recall_score(y_test,pred)\n",
    "        f1 = f1_score(y_test, pred)\n",
    "        precision = precision_score(y_test,pred)\n",
    "        accuracies.append(accuracy)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        f1s.append(f1)\n",
    "        fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        roc_aucs.append(roc_auc)\n",
    "        if count%10 == 0:\n",
    "            print(count)\n",
    "        \n",
    "        \n",
    "    models_dict_downsampling[key]['accuracy'] = accuracies\n",
    "    models_dict_downsampling[key]['recall'] = recalls\n",
    "    models_dict_downsampling[key]['precision'] = precisions\n",
    "    models_dict_downsampling[key]['f1_score'] = f1s\n",
    "    models_dict_downsampling[key]['roc_auc'] = roc_aucs\n",
    "    \n",
    "with open('downsampling_models.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(models_dict_downsampling, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('downsampling_models.pkl', 'rb') as picklefile:\n",
    "    models_dict_downsampling = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxims_downsampling = {}\n",
    "\n",
    "for item in metrics:\n",
    "    maxims_downsampling[item] = [0, '']\n",
    "    \n",
    "    \n",
    "for key in models_dict_downsampling.keys():\n",
    "    \n",
    "    print('Accuracy: ', key,max(models_dict_downsampling[key]['accuracy']))\n",
    "    print(\"Recall: \", key, max(models_dict_downsampling[key]['recall']))\n",
    "    for metric in metrics:\n",
    "        \n",
    "        if max(models_dict_downsampling[key][metric]) >= maxims_downsampling[metric][0]:\n",
    "            maxims_downsampling[metric][0] = round(max(models_dict_downsampling[key][metric]),6)\n",
    "            maxims_downsampling[metric][1] = key\n",
    "    \n",
    "maxims_downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Analyzingthe best roc_auc\n",
    "to_consider = 'roc_auc'\n",
    "models_dict_downsampling[maxims_downsampling[to_consider][1]][to_consider] = [round(x,6) for x in models_dict_downsampling[maxims_downsampling[to_consider][1]][to_consider]]\n",
    "fea_index = models_dict_downsampling[maxims_downsampling[to_consider][1]][to_consider].index(maxims_downsampling[to_consider][0])\n",
    "\n",
    "pred, y_test = selecting_model_downsampling(train, test, features[fea_index], models_dict[maxims_downsampling[to_consider][1]]['name'])\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Recall: \", recall_score(y_test, pred),  \"ROC-AUC: \", roc_auc)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area ={})'.format(round(roc_auc, 4)))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "print(\"Flase Negatives: \", fn)\n",
    "print(\"Amount of ones predicted: \", pred.sum()/len(y_test))\n",
    "print(\"Features: \", features[fea_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Analyzingthe best recall\n",
    "to_consider = 'recall'\n",
    "\n",
    "models_dict_downsampling[maxims_downsampling[to_consider][1]][to_consider] = [round(x,6) for x in models_dict_downsampling[maxims_downsampling[to_consider][1]][to_consider]]\n",
    "fea_index = models_dict_downsampling[maxims_downsampling[to_consider][1]][to_consider].index(maxims_downsampling[to_consider][0])\n",
    "\n",
    "pred, y_test = selecting_model_downsampling(train, test, features[fea_index], models_dict[maxims_downsampling[to_consider][1]]['name'])\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Recall: \", recall_score(y_test, pred),  \"ROC-AUC: \", roc_auc)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area ={})'.format(round(roc_auc, 4)))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "print(\"Flase Negatives: \", fn)\n",
    "print(\"Amount of ones predicted: \", pred.sum()/len(y_test))\n",
    "print(\"Features: \", features[fea_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.fixes import signature\n",
    "average_precision = average_precision_score(y_test, pred)\n",
    "precision, recall, _ = precision_recall_curve(y_test, pred)\n",
    "\n",
    "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Sensitive Analysis\n",
    "## Next steps: add smote to costcla\n",
    "### try Bayes method\n",
    "### try QuadraticDiscriminantAnalysis and Fuzzy SVM\n",
    "### Introduce cross validationa as mentioned in a youtube video\n",
    "### class_weight is your friend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.DataFrame(pd.Series(df.victims_alert).value_counts())\n",
    "obj['Percentage'] = obj['victims_alert']/obj['victims_alert'].sum()\n",
    "obj.index = ['Negative (No deaths nor severely injured)', 'Positive (Deaths and/or severely injured)']\n",
    "obj.rename(columns = {'victims_alert':'Frequency'}, inplace=True)\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova_features = preprocessing_features(df, features[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparing_X_and_y(dataframe, features, target):\n",
    "    \n",
    "    \n",
    "    data = dataframe[features].copy()\n",
    "    data.reset_index(inplace=True)\n",
    "    for item in features:\n",
    "        if data[item].dtypes == 'object':\n",
    "            prova = pd.get_dummies(data[item], drop_first=True)\n",
    "            data = pd.concat([data,prova], axis=1)\n",
    "            data.drop(item, axis=1, inplace=True)\n",
    "            \n",
    "    X = np.array(data)\n",
    "    y = dataframe[target]\n",
    "    y = (np.where (y > 0, 1, 0))\n",
    "    y = np.reshape(y, len(y))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1, stratify=y)\n",
    "    \n",
    "    \n",
    "    X_resampled, y_resampled = SMOTE(ratio=0.3, random_state=2018).fit_sample(X_train, y_train)\n",
    "\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_resampled)\n",
    "    X_train_std = ss.transform(X_resampled)\n",
    "    X_test_std = ss.transform(X_test)\n",
    "    \n",
    "    return X_train_std, X_test_std, y_resampled, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = preparing_X_and_y(df, features[37], target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_mat[:, 0] = false_positive_cost\n",
    "cost_mat[:, 1] = false_negative_cost\n",
    "cost_mat[:, 2] = true_positive_cost\n",
    "cost_mat[:, 3] = true_negative_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FP, FN, TP, TN\n",
    "costs = [1,20, -1, 0]\n",
    "cost_mat = np.zeros((df.shape[0], 4))\n",
    "cost_mat_train = np.zeros((X_train.shape[0], 4))\n",
    "cost_mat_test = np.zeros((X_test.shape[0], 4))\n",
    "for i in range(0,4):\n",
    "    cost_mat[:, i] = costs[i] ##FP\n",
    "    cost_mat_train[:, i] = costs[i]    \n",
    "    cost_mat_test[:, i] = costs[i]     \n",
    "###Cost all zeros\n",
    "cost_all_zeros = cost_loss(y_test, np.zeros(len(y_test)), cost_mat_test)\n",
    "###\n",
    "cost_all_ones = cost_loss(y_test, np.ones(len(y_test)), cost_mat_test)\n",
    "cost_to_beat = min(cost_all_ones, cost_all_zeros)\n",
    "print(\"all zeros: \", cost_all_zeros)\n",
    "print(\"all ones: \", cost_all_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict_cs = {'log_reg': {'F': LogisticRegression(C= 100, random_state=random_state)},\n",
    "'forest':{'F': RandomForestClassifier(class_weight='balanced', max_depth=5, n_estimators=10, max_features=1, random_state=random_state)}, \n",
    "'gbc': {'F': GradientBoostingClassifier(random_state=random_state, learning_rate=0.01)},\n",
    "       'linearsvc':{'F': LinearSVC(C=1.0, random_state=random_state, class_weight='balanced')},\\\n",
    "              'Perceptron': {'F': Perceptron(class_weight='balanced', random_state=random_state)},\n",
    "              'MLPClassifier': {'F': MLPClassifier(random_state=random_state)}}\n",
    "measures = {\"f1_score\": f1_score, \"precision\": precision_score, \n",
    "            \"recall\": recall_score, \"accuracy\": accuracy_score, 'roc_auc': roc_auc_score,\\\n",
    "           'savings': savings_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding savings as a metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resultats = pd.DataFrame(columns=measures.keys())\n",
    "\n",
    "for key in models_dict_cs.keys():\n",
    "    \n",
    "    print(key)\n",
    "    accuracies = []\n",
    "    recalls =[]\n",
    "    precisions = []\n",
    "    f1s = []\n",
    "    roc_aucs = []\n",
    "    savings = []\n",
    "    \n",
    "    \n",
    "    for i in features:\n",
    "\n",
    "        X_train, X_test, y_train, y_test = preparing_X_and_y(df, i, target)\n",
    "    \n",
    "        clf = models_dict_cs[key]['F'].fit(X_train, y_train)\n",
    "    \n",
    "        pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, pred)\n",
    "        recall = recall_score(y_test,pred)\n",
    "        f1 = f1_score(y_test, pred)\n",
    "        precision = precision_score(y_test,pred)\n",
    "        accuracies.append(accuracy)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        f1s.append(f1)\n",
    "        fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        roc_aucs.append(roc_auc)\n",
    "        ###define clas_mat_test\n",
    "        \n",
    "        cost_mat_test = np.zeros((X_test.shape[0], 4))\n",
    "        for i in range(0,4):\n",
    "            cost_mat_test[:, i] = costs[i]   \n",
    "        saving = savings_score(y_test, pred, cost_mat_test)\n",
    "        savings.append(saving)\n",
    "    \n",
    "        \n",
    "    models_dict_cs[key]['accuracy'] = accuracies\n",
    "    models_dict_cs[key]['recall'] = recalls\n",
    "    models_dict_cs[key]['precision'] = precisions\n",
    "    models_dict_cs[key]['f1_score'] = f1s\n",
    "    models_dict_cs[key]['roc_auc'] = roc_aucs\n",
    "    models_dict_cs[key]['savings'] = savings\n",
    "    \n",
    "with open('cs_models.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(models_dict_cs, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cs_models.pkl', 'rb') as picklefile:\n",
    "    models_dict_cs = pickle.load(picklefile)\n",
    "    \n",
    "models_dict_cs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxims_cs = {}\n",
    "\n",
    "for item in measures:\n",
    "    maxims_cs[item] = [0, ['']]\n",
    "    \n",
    "    \n",
    "for key in models_dict_cs.keys():\n",
    "    for subkey in models_dict_cs[key].keys():\n",
    "        if subkey != 'F':\n",
    "    \n",
    "            print(key, subkey, max(models_dict_cs[key][subkey]), sum(models_dict_cs[key][subkey])/len(models_dict_cs[key][subkey]))\n",
    "    for measure in measures:\n",
    "        \n",
    "        if max(models_dict_cs[key][measure]) > maxims_cs[measure][0]:\n",
    "            maxims_cs[measure][0] = round(max(models_dict_cs[key][measure]),6)\n",
    "            ##add models here\n",
    "            maxims_cs[measure][1] = [key]\n",
    "        elif max(models_dict_cs[key][measure]) == maxims_cs[measure][0]:\n",
    "            maxims_cs[measure][1].append(key)\n",
    "            \n",
    "    \n",
    "maxims_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Investigating maxim precision\n",
    "models_dict_cs['log_reg']['precision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_consider = 'precision'\n",
    "model = maxims_cs[to_consider][1][0]\n",
    "print(model)\n",
    "models_dict_cs[model][to_consider] = [round(x,6) for x in models_dict_cs[model][to_consider]]\n",
    "fea_index = models_dict_cs[model][to_consider].index(maxims_cs[to_consider][0])\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = preparing_X_and_y(df, features[fea_index], target)\n",
    "    \n",
    "clf = models_dict_cs[model]['F'].fit(X_train, y_train)\n",
    "    \n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Recall: \", recall_score(y_test, pred),  \"ROC-AUC: \", roc_auc)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area ={})'.format(round(roc_auc, 4)))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "print(\"Flase Negatives: \", fn)\n",
    "print(\"Amount of ones predicted: \", pred.sum()/len(y_test))\n",
    "print(\"Features: \", features[fea_index])\n",
    "print(to_consider, savings_score(y_test,pred, cost_mat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats_cs = pd.DataFrame(columns=measures.keys())\n",
    "\n",
    "\n",
    "for model in models_dict_cs.keys():\n",
    " \n",
    "    resultats_cs.loc[model] = [sum(models_dict_cs[model][measure])/len(models_dict_cs[model][measure])\\\n",
    "                               for measure in measures.keys()]\n",
    "    \n",
    "resultats_cs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Bayes Minimum Risk Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict_bmr = {'log_reg': {'F': LogisticRegression(C= 100, random_state=random_state)},\n",
    "'forest':{'F': RandomForestClassifier(class_weight='balanced', max_depth=5, n_estimators=10, max_features=1, random_state=random_state)}, \n",
    "'gbc': {'F': GradientBoostingClassifier(random_state=random_state, learning_rate=0.01)},\n",
    "       'svc':{'F': SVC(C=1.0, random_state=random_state, class_weight='balanced', probability=True)},\n",
    "              'MLPClassifier': {'F': MLPClassifier(random_state=random_state)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = {\"f1_score\": f1_score, \"precision\": precision_score, \n",
    "            \"recall\": recall_score, \"accuracy\": accuracy_score, 'roc_auc': roc_auc_score,\\\n",
    "           \"savings\": savings_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculating_metrics(mydict,features):\n",
    "\n",
    "    for key in mydict.keys():\n",
    "\n",
    "        print(key)\n",
    "        accuracies = []\n",
    "        recalls =[]\n",
    "        precisions = []\n",
    "        f1s = []\n",
    "        roc_aucs = []\n",
    "        savings = []\n",
    "\n",
    "\n",
    "        for i in features:\n",
    "\n",
    "            X_train, X_test, y_train, y_test = preparing_X_and_y(df, i, target)\n",
    "\n",
    "            clf = mydict[key]['F'].fit(X_train, y_train)\n",
    "\n",
    "            pred = clf.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, pred)\n",
    "            recall = recall_score(y_test,pred)\n",
    "            f1 = f1_score(y_test, pred)\n",
    "            precision = precision_score(y_test,pred)\n",
    "            accuracies.append(accuracy)\n",
    "            recalls.append(recall)\n",
    "            precisions.append(precision)\n",
    "            f1s.append(f1)\n",
    "            fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "            roc_auc = roc_auc_score(y_test,pred)\n",
    "            roc_aucs.append(roc_auc)\n",
    "            ###define clas_mat_test\n",
    "\n",
    "            cost_mat_test = np.zeros((X_test.shape[0], 4))\n",
    "            for i in range(0,4):\n",
    "                cost_mat_test[:, i] = costs[i]   \n",
    "            saving = savings_score(y_test, pred, cost_mat_test)\n",
    "            savings.append(saving)\n",
    "\n",
    "\n",
    "        mydict[key]['accuracy'] = accuracies\n",
    "        mydict[key]['recall'] = recalls\n",
    "        mydict[key]['precision'] = precisions\n",
    "        mydict[key]['f1_score'] = f1s\n",
    "        mydict[key]['roc_auc'] = roc_aucs\n",
    "        mydict[key]['savings'] = savings\n",
    "\n",
    "    with open(mydict + 'mydict.pkl', 'wb') as picklefile:\n",
    "        pickle.dump(mydict, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmr_features = dict_features['recall_features_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_dict_bmr = calculating_metrics(models_dict_bmr, bmr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models_dict_bmr.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(models_dict_bmr, picklefile )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_dict_maxims(mydict,measures):\n",
    "\n",
    "    maxims = {}\n",
    "\n",
    "    for item in measures:\n",
    "        maxims[item] = [0, ['']]\n",
    "    \n",
    "    \n",
    "    for key in mydict.keys():\n",
    "    \n",
    "        print('Accuracy: ', key,max(mydict[key]['accuracy']))\n",
    "        print(\"Recall: \", key, max(mydict[key]['recall']))\n",
    "        print(\"Roc_auc: \", key, max(mydict[key]['roc_auc']))\n",
    "        for measure in measures:\n",
    "        \n",
    "            if max(mydict[key][measure]) > maxims[measure][0]:\n",
    "                maxims[measure][0] = round(max(mydict[key][measure]),6)\n",
    "                \n",
    "                maxims[measure][1] = [key]\n",
    "            elif max(mydict[key][measure]) == maxims[measure][0]:\n",
    "                maxims[measure][1].append(key)\n",
    "                \n",
    "    return maxims\n",
    "            \n",
    "    \n",
    "maxims_bmr = creating_dict_maxims(models_dict_bmr, measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Bayes Minimum Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preparing_X_and_y(df, features[41], target)\n",
    "\n",
    "for model in models_dict_bmr.keys():\n",
    "    print(model)\n",
    "    # Fit\n",
    "    models_dict_bmr[model][\"F\"].fit(X_train, y_train)\n",
    "    # Predict\n",
    "    models_dict_bmr[model][\"c\"] = models_dict_bmr[model][\"F\"].predict(X_test)\n",
    "    models_dict_bmr[model][\"p\"] = models_dict_bmr[model][\"F\"].predict_proba(X_test)\n",
    "    #models_dict_bmr[model][\"p_train\"] = models_dict_bmr[model][\"F\"].predict_proba(X_train)\n",
    "models_dict_bmr.keys()\n",
    "\n",
    "with open('models_dict_bmr.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(models_dict_bmr, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models_dict_bmr.pkl', 'rb') as picklefile:\n",
    "    models_dict_bmr = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtaining_resultats(mydict, measures):\n",
    "    \n",
    "    \n",
    "    resultats = pd.DataFrame(columns=measures.keys())\n",
    "    \n",
    "    for model in mydict.keys():\n",
    " \n",
    "        resultats.loc[model] = [measures[measure](y_test, mydict[model][\"c\"]) if measure != 'savings' else measures[measure](y_test, models_dict_bmr[model][\"c\"], cost_mat_test)\\\n",
    " for measure in measures.keys()]\n",
    "    \n",
    "    return resultats\n",
    "\n",
    "resultats_bmr = obtaining_resultats(models_dict_bmr, measures)\n",
    "\n",
    "resultats_bmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del models_dict_bmr['CSDT']\n",
    "models_dict_bmr.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for model in list(models_dict_bmr):\n",
    "    models_dict_bmr[model+\"-BMR\"] = {\"F\": BayesMinimumRiskClassifier()}\n",
    "    # Fit\n",
    "    models_dict_bmr[model+\"-BMR\"][\"F\"].fit(y_test, models_dict_bmr[model][\"p\"])  \n",
    "    # Calibration must be made in a validation set\n",
    "    # Predict\n",
    "    models_dict_bmr[model+\"-BMR\"][\"c\"] = models_dict_bmr[model+\"-BMR\"][\"F\"].predict(models_dict_bmr[model][\"p\"], cost_mat_test)\n",
    "    # Evaluate\n",
    "    resultats_bmr.loc[model+\"-BMR\"] = 0\n",
    "    resultats_bmr.loc[model+\"-BMR\", measures.keys()] = \\\n",
    "    [measures[measure](y_test, models_dict_bmr[model+\"-BMR\"][\"c\"]) if measure != 'savings' else measures[measure](y_test, models_dict_bmr[model][\"c\"], cost_mat_test)\\\n",
    " for measure in measures.keys()]    \n",
    "resultats_bmr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Adding costcla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from costcla.models import CostSensitiveDecisionTreeClassifier, CostSensitiveLogisticRegression, CostSensitiveRandomForestClassifier\n",
    " \n",
    "    \n",
    "models_dict_bmr[\"CSDT\"] = {\"F\": CostSensitiveDecisionTreeClassifier(criterion_weight='balanced')}\n",
    "models_dict_bmr['CS-LR'] = {\"F\": CostSensitiveLogisticRegression(random_state=random_state)}\n",
    "models_dict_bmr['CSRC'] = {\"F\": CostSensitiveRandomForestClassifier(combination=\"weighted_voting\")}\n",
    "for i in ['CSDT', \"CS-LR\", 'CSRC']:\n",
    "    # Fit\n",
    "    models_dict_bmr[i][\"F\"].fit(X_train, y_train, cost_mat_train)\n",
    "    # Predict\n",
    "    models_dict_bmr[i][\"c\"] = models_dict_bmr[key][\"F\"].predict(X_test)\n",
    "    # Evaluate\n",
    "    resultats_bmr.loc[i] = 0\n",
    "    resultats_bmr.loc[i, measures.keys()] = \\\n",
    "    [measures[measure](y_test, models_dict_bmr[i][\"c\"]) if measure != 'savings' else measures[measure](y_test, models_dict_bmr[i][\"c\"], cost_mat_test)\\\n",
    "     for measure in measures.keys()]  \n",
    "    #[measures[measure](y_test, classifiers[\"CSRP\"][\"c\"]) for measure in measures.keys()]    \n",
    "print(resultats_bmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ThresholdingOptimization\n",
    "\n",
    "# One soluntion via Bayes following guy in internet and one singular set of features\n",
    "\n",
    "# Finalize it with Fuzzy SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats[\"sav\"] = np.zeros(resultats.shape[0])\n",
    "for model in models_dict_cs.keys():\n",
    "    resultats[\"sav\"].loc[model] = (savings_score(y_test, models_dict_cs[model][\"class\"], cost_mat_test))\n",
    "resultats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\"RF\": {\"f\": RandomForestClassifier(random_state=random_state)},\n",
    "               \"DT\": {\"f\": DecisionTreeClassifier(random_state=random_state)},\n",
    "               \"LR\": {\"f\": LogisticRegression(random_state=random_state)}}\n",
    "\n",
    "for model in classifiers.keys():\n",
    "    # Fit\n",
    "    classifiers[model][\"f\"].fit(X_train, y_train)\n",
    "    # Predict\n",
    "    classifiers[model][\"c\"] = classifiers[model][\"f\"].predict(X_test)\n",
    "    classifiers[model][\"p\"] = classifiers[model][\"f\"].predict_proba(X_test)\n",
    "    classifiers[model][\"p_train\"] = classifiers[model][\"f\"].predict_proba(X_train)\n",
    "classifiers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = {\"f1\": f1_score, \"pre\": precision_score, \n",
    "            \"rec\": recall_score, \"acc\": accuracy_score, 'roc_auc': roc_auc_score}\n",
    "results = pd.DataFrame(columns=measures.keys())\n",
    "\n",
    "# Evaluate each model in classifiers\n",
    "for model in classifiers.keys():\n",
    " \n",
    "    results.loc[model] = [measures[measure](y_test, classifiers[model][\"c\"]) for measure in measures.keys()]\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from costcla.metrics import savings_score, cost_loss \n",
    "\n",
    "# Evaluate the savings for each model\n",
    "results[\"sav\"] = np.zeros(results.shape[0])\n",
    "for model in classifiers.keys():\n",
    "    results[\"sav\"].loc[model] = (savings_score(y_test, classifiers[model][\"c\"], cost_mat_test))\n",
    "results[\"cost_vs_baseline\"] = np.zeros(results.shape[0])\n",
    "for model in classifiers.keys():\n",
    "    results[\"cost_vs_baseline\"].loc[model] = (cost_loss(y_test, classifiers[model][\"c\"], cost_mat_test) - cost_all_zeros)\n",
    "\n",
    "# TODO: plot results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the results\n",
    "colors = sns.color_palette()\n",
    "\n",
    "figsize = (10, 5)\n",
    "ax = plt.subplot(111)\n",
    "l = ax.plot(ind, results[\"f1\"], \"-o\", label='F1Score', color=colors[2])\n",
    "b = ax.bar(ind-0.3, results['sav'], 0.6, label='Savings', color=colors[0])\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.set_xlim([-0.5, ind[-1]+.5])\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(results.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from costcla.models import BayesMinimumRiskClassifier\n",
    "ci_models = models_dict_cs.keys()\n",
    "\n",
    "for model in list(models_dict_cs):\n",
    "    classifiers[model+\"-BMR\"] = {\"F\": BayesMinimumRiskClassifier()}\n",
    "    # Fit\n",
    "    classifiers[model+\"-BMR\"][\"F\"].fit(y_test, classifiers[model][\"p\"])  \n",
    "    # Calibration must be made in a validation set\n",
    "    # Predict\n",
    "    classifiers[model+\"-BMR\"][\"class\"] = classifiers[model+\"-BMR\"][\"F\"].predict(classifiers[model][\"p\"], cost_mat_test)\n",
    "    # Evaluate\n",
    "    results.loc[model+\"-BMR\"] = 0\n",
    "    results.loc[model+\"-BMR\", measures.keys()] = \\\n",
    "    [measures[measure](y_test, classifiers[model+\"-BMR\"][\"c\"]) for measure in measures.keys()]\n",
    "    results[\"sav\"].loc[model+\"-BMR\"] = savings_score(y_test, classifiers[model+\"-BMR\"][\"c\"], cost_mat_test)\n",
    "    \n",
    "print(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "ind = np.arange(results.shape[0])\n",
    "colors = sns.color_palette()\n",
    "figsize = (10, 5)\n",
    "ax = plt.subplot(111)\n",
    "l = ax.plot(ind, results[\"f1\"], \"-o\", label='F1Score', color=colors[2])\n",
    "b = ax.bar(ind-0.3, results['sav'], 0.6, label='Savings', color=colors[0])\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.set_xlim([-0.5, ind[-1]+.5])\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(results.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from costcla.models import CostSensitiveRandomPatchesClassifier\n",
    "\n",
    "classifiers[\"CSRP\"] = {\"f\": CostSensitiveRandomPatchesClassifier(combination='weighted_voting')}\n",
    "# Fit\n",
    "classifiers[\"CSRP\"][\"f\"].fit(X_train, y_train, cost_mat_train)\n",
    "# Predict\n",
    "classifiers[\"CSRP\"][\"c\"] = classifiers[\"CSRP\"][\"f\"].predict(X_test)\n",
    "# Evaluate\n",
    "results.loc[\"CSRP\"] = 0\n",
    "results.loc[\"CSRP\", measures.keys()] = \\\n",
    "[measures[measure](y_test, classifiers[\"CSRP\"][\"c\"]) for measure in measures.keys()]\n",
    "results[\"sav\"].loc[\"CSRP\"] = savings_score(y_test, classifiers[\"CSRP\"][\"c\"], cost_mat_test)\n",
    "    \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "ind = np.arange(results.shape[0])\n",
    "figsize = (10, 5)\n",
    "ax = plt.subplot(111)\n",
    "l = ax.plot(ind, results[\"f1\"], \"-o\", label='F1Score', color=colors[2])\n",
    "b = ax.bar(ind-0.3, results['sav'], 0.6, label='Savings', color=colors[0])\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.set_xlim([-0.5, ind[-1]+.5])\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(results.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "QuadraticDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "from operator import itemgetter\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "# from http://scikit-learn.org/stable/auto_examples/model_selection/randomized_search.html\n",
    "param_dist = {\"n_estimators\": [10, 20, 50, 100, 1000],\n",
    "              \"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 10),\n",
    "              \"min_samples_split\": sp_randint(1, 100),\n",
    "              \"min_samples_leaf\": sp_randint(1, 100),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "classifiers[\"RS-RF\"] = {\"f\": RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                                n_iter=20, n_jobs=4, verbose=1)}\n",
    "# Fit\n",
    "start = time()\n",
    "classifiers[\"RS-RF\"][\"f\"].fit(X_train, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds\"\n",
    "      \" parameter settings.\" % ((time() - start),))\n",
    "\n",
    "report(classifiers[\"RS-RF\"][\"f\"].grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "classifiers[\"RS-RF\"][\"c\"] = classifiers[\"RS-RF\"][\"f\"].predict(X_test)\n",
    "# Evaluate\n",
    "results.loc[\"RS-RF\"] = 0\n",
    "results.loc[\"RS-RF\", measures.keys()] = \\\n",
    "[measures[measure](y_test, classifiers[\"RS-RF\"][\"c\"]) for measure in measures.keys()]\n",
    "results[\"sav\"].loc[\"RS-RF\"] = savings_score(y_test, classifiers[\"RS-RF\"][\"c\"], cost_mat_test)\n",
    "    \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_acc = []\n",
    "rf_rec = []\n",
    "rf_auc = []\n",
    "rf_fn = []\n",
    "\n",
    "for item in features:\n",
    "    \n",
    "    \n",
    "    y = train_upsampled.victims_alert\n",
    "    X = preprocessing_features(train_upsampled, item)\n",
    "    y_test = test.victims_alert\n",
    "    X_test = preprocessing_features(test, item) \n",
    "\n",
    "\n",
    "    clf = RandomForestClassifier(random_state=random_state).fit(X,y)\n",
    "\n",
    "    # Predict on training set\n",
    "    pred = clf.predict(X_test)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    _, _, fn, _ = confusion_matrix(y_test, pred).ravel()\n",
    "    \n",
    "    rf_fn.append(fn)\n",
    "    print( 'Random Forest False Negative: ', fn )\n",
    "    # How's our accuracy?\n",
    "    \n",
    "    rf_acc.append(accuracy_score(y_test, pred))\n",
    "    \n",
    "    #print( 'Random Forest Accuracy: ', round(accuracy_score(y_test, pred),4) )\n",
    "    rf_rec.append(recall_score(y_test, pred))\n",
    "\n",
    "    #print('Random Forest Recall: ',round(recall_score(y_test, pred), 4))\n",
    "    rf_auc.append(auc(fpr, tpr))\n",
    "    #print('Random Forest AUC: ',round(auc(fpr, tpr), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(rf_fn), rf_fn.index(min(rf_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(rf_acc), rf_acc.index(max(rf_acc)), max(rf_rec), rf_rec.index(max(rf_rec)), max(rf_auc), rf_auc.index(max(rf_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_upsampled.victims_alert\n",
    "X = preprocessing_features(train_upsampled, features[35])\n",
    "y_test = test.victims_alert\n",
    "X_test = preprocessing_features(test, features[35]) \n",
    "\n",
    "# Train model\n",
    "\n",
    "clf = RandomForestClassifier(random_state=random_state).fit(X,y)\n",
    "\n",
    "# Predict on training set\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "prob = clf.predict_proba(X_test)\n",
    "\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "#print( np.unique( pred_y_1 ) )\n",
    "# [0 1]\n",
    " \n",
    "# How's our accuracy?\n",
    "\n",
    "print( 'Random Forest Accuracy: ', round(accuracy_score(y_test, pred),4) )\n",
    "\n",
    "print('Random Forest Recall: ',round(recall_score(y_test, pred), 4))\n",
    "\n",
    "\n",
    "\n",
    "print( 'Random Forest: ',pred.sum(), len(pred), len(pred) *0.25, pred.sum()/len(pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_0 = [x[0] for x in prob]\n",
    "prob_1 = [x[1] for x in prob]\n",
    "\n",
    "\n",
    "for item in np.linspace(0.5,1, 5):\n",
    "    \n",
    "    pred_0_t = [0 if x >= item else 1 for x in prob_0 ]\n",
    "    acc_0_t = accuracy_score(y_test, pred_0_t)\n",
    "    rec_0_t = recall_score(y_test,pred_0_t)\n",
    "    prec_0_t = precision_score(y_test, pred_0_t)\n",
    "    _, _, fn_0_t, _ = confusion_matrix(y_test, pred_0_t).ravel()\n",
    "    print(item, acc_0_t, rec_0_t, fn_0_t, prec_0_t, sum(pred_0_t), len(pred_0_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_features, rf_rec);\n",
    "for key in dict_features.keys():\n",
    "    plt.axvline(x=dict_features[key], c = 'red')\n",
    "plt.title(\"Recall(acc, f1, precision, recall)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = [x for x in range(1,len(features) + 1)]\n",
    "plt.plot(x_features, rf_acc);\n",
    "for key in dict_features.keys():\n",
    "    plt.axvline(x=dict_features[key], c = 'red')\n",
    "plt.title(\"Accuracy(acc, f1, precision, recall)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for key in dict_features.keys():\n",
    "    plt.axvline(x=dict_features[key], c = 'red')\n",
    "plt.plot(x_features, rf_auc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "RNG = 42\n",
    "# Make some synthetic imbalanced binary classification data\n",
    "y = train_upsampled.victims_alert\n",
    "X = preprocessing_features(train_upsampled, features[39])\n",
    "y_test = test.victims_alert\n",
    "X_test = preprocessing_features(test, features[39]) \n",
    "\n",
    "metric_names = ['f1', 'average_precision', 'accuracy', 'precision', 'recall']\n",
    "scores_df = pd.DataFrame(index=metric_names, columns=['Random-CV', 'Stratified-CV']) # to store the scores\n",
    "cv = KFold(n_splits=3)\n",
    "scv = StratifiedKFold(n_splits=3)\n",
    "clf = RandomForestClassifier(random_state=random_state)\n",
    "for metric in metric_names:\n",
    "    score1 = cross_val_score(clf, X, y, scoring=metric, cv=cv).mean()\n",
    "    score2 = cross_val_score(clf, X, y, scoring=metric, cv=scv).mean()\n",
    "    scores_df.loc[metric] = [score1, score2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in np.linspace(0.3,0.5, 4):\n",
    "    for model in models_dict.keys():\n",
    "    \n",
    "        print(r, models_dict[model]['name'], selecting_model_smote(df, target, r, features[39], models_dict[model]['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_smote_perceptron = (0.2/3 + 0.3)\n",
    "a, b, _, _, pred, y_test  = selecting_model_smote\\\n",
    "(df,target,max_smote_perceptron,features[39],models_dict['Perceptron']['name'])\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Random Forest confusion matrix analysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "\n",
    "\n",
    "from sklearn.metrics import auc, precision_recall_curve, average_precision_score\n",
    "fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area ={})'.format(round(roc_auc, 4)))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn, sum(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Trying SVC with penalisation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def selecting_model_smote(dataframe, target, ratio, features,model):\n",
    "    \n",
    "    data = dataframe[features].copy()\n",
    "    data.reset_index(inplace=True)\n",
    "    for item in features:\n",
    "        if data[item].dtypes == 'object':\n",
    "            #print(item, data[item].dtypes, 'object')\n",
    "            prova = pd.get_dummies(data[item], drop_first=True)\n",
    "            data = pd.concat([data,prova], axis=1)\n",
    "            data.drop(item, axis=1, inplace=True)\n",
    "\n",
    "    X = np.array(data)\n",
    "    y = dataframe[target]\n",
    "    y = (np.where (y > 0, 1, 0))\n",
    "    y = np.reshape(y, len(y))\n",
    "    \n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1, stratify=y)\n",
    "    \n",
    "    \n",
    "    X_resampled, y_resampled = SMOTE(ratio=ratio, random_state=2018).fit_sample(X_train, y_train)\n",
    "\n",
    "    #print('Labels counts in y:', np.bincount(y), (np.bincount(y)[1]/np.bincount(y)[0]))\n",
    "    #print('Labels counts in y_train:', np.bincount(y_train), (np.bincount(y_train)[1]/np.bincount(y_train)[0]))\n",
    "    #print('Labels counts in y_test:', np.bincount(y_test), (np.bincount(y_test)[1]/np.bincount(y_test)[0]))\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_resampled)\n",
    "    X_train_std = ss.transform(X_resampled)\n",
    "    X_test_std = ss.transform(X_test)\n",
    "    \n",
    "\n",
    "                \n",
    "    model.fit(X_train_std, y_resampled)\n",
    "    pred = model.predict(X_test_std)\n",
    "    #prob = clf.predict_proba(X_test_std)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "        \n",
    "    return accuracy, recall, precision, f1, pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###chapter 2\n",
    "\n",
    "class Perceptron(object):\n",
    "    \"\"\"Perceptron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "      Learning rate (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "      Passes over the training dataset.\n",
    "    random_state : int\n",
    "      Random number generator seed for random weight\n",
    "      initialization.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "      Weights after fitting.\n",
    "    errors_ : list\n",
    "      Number of misclassifications (updates) in each epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "          Training vectors, where n_samples is the number of samples and\n",
    "          n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "          Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
    "        self.errors_ = []\n",
    "\n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_[1:] += update * xi\n",
    "                self.w_[0] += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def selecting_model(dataframe, target, features, **models_dict):\n",
    "    \n",
    "    data = dataframe[features].copy()\n",
    "    data.reset_index(inplace=True)\n",
    "    for item in features:\n",
    "        if data[item].dtypes == 'object':\n",
    "            #print(item, data[item].dtypes, 'object')\n",
    "            prova = pd.get_dummies(data[item], drop_first=True)\n",
    "            data = pd.concat([data,prova], axis=1)\n",
    "            data.drop(item, axis=1, inplace=True)\n",
    "\n",
    "    X = np.array(data)\n",
    "    y = dataframe[target]\n",
    "    y = (np.where (y > 0, 1, 0))\n",
    "    y = np.reshape(y, len(y))\n",
    "    \n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1, stratify=y)\n",
    "    \n",
    "    \n",
    "    X_resampled, y_resampled = SMOTE(ratio=0.3, random_state=2018).fit_sample(X_train, y_train)\n",
    "\n",
    "    #print('Labels counts in y:', np.bincount(y), (np.bincount(y)[1]/np.bincount(y)[0]))\n",
    "    #print('Labels counts in y_train:', np.bincount(y_train), (np.bincount(y_train)[1]/np.bincount(y_train)[0]))\n",
    "    #print('Labels counts in y_test:', np.bincount(y_test), (np.bincount(y_test)[1]/np.bincount(y_test)[0]))\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_resampled)\n",
    "    X_train_std = ss.transform(X_resampled)\n",
    "    X_test_std = ss.transform(X_test)\n",
    "    \n",
    "    \n",
    "    for item in models_dict.keys():\n",
    "\n",
    "        \n",
    "  \n",
    "        clf = models_dict[item]['name']\n",
    "            \n",
    "        clf.fit(X_train_std, y_resampled)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        pred = clf.predict(X_test_std)\n",
    "        #prob = clf.predict_proba(X_test_std)\n",
    "        accuracy = accuracy_score(y_test, pred)\n",
    "        recall = recall_score(y_test, pred)\n",
    "        #models_dict[item]['pred'].append(pred)\n",
    "        #models_dict[item]['proba'].append(prob)\n",
    "        #models_dict[item]['accuracy'].append(accuracy)\n",
    "        #models_dict[item]['recall'].append(recall)\n",
    "        #models_dict[key]['count'].append(num)\n",
    "        print(str(models_dict[item]))\n",
    "        print('Misclassified samples: %d' % (y_test != pred).sum())\n",
    "        print('Amount of victims predicted: ', pred.sum())\n",
    "        print(\"How many predictions over real: \", pred.sum()/y_test.sum())\n",
    "        print(\"Predicted one vs total compared with original: \", pred.sum()/len(y_test), y_test.sum()/len(y_test))\n",
    "        print('Victims_alert missed: ',  sum([1 for x,y in zip(y_test,pred) if x ==1 and y==0]))\n",
    "\n",
    "        print('Accuracy: %.4f' % accuracy_score(y_test, pred))\n",
    "        print('Recall: {}'.format(recall_score(y_test, pred)))\n",
    "        print('Precision: {}'.format(precision_score(y_test, pred)))\n",
    "        print('f1_score: {}'.format(f1_score(y_test, pred)))\n",
    "        print('fbeta_score: {}'.format(fbeta_score(y_test, pred, beta=0.5)))\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selecting_model(df, target,features_max_f1_score[1], **models_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_features(df, features):\n",
    "    \n",
    "    \"Getting ready the features for the model\"\n",
    "    \n",
    "    data = df[features].copy()\n",
    "    data.reset_index(inplace=True)\n",
    "    for item in features:\n",
    "        if data[item].dtypes == 'object':\n",
    "            print(item, data[item].dtypes)\n",
    "            prova = pd.get_dummies(data[item], drop_first=True)\n",
    "            data = pd.concat([data,prova], axis=1)\n",
    "            data.drop(item, axis=1, inplace=True)\n",
    "\n",
    "    features_array = np.array(data)\n",
    "    \n",
    "    return features_array\n",
    "preprocessing_features(df,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,0,1,0,0,0])\n",
    "b = np.array([0,0,1,0,0,0])\n",
    "sum([1 for x,y in zip(a,b) if x ==1 and y==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = preprocessing_features(df, all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_array\n",
    "y = df[target].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class SBS():\n",
    "    \n",
    "    \"\"\"loading initial information\"\"\"\n",
    "    \n",
    "    def __init__(self, estimator, k_features, scoring=accuracy_score,\n",
    "                 test_size=0.25, random_state=1):\n",
    "        self.scoring = scoring\n",
    "        self.estimator = clone(estimator)\n",
    "        self.k_features = k_features\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        \"\"\"calculate score with all features included initialy in X\"\"\"\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(X, y, test_size=self.test_size,\n",
    "                             random_state=self.random_state)\n",
    "\n",
    "        dim = X_train.shape[1]\n",
    "        self.indices_ = tuple(range(dim))\n",
    "        self.subsets_ = [self.indices_]\n",
    "        score = self._calc_score(X_train, y_train, \n",
    "                                 X_test, y_test, self.indices_)\n",
    "        self.scores_ = [score]\n",
    "        \n",
    "        \"while the number of initial features is bigger than the value k_features given\"\n",
    "\n",
    "        while dim > self.k_features:\n",
    "            scores = []\n",
    "            subsets = []\n",
    "\n",
    "            for p in combinations(self.indices_, r=dim - 1):\n",
    "                score = self._calc_score(X_train, y_train, \n",
    "                                         X_test, y_test, p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "\n",
    "            best = np.argmax(scores)\n",
    "            self.indices_ = subsets[best]\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim -= 1\n",
    "\n",
    "            self.scores_.append(scores[best])\n",
    "        self.k_score_ = self.scores_[-1]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \n",
    "        \"\"\"Preparing the X based on selected features\"\"\"\n",
    "        return X[:, self.indices_]\n",
    "\n",
    "    def _calc_score(self, X_train, y_train, X_test, y_test, indices):\n",
    "        \n",
    "        \"\"\"scoreing the model based on gthe selected features selected by indices\"\"\"\n",
    "        \n",
    "        self.estimator.fit(X_train[:, indices], y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:, indices])\n",
    "        score = self.scoring(y_test, y_pred)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_fetuares = df[all_features].select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df[numeric_fetuares])\n",
    "y = df[target].values\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "# selecting features\n",
    "sbs = SBS(knn, k_features=1)\n",
    "#sbs.fit(X_train_std, y_train)\n",
    "sbs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _calc_score(X_train, y_train, X_test, y_test):\n",
    "        pp = Perceptron()\n",
    "        pp.fit(X_train, y_train)\n",
    "        y_pred = pp.predict(X_test)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        return score, y_pred, y_test\n",
    "    \n",
    "dim = X_train.shape[1]\n",
    "indices_ = tuple(range(dim))\n",
    "subsets_ = [indices_]\n",
    "score, pred, real = _calc_score(X_train, y_train, \n",
    "                                 X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred), len(real), pred.sum(), real.sum()\n",
    "misclassified_samples = []\n",
    "cagades = []\n",
    "\n",
    "for x,y in zip(real,pred):\n",
    "    if x != y:\n",
    "        misclassified_samples.append(1)\n",
    "    \n",
    "print('Misclassified Samples: ', sum(misclassified_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['Perceptron', 'LogisticRegression', 'SVC', 'DecisionTreeClassifier', 'RandomForestClassifier',\\\n",
    "          'KNeighborsClassifier']\n",
    "for itrem in models:    \n",
    "    calculant_recall(df,target, features, itrem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    print(i, len(df[i].unique()))\n",
    "\n",
    "print('Number of Nan;', df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred), y_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculate recall\n",
    "evaluation_metrics['recall'], evaluation_metrics['precision']\n",
    "##THIS ONE SUCKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SECOND TRY-----ADDING FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##we will add some features\n",
    "set_features = ['hour_day', 'month', 'latitude', 'longitude', 'year', 'victims_alert']\n",
    "\n",
    "df1 = (pd.concat([df[set_features], pd.get_dummies(df['month'])], axis=1, join_axes=[df.index])).drop('month', axis= 1)  \n",
    "\n",
    "first_set_features = df1.columns\n",
    "first_set_features.drop('victims_alert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(df1):\n",
    "    \"\"\"Prepares input features from accidents.\n",
    "\n",
    "    Args:\n",
    "    final_accidents dataframe: A Pandas DataFrame expected to contain data\n",
    "      from the Barcelona Accidents.\n",
    "    Returns:\n",
    "    A DataFrame that contains the features to be used for the model, including\n",
    "    synthetic features.\n",
    "    \"\"\"\n",
    "    selected_features = df1[first_set_features]\n",
    "    processed_features = selected_features.copy()\n",
    "    return processed_features\n",
    "\n",
    "def preprocess_targets(df1):\n",
    "    \"\"\"Prepares target features (i.e., labels) from BarcelonaAccidents data set.\n",
    "\n",
    "    Args:\n",
    "    final_accidents_dataframe: A Pandas DataFrame expected to contain data\n",
    "      from the BarcelonaAccidents data set.\n",
    "    Returns:\n",
    "    A DataFrame that contains the target feature.\n",
    "    \"\"\"\n",
    "    output_targets = pd.DataFrame()\n",
    "    # Create a boolean categorical feature representing whether the\n",
    "    # median_house_value is above a set threshold.\n",
    "    output_targets[\"victims_alert\"] = df1[\"victims_alert\"].astype(float)\n",
    "    return output_targets\n",
    "\n",
    "msk = np.random.rand(len(df1)) < 0.75\n",
    "# Choose the first 12000 (out of 17000) examples for training.\n",
    "training_examples = preprocess_features(df1[msk])\n",
    "training_targets = preprocess_targets(df1[msk])\n",
    "\n",
    "# Choose the last 5000 (out of 17000) examples for validation.\n",
    "validation_examples = preprocess_features(df1[~msk])\n",
    "validation_targets = preprocess_targets(df1[~msk])\n",
    "\n",
    "# Double-check that we've done the right thing.\n",
    "print(\"Training examples summary:\")\n",
    "display.display(training_examples.describe())\n",
    "print(\"Validation examples summary:\")\n",
    "display.display(validation_examples.describe())\n",
    "\n",
    "print(\"Training targets summary:\")\n",
    "display.display(training_targets.describe())\n",
    "print(\"Validation targets summary:\")\n",
    "display.display(validation_targets.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_linear_classifier_model(\n",
    "    learning_rate,\n",
    "    regularization_strength,\n",
    "    steps,\n",
    "    batch_size,\n",
    "    feature_columns,\n",
    "    training_examples,\n",
    "    training_targets,\n",
    "    validation_examples,\n",
    "    validation_targets):\n",
    "    \"\"\"Trains a linear regression model.\n",
    "\n",
    "    In addition to training, this function also prints training progress information,\n",
    "    as well as a plot of the training and validation loss over time.\n",
    "\n",
    "    Args:\n",
    "    learning_rate: A `float`, the learning rate.\n",
    "    regularization_strength: A `float` that indicates the strength of the L1\n",
    "       regularization. A value of `0.0` means no regularization.\n",
    "    steps: A non-zero `int`, the total number of training steps. A training step\n",
    "      consists of a forward and backward pass using a single batch.\n",
    "    feature_columns: A `set` specifying the input feature columns to use.\n",
    "    training_examples: A `DataFrame` containing one or more columns from\n",
    "      `california_housing_dataframe` to use as input features for training.\n",
    "    training_targets: A `DataFrame` containing exactly one column from\n",
    "      `california_housing_dataframe` to use as target for training.\n",
    "    validation_examples: A `DataFrame` containing one or more columns from\n",
    "      `california_housing_dataframe` to use as input features for validation.\n",
    "    validation_targets: A `DataFrame` containing exactly one column from\n",
    "      `california_housing_dataframe` to use as target for validation.\n",
    "\n",
    "    Returns:\n",
    "    A `LinearClassifier` object trained on the training data.\n",
    "    \"\"\"\n",
    "\n",
    "    periods = 12\n",
    "    steps_per_period = steps / periods\n",
    "\n",
    "    # Create a linear classifier object.\n",
    "    my_optimizer = tf.train.FtrlOptimizer(learning_rate=learning_rate, l1_regularization_strength=regularization_strength)\n",
    "    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "    linear_classifier = tf.estimator.LinearClassifier(\n",
    "      feature_columns=feature_columns,\n",
    "      optimizer=my_optimizer\n",
    "    )\n",
    "\n",
    "    # Create input functions.\n",
    "    training_input_fn = lambda: my_input_fn(training_examples, \n",
    "                                          training_targets[\"victims_alert\"], \n",
    "                                          batch_size=batch_size)\n",
    "    predict_training_input_fn = lambda: my_input_fn(training_examples, \n",
    "                                                  training_targets[\"victims_alert\"], \n",
    "                                                  num_epochs=1, \n",
    "                                                  shuffle=False)\n",
    "    predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
    "                                                    validation_targets[\"victims_alert\"], \n",
    "                                                    num_epochs=1, \n",
    "                                                    shuffle=False)\n",
    "\n",
    "    # Train the model, but do so inside a loop so that we can periodically assess\n",
    "    # loss metrics.\n",
    "    print(\"Training model...\")\n",
    "    print(\"LogLoss (on validation data):\")\n",
    "    training_log_losses = []\n",
    "    validation_log_losses = []\n",
    "    for period in range (0, periods):\n",
    "        # Train the model, starting from the prior state.\n",
    "        linear_classifier.train(\n",
    "            input_fn=training_input_fn,\n",
    "            steps=steps_per_period\n",
    "        )\n",
    "        # Take a break and compute predictions.\n",
    "        training_probabilities = linear_classifier.predict(input_fn=predict_training_input_fn)\n",
    "        training_probabilities = np.array([item['probabilities'] for item in training_probabilities])\n",
    "\n",
    "        validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
    "        validation_probabilities = np.array([item['probabilities'] for item in validation_probabilities])\n",
    "\n",
    "        # Compute training and validation loss.\n",
    "        training_log_loss = metrics.log_loss(training_targets, training_probabilities)\n",
    "        validation_log_loss = metrics.log_loss(validation_targets, validation_probabilities)\n",
    "        # Occasionally print the current loss.\n",
    "        print(\"  period {:02d} : {:0.2f}\".format(period, validation_log_loss))\n",
    "        # Add the loss metrics from this period to our list.\n",
    "        training_log_losses.append(training_log_loss)\n",
    "        validation_log_losses.append(validation_log_loss)\n",
    "    print(\"Model training finished.\")\n",
    "    \n",
    "    \n",
    "\n",
    "    #validation_predictions = np.array([item['probabilities'] for item in validation_probabilities])\n",
    "\n",
    "    _ = plt.hist(validation_predictions)\n",
    "\n",
    "    evaluation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)\n",
    "\n",
    "    print(\"AUC on the validation set: {:0.4f}\".format(evaluation_metrics['auc']))\n",
    "    print(\"Accuracy on the validation set: {:0.6f}\".format(evaluation_metrics['accuracy']))\n",
    "    print(\"AUC_precision-recall {:0.5f}\".format(evaluation_metrics['auc_precision_recall']))\n",
    "\n",
    "    # Output a graph of loss metrics over periods.\n",
    "    plt.ylabel(\"LogLoss\")\n",
    "    plt.xlabel(\"Periods\")\n",
    "    plt.title(\"LogLoss vs. Periods\")\n",
    "    plt.tight_layout()\n",
    "    plt.plot(training_log_losses, label=\"training\")\n",
    "    plt.plot(validation_log_losses, label=\"validation\")\n",
    "    plt.legend()\n",
    "\n",
    "    return linear_classifier\n",
    "\n",
    "def model_size(estimator):\n",
    "    variables = estimator.get_variable_names()\n",
    "    size = 0\n",
    "    for variable in variables:\n",
    "        if not any(x in variable \n",
    "            for x in ['global_step',\n",
    "                         'centered_bias_weight',\n",
    "                         'bias_weight',\n",
    "                         'Ftrl']\n",
    "              ):\n",
    "            size += np.count_nonzero(estimator.get_variable_value(variable))\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in np.linspace(0,1, 5):\n",
    "    linear_classifier = train_linear_classifier_model(\n",
    "        learning_rate=0.000005,\n",
    "        # TWEAK THE REGULARIZATION VALUE BELOW\n",
    "        regularization_strength =item,\n",
    "        steps=500,\n",
    "        batch_size=100,\n",
    "        feature_columns =construct_feature_columns(training_examples),\n",
    "        training_examples=training_examples,\n",
    "        training_targets=training_targets,\n",
    "        validation_examples=validation_examples,\n",
    "        validation_targets=validation_targets)\n",
    "    print(\"Model size:\", model_size(linear_classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
    "                                                  validation_targets[\"victims_alert\"], \n",
    "                                                  num_epochs=1, \n",
    "                                                  shuffle=False)\n",
    "\n",
    "validation_predictions = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
    "validation_predictions = np.array([item['probabilities'][0] for item in validation_predictions])\n",
    "\n",
    "_ = plt.hist(validation_predictions)\n",
    "\n",
    "evaluation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)\n",
    "\n",
    "print(\"AUC on the validation set: {:0.4f}\".format(evaluation_metrics['auc']))\n",
    "print(\"Accuracy on the validation set: {:0.2f}\".format(evaluation_metrics['accuracy']))\n",
    "print(\"AUC_precision-recall {:0.3f}\".format(evaluation_metrics['auc_precision_recall']))\n",
    "\n",
    "validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
    "# Get just the probabilities for the positive class.\n",
    "validation_probabilities = np.array([item['probabilities'][1] for item in validation_probabilities])\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(\n",
    "    validation_targets, validation_probabilities)\n",
    "plt.plot(false_positive_rate, true_positive_rate, label=\"our model\")\n",
    "plt.plot([0, 1], [0, 1], label=\"random classifier\")\n",
    "_ = plt.legend(loc=2)\n",
    "\n",
    "average_precision = average_precision_score(validation_targets, validation_probabilities)\n",
    "precision, recall, _ = precision_recall_curve(validation_targets, validation_probabilities)\n",
    "\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculate recall\n",
    "evaluation_metrics['recall'], evaluation_metrics['precision']\n",
    "##THIS ONE SUCKS but it doesn't?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THIRD TRY--- ALL FEATURES AND REGLARIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##we will add some features\n",
    "set_features = ['hour_day', 'month', 'latitude', 'longitude', 'year', 'victims_alert', 'week_day']\n",
    "\n",
    "df2 = (pd.concat([df[set_features], pd.get_dummies(df[['month', 'week_day']])], axis=1, join_axes=[df.index])).drop(['month', 'week_day'], axis= 1)  \n",
    "\n",
    "first_set_features = df2.columns\n",
    "\n",
    "def preprocess_features(df2):\n",
    "    \"\"\"Prepares input features from California housing data set.\n",
    "\n",
    "    Args:\n",
    "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
    "      from the California housing data set.\n",
    "    Returns:\n",
    "    A DataFrame that contains the features to be used for the model, including\n",
    "    synthetic features.\n",
    "    \"\"\"\n",
    "    selected_features = df2[first_set_features]\n",
    "    processed_features = selected_features.copy()\n",
    "    processed_features[\"latxlong\"] = (\n",
    "    df2[\"latitude\"] * df2[\"longitude\"])\n",
    "    return processed_features\n",
    "\n",
    "def preprocess_targets(df2):\n",
    "    \"\"\"Prepares target features (i.e., labels) from California housing data set.\n",
    "\n",
    "    Args:\n",
    "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
    "      from the California housing data set.\n",
    "    Returns:\n",
    "    A DataFrame that contains the target feature.\n",
    "    \"\"\"\n",
    "    output_targets = pd.DataFrame()\n",
    "    # Create a boolean categorical feature representing whether the\n",
    "    # median_house_value is above a set threshold.\n",
    "    output_targets[\"victims_alert\"] = df2[\"victims_alert\"].astype(float)\n",
    "    return output_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(df2)) < 0.75\n",
    "# Choose the first 12000 (out of 17000) examples for training.\n",
    "training_examples = preprocess_features(df2[msk])\n",
    "training_targets = preprocess_targets(df2[msk])\n",
    "\n",
    "# Choose the last 5000 (out of 17000) examples for validation.\n",
    "validation_examples = preprocess_features(df2[~msk])\n",
    "validation_targets = preprocess_targets(df2[~msk])\n",
    "\n",
    "# Double-check that we've done the right thing.\n",
    "print(\"Training examples summary:\")\n",
    "display.display(training_examples.describe())\n",
    "print(\"Validation examples summary:\")\n",
    "display.display(validation_examples.describe())\n",
    "\n",
    "print(\"Training targets summary:\")\n",
    "display.display(training_targets.describe())\n",
    "print(\"Validation targets summary:\")\n",
    "display.display(validation_targets.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##It is better to use a low learning rate to ensure convergence\n",
    "\n",
    "linear_classifier = train_linear_classifier_model(\n",
    "    learning_rate=0.000001,\n",
    "    # TWEAK THE REGULARIZATION VALUE BELOW\n",
    "    steps=500,\n",
    "    batch_size=20,\n",
    "    training_examples=training_examples,\n",
    "    training_targets=training_targets,\n",
    "    validation_examples=validation_examples,\n",
    "    validation_targets=validation_targets)\n",
    "print(\"Model size:\", model_size(linear_classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
    "                                                  validation_targets[\"victims_alert\"], \n",
    "                                                  num_epochs=1, \n",
    "                                                  shuffle=False)\n",
    "\n",
    "validation_predictions = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
    "validation_predictions = np.array([item['probabilities'][0] for item in validation_predictions])\n",
    "\n",
    "_ = plt.hist(validation_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)\n",
    "\n",
    "print(\"AUC on the validation set: {:0.4f}\".format(evaluation_metrics['auc']))\n",
    "print(\"Accuracy on the validation set: {:0.5f}\".format(evaluation_metrics['accuracy']))\n",
    "print(\"AUC_precision-recall {:0.3f}\".format(evaluation_metrics['auc_precision_recall']))\n",
    "\n",
    "validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
    "# Get just the probabilities for the positive class.\n",
    "validation_probabilities = np.array([item['probabilities'][1] for item in validation_probabilities])\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(\n",
    "    validation_targets, validation_probabilities)\n",
    "plt.plot(false_positive_rate, true_positive_rate, label=\"our model\")\n",
    "plt.plot([0, 1], [0, 1], label=\"random classifier\")\n",
    "_ = plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision = average_precision_score(validation_targets, validation_probabilities)\n",
    "precision, recall, _ = precision_recall_curve(validation_targets, validation_probabilities)\n",
    "\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 =LogisticRegression()\n",
    "lr.fit(X_test, y_test)\n",
    "prediction = lr.predict_proba(X_resampled)\n",
    "accuracy_score(y_train, prediction)\n",
    "recall_score(y_resampled, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Logistic Regression\", \"Random Forest\", \"Gradient Boost Classifier\"]\n",
    "classifiers = [\n",
    "    LogisticRegression(C= 2),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    GradientBoostingClassifier()]\n",
    "#model_list = ['logreg']\n",
    "logreg_score = []\n",
    "rf_score = []\n",
    "gbc_score = []\n",
    "logreg_recall = []\n",
    "rf_recall = []\n",
    "gbc_recall = []\n",
    "accidents.drop(['#_deaths', 'amount_victims', 'incident_#', 'minor_injures', 'severely_injured', 'victims'],\\\n",
    "               axis=1, inplace=True)\n",
    "\n",
    "\n",
    "objectes = accidents.select_dtypes(include='object').columns\n",
    "numerical = accidents.select_dtypes(exclude='object').columns\n",
    "print('Object_columns:', objectes, len(objectes))\n",
    "print('Numerical_columns:', numerical, len(numerical))\n",
    "print('Ha de ser zero:', len(accidents.columns) - len(numerical) - len(objectes))\n",
    "dummies = pd.get_dummies(accidents[objectes])\n",
    "final = pd.concat([accidents[numerical], dummies], axis=1)\n",
    "\n",
    "correlation = final.corr()\n",
    "#correlation['victims_alert'].head(10)\n",
    "\n",
    "pos_values = []\n",
    "for item in correlation['victims_alert']:\n",
    "    if item < 0:\n",
    "        item = item * (-1)\n",
    "        pos_values.append(item)\n",
    "    else:\n",
    "        pos_values.append(item)\n",
    "correlation['victims_alert'] = pos_values\n",
    "all_features = list(correlation['victims_alert'].sort_values(ascending=False)[1::].index)\n",
    "for num in range(2,len(all_features), 2):\n",
    "    \n",
    "    fea = all_features[0:num]\n",
    "    X = final[fea]\n",
    "    y = accidents['victims_alert'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    if (y.sum()/final.shape[0]) < 0.05:\n",
    "    \n",
    "        X_resampled, y_resampled = SMOTE(ratio=0.3, random_state=2018).fit_sample(X_train, y_train)\n",
    "        scaler = StandardScaler()\n",
    "        Xs_train = scaler.fit_transform(X_resampled)\n",
    "        Xs_test = scaler.transform(X_test)\n",
    "\n",
    "    else:\n",
    "        scaler = StandardScaler()\n",
    "        Xs_train = scaler.fit_transform(X_train)\n",
    "        Xs_test = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "    for name, clf in zip(names, classifiers):\n",
    "        \n",
    "        clf.fit(Xs_train, y_resampled)\n",
    "        score = clf.score(Xs_test, y_test)\n",
    "        pred = clf.predict(Xs_test)\n",
    "        prob = clf.predict_proba(X_test)\n",
    "        new_proba = []\n",
    "        for l in range(0,len(prob)):\n",
    "            z = prob[l][1]\n",
    "            new_proba.append(z)\n",
    "        \n",
    "        \n",
    "\n",
    "            hedging_all = y.sum() * (2)\n",
    "            new_pred = [hedging_all + 1]\n",
    "\n",
    "            limits = np.linspace(0.0253,0.03, 20)\n",
    "            i = 0\n",
    "            \n",
    "            while i < len(limits) and sum(new_pred) > hedging_all:\n",
    "\n",
    "                numero = limits[i]\n",
    "    \n",
    "                #for numero in np.linspace(0.0253,0.03, 20):\n",
    "                #new_pred = [1960]\n",
    "                    #while sum(new_pred) > y.sum():\n",
    "                new_pred = []\n",
    "                for item in new_proba:\n",
    "                    if item > numero:\n",
    "                        new_pred.append(1)\n",
    "                    else:\n",
    "                        new_pred.append(0)\n",
    "\n",
    "                i += 1\n",
    "\n",
    "    \n",
    "            recall = recall_score(y_test, new_pred)\n",
    "\n",
    "    \n",
    "        #recall = recall_score(y_test, pred)\n",
    "        print(name, score)\n",
    "        if name == 'Logistic Regression':\n",
    "            logreg_score.append(score)\n",
    "            logreg_recall.append(recall)\n",
    "            print(name, score)\n",
    "        elif name == \"Random Forest\":\n",
    "            rf_score.append(score)\n",
    "            rf_recall.append(recall)\n",
    "        elif name == \"Gradient Boost Classifier\":\n",
    "            gbc_score.append(score)\n",
    "            gbc_recall.append(recall)\n",
    "            \n",
    "\"\"\"X = accidents[['amount_vehicles_involved', 'day_month',\n",
    "        'hour_day', 'point_x', 'point_y',\n",
    "        'street_code', 'year']]\n",
    "y = accidents['victims_alert'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=2018)\"\"\"\n",
    "\n",
    "#pred = lr.predict(X_test)\n",
    "\n",
    "\n",
    "####METRICS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = []\n",
    "for item in range(2, len(all_features), 2):\n",
    "    x.append(item)\n",
    "plt.plot(x, logreg_score, c='y')\n",
    "plt.plot(x, rf_score, c='r')\n",
    "plt.plot(x, gbc_score, c='b')\n",
    "plt.axhline(baseline);\n",
    "\n",
    "###Change metrics: no accuracy but to attend all the requested cases TruePositives/all_positives is \n",
    "###called tru positive rate or recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxim_logreg = 0\n",
    "for features,y in zip(x, logreg_score):\n",
    "    if y > maxim_logreg:\n",
    "        maxim_logreg = y\n",
    "print(maxim_logreg)\n",
    "\n",
    "logreg_serie = pd.Series(data=logreg_score, index=x)\n",
    "print('logreg max:', logreg_serie[logreg_serie == maxim_logreg])\n",
    "\n",
    "maxim_rf = 0\n",
    "for features,y in zip(x, rf_score):\n",
    "    if y > maxim_rf:\n",
    "        maxim_rf = y\n",
    "#print(maxim_rf)\n",
    "\n",
    "rf_serie = pd.Series(data=rf_score, index=x)\n",
    "print('rf max:', rf_serie[rf_serie == maxim_rf])\n",
    "\n",
    "maxim_gbc = 0\n",
    "for features,y in zip(x, gbc_score):\n",
    "    if y > maxim_gbc:\n",
    "        maxim_gbc = y\n",
    "#print(maxim_rf)\n",
    "\n",
    "gbc_serie = pd.Series(data=gbc_score, index=x)\n",
    "print('rf max:', gbc_serie[gbc_serie == maxim_rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == str(logreg):\n",
    "            \n",
    "            \n",
    "            lr = LogisticRegression()\n",
    "            \n",
    "            lr.fit(Xs_train, y_train)\n",
    "            pred = lr.predict(Xs_test)\n",
    "            score = accuracy_score(y_test, pred)\n",
    "            logreg_score.append(score)\n",
    "        \n",
    "        elif model == randomforest:\n",
    "            \n",
    "            rf = RandomForestClassifier()\n",
    "            rf.fit(Xs_train, y_train)\n",
    "            pred = rf.predict(Xs_test)\n",
    "            score = accuracy_score(y_test, pred)\n",
    "            rf_score.append(score)\n",
    "        else:\n",
    "            \n",
    "            gbc = GradientBoostingClassifier()\n",
    "            gbc.fit(Xs_train, y_train)\n",
    "            pred = gbc.predict(Xs_test)\n",
    "            score = accuracy_score(y_test, pred)\n",
    "            gbc_score.append(score)\n",
    "            \n",
    "plt.plot(range(range(2,len(all_features), 2)), logreg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation['victims_alert'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_feature_columns():\n",
    "    \"\"\"Construct the TensorFlow Feature Columns.\n",
    "\n",
    "    Returns:\n",
    "    A set of feature columns\n",
    "    \"\"\"\n",
    "\n",
    "    bucketized_households = tf.feature_column.bucketized_column(\n",
    "    tf.feature_column.numeric_column(\"households\"),\n",
    "    boundaries=get_quantile_based_buckets(training_examples[\"households\"], 10))\n",
    "    bucketized_longitude = tf.feature_column.bucketized_column(\n",
    "    tf.feature_column.numeric_column(\"longitude\"),\n",
    "    boundaries=get_quantile_based_buckets(training_examples[\"longitude\"], 50))\n",
    "    bucketized_latitude = tf.feature_column.bucketized_column(\n",
    "    tf.feature_column.numeric_column(\"latitude\"),\n",
    "    boundaries=get_quantile_based_buckets(training_examples[\"latitude\"], 50))\n",
    "    bucketized_housing_median_age = tf.feature_column.bucketized_column(\n",
    "    tf.feature_column.numeric_column(\"housing_median_age\"),\n",
    "    boundaries=get_quantile_based_buckets(\n",
    "      training_examples[\"housing_median_age\"], 10))\n",
    "    bucketized_total_rooms = tf.feature_column.bucketized_column(\n",
    "    tf.feature_column.numeric_column(\"total_rooms\"),\n",
    "    boundaries=get_quantile_based_buckets(training_examples[\"total_rooms\"], 10))\n",
    "    bucketized_total_bedrooms = tf.feature_column.bucketized_column(\n",
    "    tf.feature_column.numeric_column(\"total_bedrooms\"),\n",
    "    boundaries=get_quantile_based_buckets(training_examples[\"total_bedrooms\"], 10))\n",
    "    bucketized_population = tf.feature_column.bucketized_column(\n",
    "    tf.feature_column.numeric_column(\"population\"),\n",
    "    boundaries=get_quantile_based_buckets(training_examples[\"population\"], 10))\n",
    "    bucketized_median_income = tf.feature_column.bucketized_column(\n",
    "    tf.feature_column.numeric_column(\"median_income\"),\n",
    "    boundaries=get_quantile_based_buckets(training_examples[\"median_income\"], 10))\n",
    "    bucketized_rooms_per_person = tf.feature_column.bucketized_column(\n",
    "    tf.feature_column.numeric_column(\"rooms_per_person\"),\n",
    "    boundaries=get_quantile_based_buckets(\n",
    "      training_examples[\"rooms_per_person\"], 10))\n",
    "\n",
    "    long_x_lat = tf.feature_column.crossed_column(\n",
    "    set([bucketized_longitude, bucketized_latitude]), hash_bucket_size=1000)\n",
    "\n",
    "    feature_columns = set([\n",
    "    long_x_lat,\n",
    "    bucketized_longitude,\n",
    "    bucketized_latitude,\n",
    "    bucketized_housing_median_age,\n",
    "    bucketized_total_rooms,\n",
    "    bucketized_total_bedrooms,\n",
    "    bucketized_population,\n",
    "    bucketized_households,\n",
    "    bucketized_median_income,\n",
    "    bucketized_rooms_per_person])\n",
    "  \n",
    "    return feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_class(target, features, data, model):\n",
    "    \n",
    "    \n",
    "    \n",
    "    objectes = data[features].select_dtypes(include='object').columns\n",
    "    numericals = data[features].select_dtypes(exclude='object').columns\n",
    "    #dummies = pd.get_dummies(data[objectes])\n",
    "    #final = pd.concat([data[numericals], dummies], axis=1)\n",
    "    #list(features).remove(target)\n",
    "    X = data[prova_features]\n",
    "    y = data[target].reshape(-1,1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=2018)\n",
    "    if (y.sum()/len(data)) < 0.05:\n",
    "        \n",
    "        X_resampled, y_resampled = SMOTE(ratio=0.3, random_state=218).fit_sample(X_train, y_train)\n",
    "        scaler = StandardScaler()\n",
    "        Xs_train = scaler.fit_transform(X_resampled)\n",
    "        Xs_test = scaler.transform(X_test)\n",
    "    params = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': np.linspace(0.01, 0.99, 5)}\n",
    "\n",
    "    grid_search = GridSearchCV(model,\n",
    "                          params,\n",
    "                          verbose=1,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "    grid_search.fit(Xs_train, y_resampled)\n",
    "    print(grid_search.best_params_)\n",
    "    lr_hyperparams = grid_search.best_estimator_\n",
    "    pred = grid_search.predict(Xs_test)\n",
    "    score = accuracy_score(y_test, pred)\n",
    "    conf = classification_report(y_test, pred)\n",
    "    baseline = 1 - (y.sum()/len(data))\n",
    "    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(\n",
    "    validation_targets, validation_probabilities)\n",
    "    plt.plot(false_positive_rate, true_positive_rate, label=\"our model\")\n",
    "    plt.plot([0, 1], [0, 1], label=\"random classifier\")\n",
    "    _ = plt.legend(loc=2)\n",
    "    \n",
    "    return 'Baseline:', baseline, 'Score:', score, lr_hyperparams\n",
    "\n",
    "\n",
    "binary_class('victims_alert', prova_features, df2, LogisticRegression(random_state=2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = list(first_set_features)\n",
    "xx.append('visca')\n",
    "tt = 'visca'\n",
    "print(xx)\n",
    "xx.remove(tt, target)\n",
    "print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(first_set_features))\n",
    "tt = 'victims_alert'\n",
    "prova_features = [x for x in first_set_features if x != tt]\n",
    "prova_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LogReg\n",
    "target = accidents['victims_alert']\n",
    "X = final[all_features[0:12]]\n",
    "y = target.reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=2018)\n",
    "\n",
    "if (y.sum()/len(accidents)) < 0.05:\n",
    "        \n",
    "    X_resampled, y_resampled = SMOTE(ratio=0.3, random_state=2018).fit_sample(X_train, y_train)\n",
    "    scaler = StandardScaler()\n",
    "    Xs_train = scaler.fit_transform(X_resampled)\n",
    "    Xs_test = scaler.transform(X_test)\n",
    "params = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': np.linspace(0.01, 0.99, 5)}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(random_state=2018),\n",
    "                    params,\n",
    "                    verbose=2,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "grid_search.fit(Xs_train, y_resampled)\n",
    "print(grid_search.best_params_)\n",
    "lr_hyperparams = grid_search.best_estimator_\n",
    "pred_logreg = grid_search.predict(Xs_test)\n",
    "score_logreg = accuracy_score(y_test, pred)\n",
    "conf = classification_report(y_test, pred)\n",
    "baseline = 1 - (y.sum()/len(accidents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logreg.sum(), score_logreg, baseline-score_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###RAndom Forest\n",
    "\n",
    "target = accidents['victims_alert']\n",
    "objectes = accidents[initial_features].select_dtypes(include='object').columns\n",
    "numericals = accidents[initial_features].select_dtypes(exclude='object').columns\n",
    "dummies = pd.get_dummies(accidents[objectes])\n",
    "final = pd.concat([accidents[numericals], dummies], axis=1)\n",
    "X = final\n",
    "y = target.reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=2018)\n",
    "\n",
    "if (y.sum()/len(accidents)) < 0.05:\n",
    "        \n",
    "    X_resampled, y_resampled = SMOTE(ratio=0.3, random_state=2018).fit_sample(X_train, y_train)\n",
    "    scaler = StandardScaler()\n",
    "    Xs_train = scaler.fit_transform(X_resampled)\n",
    "    Xs_test = scaler.transform(X_test)\n",
    "params = {\n",
    "    'max_depth': [2,3,4, 5],\n",
    "    'n_estimators': [6, 8, 10, 12, 14]}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=2018,),\n",
    "                    params,\n",
    "                    verbose=2,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "grid_search.fit(Xs_train, y_resampled)\n",
    "print(grid_search.best_params_)\n",
    "lr_hyperparams = grid_search.best_estimator_\n",
    "pred_rf = grid_search.predict(Xs_test)\n",
    "score_rf = accuracy_score(y_test, pred)\n",
    "conf = classification_report(y_test, pred)\n",
    "baseline = 1 - (y.sum()/len(accidents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline, score_rf, pred_rf.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Confusion matrix being 1 predicted sevre\n",
    "# True Negative. There are no injured and we predict no injures\n",
    "conf_matrix['pred'] = pred_rf\n",
    "conf_matrix['true'] = y_test\n",
    "\n",
    "tn = 0 ### predicted no injures and there are no injures\n",
    "tp = 0 ### predicted injures and there are injures\n",
    "fn = 0 ### predicted no injures but there are injures\n",
    "fp = 0 ### predicted injures there are none\n",
    "\n",
    "for index, row in conf_matrix[['pred', 'true']].iterrows():\n",
    "    \n",
    "    if row['pred'] == 0 and (row['true'] == 0):\n",
    "        \n",
    "        tn += 1\n",
    "    \n",
    "    elif row['pred'] == 1 and row['true'] == 1:\n",
    "        \n",
    "        tp += 1\n",
    "        \n",
    "    elif row['pred'] == 0 and row['true'] == 1:\n",
    "        \n",
    "        fn +=1\n",
    "        \n",
    "    elif row['pred'] == 1 and row['true'] == 0:\n",
    "        \n",
    "        fp +=1\n",
    "    \n",
    "print(tn, tp, fn, fp)\n",
    "print('Has to be zero:', len(pred) - (tn+tp+fn+fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Gradient Boost Classifier\n",
    "target = accidents['victims_alert']\n",
    "objectes = accidents[initial_features].select_dtypes(include='object').columns\n",
    "numericals = accidents[initial_features].select_dtypes(exclude='object').columns\n",
    "dummies = pd.get_dummies(accidents[objectes])\n",
    "final = pd.concat([accidents[numericals], dummies], axis=1)\n",
    "X = final\n",
    "y = target.reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=2018)\n",
    "\n",
    "if (y.sum()/len(accidents)) < 0.05:\n",
    "        \n",
    "    X_resampled, y_resampled = SMOTE(ratio=0.3, random_state=2018).fit_sample(X_train, y_train)\n",
    "    scaler = StandardScaler()\n",
    "    Xs_train = scaler.fit_transform(X_resampled)\n",
    "    Xs_test = scaler.transform(X_test)\n",
    "params = {\n",
    "    'loss': ['deviance','exponential'],\n",
    "    'max_depth': [2,3,4, 5]}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(random_state=2018,),\n",
    "                    params,\n",
    "                    verbose=2,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "grid_search.fit(Xs_train, y_resampled)\n",
    "print(grid_search.best_params_)\n",
    "lr_hyperparams = grid_search.best_estimator_\n",
    "pred_gbc = grid_search.predict(Xs_test)\n",
    "score_gbc = accuracy_score(y_test, pred)\n",
    "conf = classification_report(y_test, pred)\n",
    "baseline = 1 - (y.sum()/len(accidents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llista = [1960 * 1.1]\n",
    "llista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = accidents[['amount_vehicles_involved', 'day_month',\n",
    "        'hour_day', 'point_x', 'point_y',\n",
    "        'street_code', 'year']]\n",
    "y = accidents['victims_alert'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=2018)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "pred = lr.predict(X_test)\n",
    "prob = lr.predict_proba(X_test)\n",
    "prob_1 = []\n",
    "\n",
    "####METRICS\n",
    "\n",
    "\n",
    "new_proba = []\n",
    "for l in range(0,len(prob)):\n",
    "    z = prob[l][1]\n",
    "    new_proba.append(z)\n",
    "len(new_proba), max(new_proba), min(new_proba)\n",
    "\n",
    "hedging_all = y.sum() * (2)\n",
    "new_pred = [hedging_all + 1]\n",
    "\n",
    "limits = np.linspace(0.0253,0.03, 20)\n",
    "i = 0\n",
    "\n",
    "\n",
    "while i < len(limits) and sum(new_pred) > hedging_all:\n",
    "\n",
    "    numero = limits[i]\n",
    "    \n",
    "    #for numero in np.linspace(0.0253,0.03, 20):\n",
    "    #new_pred = [1960]\n",
    "        #while sum(new_pred) > y.sum():\n",
    "    new_pred = []\n",
    "    for item in new_proba:\n",
    "        if item > numero:\n",
    "            new_pred.append(1)\n",
    "        else:\n",
    "            new_pred.append(0)\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "    print(sum(new_class),numero)\n",
    "recall_score(y_test, new_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_class = []\n",
    "\n",
    "for item in new_proba:\n",
    "    \n",
    "        #while sum(new_class) < y.sum():\n",
    "    if item > 0.027353:\n",
    "        new_class.append(1)\n",
    "    else:\n",
    "        new_class.append(0)\n",
    "            #print(num)\n",
    "    \n",
    "print(sum(new_class), y.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, new_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_class = [1960]\n",
    "\n",
    "limits = np.linspace(0.0253,0.03, 20)\n",
    "\n",
    "\"\"\"\n",
    "for(i=0; i < len(limits); i++) {\n",
    "    if (sum(new_class) > y.sum()) {\n",
    "        break;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for n in range(10):\n",
    "    print(n)\n",
    "\n",
    "... same as ...\n",
    "\n",
    "nums = list(range(10))\n",
    "i = 0\n",
    "while i < len(nums):\n",
    "    n = nums[i]\n",
    "    \n",
    "    i += 1\n",
    "\"\"\"\n",
    "\n",
    "#while iters < 100 && tolerance > 0.001:   \n",
    "\n",
    "# answer = 'n'\n",
    "# while answer != 'y':\n",
    "#    answer = raw_input('Do you want to quit?')\n",
    "\n",
    "# do {\n",
    "#     answer = raw_input('Do you want to quit?')\n",
    "# } while(answer != 'y')\n",
    "\n",
    "\n",
    "i = 0\n",
    "while i < len(limits) and sum(new_class) > y.sum():\n",
    "\n",
    "    numero = limits[i]\n",
    "    \n",
    "    #for numero in np.linspace(0.0253,0.03, 20):\n",
    "    #new_class = [1960]\n",
    "        #while sum(new_class) > y.sum():\n",
    "    new_class = []\n",
    "    for item in new_proba:\n",
    "        if item > numero:\n",
    "            new_class.append(1)\n",
    "        else:\n",
    "            new_class.append(0)\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "    print(sum(new_class),numero)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_proba.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while sum(new) > 3: \n",
    "    new=[]\n",
    "    for numero in np.linspace(0,5, 6):\n",
    "        \n",
    "        for item in llista:\n",
    "            if item > numero:\n",
    "                new.append(1)\n",
    "            else:\n",
    "                new.append(0)\n",
    "        print(numero, item, sum(new))\n",
    "    \n",
    "numero, item, sum(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " llista = [1,2,3, 4, 5, 6]\n",
    "y.sum(), sum(llista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row1 = [tn, fp]\n",
    "row2 = [fn, tp]\n",
    "neg = [tn, fn]\n",
    "pos = [fp,tp]\n",
    "neg, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = accidents['victims_alert']\n",
    "objectes = accidents[initial_features].select_dtypes(include='object').columns\n",
    "numericals = accidents[initial_features].select_dtypes(exclude='object').columns\n",
    "dummies = pd.get_dummies(accidents[objectes])\n",
    "final = pd.concat([accidents[numericals], dummies], axis=1)\n",
    "X = final\n",
    "y = target.values.reshape(-1,1)\n",
    "baseline = 1 - (y.sum()/len(accidents))\n",
    "\n",
    "####Start with models\n",
    "\n",
    "if model == logreg:\n",
    "     ####Figuring out the best train_size\n",
    "    \n",
    "    resultat = []\n",
    "    imb_ = np.linspace(0.3, 0.8, 6.0)\n",
    "    for item in imb_:\n",
    "        X_train, X_test, y_train, y_test =\\\n",
    "        train_test_split(X,y,random_state=2018, train_size=item)\n",
    "        scaler = StandardScaler()\n",
    "        Xs_train = scaler.fit_transform(X_train)\n",
    "        Xs_test = scaler.transform(X_test)\n",
    "        lr = LogisticRegressionCV()\n",
    "        lr.fit(Xs_train, y_train)\n",
    "        pred = lr.predict(Xs_test)\n",
    "        score = accuracy_score(y_test, pred)\n",
    "        resultat.append(score)\n",
    "    maxim_score = 0\n",
    "    maxim_ratio =0\n",
    "        for x,y in zip(imb_, resultat):\n",
    "            if y > maxim_score:\n",
    "                maxim_score = y\n",
    "                maxim_ratio = x\n",
    "                \n",
    "    if (y.sum()/len(accidents)) < 0.05:\n",
    "\n",
    "            resultat = []\n",
    "            imb_ = np.linspace(0.3, 0.8, 6.0)\n",
    "            for item in imb_:\n",
    "                X_train, X_test, y_train, y_test = train_test_split\\\n",
    "                (X,y,random_state=2018, train_size=maxim_ratio)\n",
    "                X_resampled, y_resampled = SMOTE(ratio=item, random_state=218).fit_sample(X_train, y_train)\n",
    "                scaler = StandardScaler()\n",
    "                Xs_train = scaler.fit_transform(X_resampled)\n",
    "                Xs_test = scaler.transform(X_test)\n",
    "                lr = LogisticRegressionCV()\n",
    "                lr.fit(Xs_train, y_resampled)\n",
    "                pred = lr.predict(Xs_test)\n",
    "                score = accuracy_score(y_test, pred)\n",
    "                resultat.append(score)\n",
    "                #print(score)\n",
    "            plt.axhline(baseline, c='r')\n",
    "            plt.plot(np.linspace(0.3,0.8,6.0), resultat)\n",
    "            maxim_score = 0\n",
    "            train_ratio =0\n",
    "            for x,y in zip(imb_, resultat):\n",
    "                if y > maxim_score:\n",
    "                    maxim_score = y\n",
    "                    train_ratio = x\n",
    "\n",
    "            #print(maxim_score,maxim_ratio)\n",
    "\n",
    "    ### LogisticRegression\n",
    "            X_resampled, y_resampled = SMOTE(ratio=maxim_ratio, random_state=218).fit_sample(X_train, y_train)\n",
    "            scaler = StandardScaler()\n",
    "            Xs_train = scaler.fit_transform(X_resampled)\n",
    "            Xs_test = scaler.transform(X_test)\n",
    "            params = {\n",
    "                'penalty': ['l1', 'l2'],\n",
    "                'C': np.linspace(0.01, 0.99, 5)}\n",
    "\n",
    "            grid_search = GridSearchCV(LogisticRegression(),\n",
    "                                  params,\n",
    "                                  verbose=1,\n",
    "                                  n_jobs=-1)\n",
    "\n",
    "            grid_search.fit(Xs_train, y_resampled)\n",
    "            #print(grid_search.best_params_)\n",
    "            lr_hyperparams = grid_search.best_estimator_\n",
    "            pred = grid_search.predict(Xs_test)\n",
    "            scores = accuracy_score(y_test, pred)\n",
    "            conf = classification_report(y_test, pred)\n",
    "            print('LogisticRegression. Smote', grid_search.best_params_, scores) \n",
    "    else:\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        Xs_train = scaler.fit_transform(X_train)\n",
    "        Xs_test = scaler.transform(X_test)\n",
    "        params = {\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'C': np.linspace(0.01, 0.99, 5)}\n",
    "\n",
    "        grid_search = GridSearchCV(LogisticRegression(),\n",
    "                              params,\n",
    "                              verbose=1,\n",
    "                              n_jobs=-1)\n",
    "\n",
    "        grid_search.fit(Xs_train, y_train)\n",
    "        print(grid_search.best_params_)\n",
    "        lr_hyperparams = grid_search.best_estimator_\n",
    "        pred = grid_search.predict(Xs_test)\n",
    "        scores = accuracy_score(y_test, pred)\n",
    "        conf = classification_report(y_test, pred)\n",
    "        print('LogisticRegression. No smote', grid_search.best_params_, scores)\n",
    "        \n",
    "#elif model == KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
