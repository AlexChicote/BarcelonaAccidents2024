{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "896d6eff-96b4-4178-8ddc-3d5665c7d75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import python_files.functions_barcelona as fb\n",
    "import datetime\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import difflib\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import date, datetime, timedelta\n",
    "#from python_files.functions_barcelona import getting_daily_weather,getting_next_day\n",
    "#rom python_files.functions_barcelona import concatenating_dataframes\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "import webbrowser\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e396693a-9657-47ad-aa7c-550784e2009e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "causes DONE\n",
      "persones DONE\n",
      "tipus DONE\n",
      "vehicles DONE\n",
      " DONE\n",
      "causa_conductor DONE\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "###ORIGINAL WORKING\n",
    "\n",
    "response = requests.get('https://opendata-ajuntament.barcelona.cat/data/api/3/action/package_search?rows=1000').json()\n",
    "\n",
    "noms=['causes-', 'persones-','tipus-', 'vehicles-','','causa_conductor_']\n",
    "##MAYBE ADDING CAUSA_CONDUCTOR\n",
    "dict_files={}\n",
    "for nom in noms:\n",
    "   \n",
    "    dict_files[nom[:-1]]=fb.concatenating_dataframes(nom,response)\n",
    "    print(nom[:-1] +' DONE')\n",
    "\n",
    "with open(\"./data/dataframes_dict_files.pkl\", \"wb\" ) as f:\n",
    "    pickle.dump( dict_files, f)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0ba141b2-bfe8-475d-b659-aeb550fad795",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What is the last year we are doing? 2024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131495, 18)\n",
      "num_incident           0\n",
      "district_code          0\n",
      "district               0\n",
      "neighborhood           0\n",
      "street_name            0\n",
      "weekday                0\n",
      "year                   0\n",
      "month                  0\n",
      "day                    0\n",
      "hour                   0\n",
      "ped_cause              0\n",
      "num_deaths             0\n",
      "num_minorly_injured    0\n",
      "num_severly_injured    0\n",
      "num_victims            0\n",
      "num_vehicles           0\n",
      "utm_y                  0\n",
      "utm_x                  0\n",
      "dtype: int64\n",
      "EL BO: (131495, 18)\n",
      "num_incident           0\n",
      "district_code          0\n",
      "district               0\n",
      "neighborhood           0\n",
      "street_name            0\n",
      "weekday                0\n",
      "year                   0\n",
      "month                  0\n",
      "day                    0\n",
      "hour                   0\n",
      "ped_cause              0\n",
      "num_deaths             0\n",
      "num_minorly_injured    0\n",
      "num_severly_injured    0\n",
      "num_victims            0\n",
      "num_vehicles           0\n",
      "utm_y                  0\n",
      "utm_x                  0\n",
      "dtype: int64\n",
      "DONE WITH ACCIDENTS\n",
      "(131495, 18) (133854, 2)\n",
      "TOTAL (131473, 19)\n",
      "DONE WITH CAUSES\n",
      "DONE WITH PEOPLE\n",
      "type:  (133854, 2) Total:  (131473, 38)\n",
      "DONE WITH TYPE\n",
      "vehicles:  (130521, 6) Total:  (131473, 43)\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "last_year=input(\"What is the last year we are doing?\")\n",
    "with open(\"./data/dataframes_dict_files.pkl\", \"rb\" ) as file:\n",
    "    dict_files=pickle.load(file)\n",
    "columnes=['num_incident', 'district_code','district', 'neighborhood','street_name',\n",
    "          'weekday', 'year', 'month', 'day', 'hour', 'ped_cause',\n",
    "           'num_deaths', 'num_minorly_injured', 'num_severly_injured',\n",
    "            'num_victims', 'num_vehicles', 'utm_y', 'utm_x']\n",
    "replacements={\"Numero_expedient\": \"num_incident\",\n",
    "              \"Numero_d_expedient\": \"num_incident\",\n",
    "              \"Numero_dexpedient\": \"num_incident\",\n",
    "              'N£mero_dexpedient': \"num_incident\",\n",
    "              'Numero_Expedient': \"num_incident\",\n",
    "              'Codi_expedient': 'num_incident',\n",
    "              'Codi_dexpedient':'num_incident',\n",
    "                \"Nom_districte\": \"district\",\n",
    "              'Codi_districte': 'district_code',\n",
    "              'Codi districte': 'district_code',\n",
    "               \"Nom_barri\":\"neighborhood\",\n",
    "              \"Nom_carrer\":\"street_name\",\n",
    "              \"Descripcio_dia_setmana\":\"weekday\",\n",
    "              \"NK_Any\":\"year\",\n",
    "              \"Any\":\"year\",\n",
    "              \"Nom_mes\":\"month\",\n",
    "              \"Dia_mes\":\"day\",\n",
    "              \"Dia_de_mes\":\"day\",\n",
    "              \"Hora_dia\":\"hour\",\n",
    "              \"Descripcio_causa_vianant\":\"ped_cause\",\n",
    "              \"Numero_morts\":\"num_deaths\",\n",
    "              \"Numero_lesionats_lleus\":\"num_minorly_injured\",\n",
    "              \"Numero_lesionats_greus\":\"num_severly_injured\",\n",
    "              \"Numero_victimes\":\"num_victims\",\n",
    "              \"Numero_vehicles_implicats\":\"num_vehicles\",\n",
    "              \"Coordenada_UTM_X_ED50\":\"utm_x\",\n",
    "              \"Coordenada_UTM_Y_ED50\":\"utm_y\",\n",
    "            \"Coordenada_UTM_X\":\"utm_x\",\n",
    "             \"Coordenada_UTM_Y\":\"utm_y\",\n",
    "             \"Coordenada UTM (Y)\": \"utm_y\",\n",
    "             \"Coordenada UTM (X)\": \"utm_x\",\n",
    "             \"Coordenada_UTM_(Y)\":\"utm_y\",\n",
    "             \"Coordenada_UTM_(X)\":\"utm_x\",\n",
    "             \"Longitud_WGS84\":\"Longitud\",\n",
    "             \"Latitud_WGS84\":\"Latitud\",\n",
    "             'Num_postal_':\"Num_postal\",\n",
    "             \"Num_postal_caption\":\"Num_postal\",\n",
    "             'Tipus_accident':'accident_type',\n",
    "              'Descripcio_tipus_accident':'accident_type',\n",
    "              'Descripcio_color':'vehicle_color',\n",
    "              'Descripcio_model':'vehicle_model',\n",
    "              'Descripcio_marca':'vehicle_brand_name',\n",
    "              'Descripcio_carnet': 'license',\n",
    "              'Antiguitat_carnet':'license_seniority'\n",
    "              \n",
    "             }\n",
    "\n",
    "llista_=['causes', 'persones', 'tipus', 'vehicles', '']\n",
    "for grup in llista_:\n",
    "    for num, df in enumerate(dict_files[grup]):\n",
    "        df.columns=[col.replace(\"ú\",'u').replace(\"ó\",\"o\").replace(\"'\",'').replace(' ','_').replace(\"_de_\",\"_\").replace(\"í\",\"i\").replace(\"¢\",'o') for col in df]\n",
    "\n",
    "        df=df.rename(columns=replacements,)\n",
    "        dict_files[grup][num]=df\n",
    "#acc=pd.DataFrame(columns=columnes)\n",
    "df_list=[]   \n",
    "for dd in dict_files['']:\n",
    "    columns=[col for col in dd.columns if col in columnes]\n",
    "    dd_final=dd[columns]\n",
    "    df_list.append(dd_final)\n",
    "    #acc=pd.concat([acc,dd_final])\n",
    "    #print(acc.shape)\n",
    "acc=pd.concat(df_list)\n",
    "\n",
    "##Fixing utm_x and utm_y that are mixed in some cases. Replacing nulls(-1) with the mean\n",
    "acc['utm_x']=[x[0] if len(str(x[0]).split('.')[0])==7 else x[1] for x in zip(acc.utm_x,acc.utm_y)]\n",
    "acc['utm_y']=[x[1] if len(str(x[1]).split('.')[0])==6 else x[0] for x in zip(acc.utm_x,acc.utm_y)]\n",
    "\n",
    "##Fixing other stuff\n",
    "acc['ped_cause']=acc['ped_cause'].apply(fb.ped_to_angles)\n",
    "acc['weekday']=acc['weekday'].apply(fb.setmana_a_angles)\n",
    "acc['month']=acc['month'].apply(fb.mes_a_angles)\n",
    "acc['num_incident']=[x.strip() for x in acc['num_incident']]\n",
    "#print(acc.shape)\n",
    "acc=acc.drop_duplicates(subset='num_incident',keep='last')\n",
    "\n",
    "print(acc.shape)\n",
    "\n",
    "\n",
    "dups=acc[acc['num_incident'].duplicated(keep=False)]\n",
    "dups[dups[['num_incident','ped_cause']].duplicated()]\n",
    "##all duplicates are due to have 2 different ped cause being the rest exactly the same. Total dups: 27. I will just keep the first. No big deal; does not pay wasting time\n",
    "acc.fillna(0,inplace=True)\n",
    "print(acc.isnull().sum())\n",
    "\n",
    "acc=acc.dropna()\n",
    "print('EL BO:',acc.shape)\n",
    "acc['district_code']=[str(int(x)) if x <0 or x>9 else '0'+str(int(x)) for x in acc.district_code]\n",
    "acc.to_csv(f'./data/accidents_only{last_year}.csv',index=False)\n",
    "print(acc.isnull().sum())\n",
    "\n",
    "print(\"DONE WITH ACCIDENTS\")\n",
    "\n",
    "\n",
    "#CAUSES\n",
    "\n",
    "for num, df in enumerate(dict_files['causes']):\n",
    "    columns_to_save=[]\n",
    "    for col in df:\n",
    "        if ('incident' in col.lower()) or ('mediata' in col.lower()):\n",
    "            columns_to_save.append(col)\n",
    "    \n",
    "    dict_files['causes'][num]=df[columns_to_save]\n",
    "    dict_files['causes'][num].columns=['num_incident' if 'incident' in col else 'cause' for col in columns_to_save]\n",
    "    \n",
    "causes=pd.concat(dict_files['causes']).reset_index(drop=True)\n",
    "causes['num_incident']=[x.strip() for x in causes['num_incident']]\n",
    "causes['cause']=causes.cause.apply(fb.posant_accents).apply(fb.cause_to_angles)\n",
    "causes=causes.drop_duplicates('num_incident',keep='last')\n",
    "causes.to_csv(f'./data/causes{last_year}.csv')\n",
    "print(acc.shape,causes.shape)\n",
    "total= pd.merge(acc,causes, how='inner',on='num_incident')\n",
    "print('TOTAL',total.shape)\n",
    "print(\"DONE WITH CAUSES\")\n",
    "\n",
    "#descripcio situacio: no interessa, no te valor predictiu\n",
    "# No interest either on 'Descripcio_victimitzacio','Descripcio_Motiu_desplaçament_vianant','Descripcio_Motiu_desplaçament_conductor'\n",
    "chosen_features=['num_incident','Descripcio_sexe','Edat','Descripcio_tipus_persona','Descripcio_tipus_persona','Desc_Tipus_vehicle_implicat']\n",
    "\n",
    "mapping_columns={'num_incident':'num_incident',\n",
    "             'Descripcio_sexe':'gender',\n",
    "             'Edat':'age',\n",
    "            'Descripcio_tipus_persona':'people_role',\n",
    "                'Desc_Tipus_vehicle_implicat': 'vehicle',\n",
    "                'Desc._Tipus_vehicle_implicat': 'vehicle',}\n",
    "persones=[]\n",
    "\n",
    "for d in dict_files['persones']:\n",
    "    #print(d.columns)\n",
    "    d.columns=[fb.posant_accents(col) for col in d.columns]\n",
    "    d.columns=[col if not col.startswith('Desc._') else 'Desc_Tipus_vehicle_implicat' for col in d.columns]\n",
    "    n_columns=[col for col in d.columns if col in chosen_features]\n",
    "    f=d[n_columns].copy()\n",
    "    f.columns=[mapping_columns[columna] for columna in f.columns]\n",
    "    persones.append(f)\n",
    "    \n",
    "persones=pd.concat(persones)\n",
    "persones=persones.reset_index()\n",
    "persones['num_incident']=[x.strip() for x in persones.num_incident]\n",
    "#replace also H and D from 2024\n",
    "persones['gender']=persones['gender'].replace(['Home',\"H\",'Dona',\"D\",\"Desconegut\"], [0,0,1,1,np.NaN])\n",
    "persones['people_role']=persones['people_role'].replace(list(persones.people_role.unique()),['passenger','driver','pedestrian',np.NaN])\n",
    "persones['age']=persones['age'].replace(['Desconegut',-1],np.NaN)\n",
    "# persones=persones.replace('Dona',1).replace('Home',0).replace(\"Conductor\",'driver').replace('Vianant', 'pedestrian').replace(\"Passatger\",'passenger').replace('Desconegut',np.NaN).replace(-1,np.NaN)\n",
    "persones['age']=persones['age'].astype(float)\n",
    "persones['vehicle']=persones.vehicle.map(fb.map_vehicles)\n",
    "for ix in persones[(persones.people_role=='driver')&(persones.age==0)].index:\n",
    "    persones.loc[ix,'age']=np.NaN\n",
    "for ix in persones[(persones.age>90)&(persones.people_role=='driver')].index:\n",
    "    persones.loc[ix,'age']=np.NaN\n",
    "persones['vehicle']=persones.vehicle.fillna('unknown')\n",
    "persones['vehicle']=['truck' if 'truck' in x else 'bus' if ' bus' in x or x=='tram' else 'car' if x=='suv' else 'van' if 'minibus' in x else x for x in persones.vehicle]\n",
    "persones['vehicle']=persones.vehicle.replace('unkown',np.NaN)\n",
    "\n",
    "##TODO: once i fix the age issue based in the vehicle\n",
    "misc_vehicles=persones.vehicle.value_counts()[persones.vehicle.value_counts()<1000].index\n",
    "persones['vehicle']=[veh if veh not in misc_vehicles else 'misc_vehicle' for veh in persones.vehicle]\n",
    "\n",
    "people=persones.set_index('num_incident').drop('index',axis=1)\n",
    "\n",
    "people=pd.get_dummies(people)\n",
    "\n",
    "index_1=people.index\n",
    "vehicle_cols=[col for col in people.columns if 'vehicle_' in col]\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "people = pd.DataFrame(scaler.fit_transform(people), columns = people.columns)\n",
    "\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "people = pd.DataFrame(imputer.fit_transform(people),columns = people.columns)\n",
    "\n",
    "people=pd.DataFrame(scaler.inverse_transform(people), columns = people.columns)\n",
    "vehicle_df=people[vehicle_cols].copy()\n",
    "#people=people.drop(vehicle_cols,axis=1)\n",
    "#people.isnull().sum()\n",
    "people['gender_100/1']=[100 if gen<=0.5 else 1 for gen in people.gender]\n",
    "people['age_driver']=people.age*people.people_role_driver\n",
    "people['gender_driver']=people['gender_100/1']*people.people_role_driver\n",
    "if 'gender' in list(people.columns):\n",
    "    people=people.drop('gender',axis=1)\n",
    "people=people.set_index(index_1)\n",
    "people['driver_u_25_count']=[1 if x < 27 else 0 for x in people.age_driver]\n",
    "people=people.reset_index().groupby('num_incident').sum()\n",
    "people['age_driver']=[x[0]/x[1] if (x[1]!=0) else np.nan for x in zip(people['age_driver'],people['people_role_driver'])]\n",
    "people['gender_driver_male_count']=[int(str(gen)[0]) if len(str(gen))==3 else 0 for gen in people.gender_driver.astype(int)]\n",
    "people['gender_driver_female_count']=[int(str(gen)[2]) if len(str(gen))==3 else gen for gen in people.gender_driver.astype(int)]\n",
    "people['age_bins']=pd.cut(people.age_driver,5, labels=range(1,6))\n",
    "people=people.drop(['age','gender_100/1','gender_driver'],axis=1)\n",
    "#people.merge()\n",
    "\n",
    "total= pd.merge(total,people, how='left',on='num_incident')\n",
    "total['age_driver']=total.age_driver.fillna(total.age_driver.mean())\n",
    "#print(total.isnull().sum())\n",
    "people.to_csv(f'./data/people{last_year}.csv', index=False)\n",
    "\n",
    "### NEXT STEP: What to do with the nulls in total after merging with people?WILL WAIT UNTIL FINAL TOTAL\n",
    "\n",
    "print(\"DONE WITH PEOPLE\")\n",
    "\n",
    "###TYPE\n",
    "\n",
    "\n",
    "tipus=pd.DataFrame(columns=['num_incident','accident_type'])\n",
    "\n",
    "for df in dict_files['tipus'].copy():\n",
    "    \n",
    "    tipus=pd.concat([tipus,df[['num_incident','accident_type']]])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "type_accident_map={'Atropellament': 'run_over',\n",
    "         'Col.lisio lateral': 'lateral_collision',\n",
    "        'Xoc contra element estatic': 'crash_into_stationary',\n",
    "      'Abast': 'rear-end_collision',\n",
    "       'Col.lisio frontal':'frontal_collision',\n",
    "      'Col.lisio fronto-lateral':'frontal-lateral_collision',\n",
    "      'Caiguda (dues rodes)':'fall--motorcycle',\n",
    "      'Abast multiple':'multiple_rear-end_collision',\n",
    "      'Caiguda interior vehicle':'fall_inside_vehicle',\n",
    "      'Altres':'Other_types',\n",
    "      'Bolcada (mes de dues rodes)':'overturning',\n",
    "      'Desconegut':'unknown',\n",
    "      'Sortida de via amb xoc o col.lisio':'run-off_with_crash_or_collision',\n",
    "      'Encalç':'rear-end_collision',\n",
    "      'Sortida de via amb bolcada':'run-off_with_overturning',\n",
    "      'Xoc amb animal a la calçada':'crash_into_animal_on_road',\n",
    "      'Resta sortides de via':'run-off_not_included_previously'}\n",
    "tipus.shape\n",
    "\n",
    "tipus['accident_type']=tipus['accident_type'].apply(fb.posant_accents).map(type_accident_map)\n",
    "\n",
    "tipus['num_incident']=[x.strip() for x in tipus.num_incident]\n",
    "tipus=tipus.dropna()\n",
    "misc_type=list(tipus.accident_type.value_counts()[tipus.accident_type.value_counts()<350].index)\n",
    "misc_type.append('Other_types')\n",
    "tipus=tipus.groupby('num_incident')['accident_type'].agg(lambda x: ','.join(x)).reset_index()\n",
    "tipus['accident_type']=[\"misc_type\" if x in misc_type else 'frontal' if 'frontal' in x else 'collision' if 'collision' in x else 'crash' if 'crash' in x else 'run-off' if 'run-off' in x else x for x in tipus.accident_type]\n",
    "\n",
    "\n",
    "type_list=tipus.accident_type.value_counts().index\n",
    "tipus['accident_type']=[fb.organizing_types(x,type_list) for x in  tipus.accident_type]\n",
    "#merging misc_type and Other_types\n",
    "tipus['accident_type']=[name if name !='Other_types' else 'misc_type' for name in tipus.accident_type]\n",
    "tipus2=tipus.copy()\n",
    "total4=total.copy()\n",
    "total= pd.merge(total,tipus, how='left',on='num_incident')\n",
    "#total.fillna('misc_type',inplace=True)\n",
    "total5=total.copy()\n",
    "tipus.to_csv(f'./data/types{last_year}.csv',index=False)\n",
    "\n",
    "print('type: ', tipus.shape, 'Total: ',total.shape)\n",
    "\n",
    "print(\"DONE WITH TYPE\")\n",
    "\n",
    "##VEHICLE***Model no surt a tots els anys. About seniority I am going to replace Desconegut with null\n",
    "##It is impossible to link people to vehicles in order to guess the value of missing license seniority. I cannot base it in age. It is not possible to link people to vehicle.\n",
    "columns_to_add=['num_incident', 'vehicle_model', 'vehicle_brand_name',\n",
    "       'vehicle_color', 'license', 'license_seniority' ]\n",
    "#vehicles=pd.DataFrame(columns=columns_to_add)\n",
    "vehicles_list=[]\n",
    "for df in dict_files['vehicles'].copy():\n",
    "    vehicles_list.append(df[columns_to_add])\n",
    "    vehicles=pd.concat([vehicles,df[columns_to_add]])\n",
    "vehicles =pd.concat(vehicles_list)\n",
    "vehicles=vehicles.dropna()\n",
    "vehicles['num_incident']=[x.strip() for x in vehicles.num_incident]\n",
    "vehicles2=vehicles.copy()\n",
    "#compiling values to calculate MEDIAN\n",
    "median_list=[]\n",
    "for v in vehicles.license_seniority:\n",
    "    if isinstance(v,float):\n",
    "        median_list.append(int(v))\n",
    "    elif v!='Desconegut':\n",
    "        #print(v)\n",
    "        median_list.append(int(v))\n",
    "    \n",
    "#Calculating MEDIAN\n",
    "if len(median_list) %2 !=2:\n",
    "    \n",
    "    MEDIAN=median_list[len(median_list)//2]\n",
    "    #print(MEDIAN)\n",
    "else:\n",
    "    MEDIAN =median_list[len(median_list)//2]+median_list[len(median_list)//2-1]/2\n",
    "    \n",
    "vehicles['license_seniority']=vehicles.license_seniority.replace('Desconegut',MEDIAN).astype(int)\n",
    "vehicles_seniority=vehicles.groupby('num_incident')[['license_seniority']].mean()\n",
    "\n",
    "\n",
    "vehicles=vehicles.drop('license_seniority',axis=1).groupby('num_incident').agg(lambda x: ','.join(x))\n",
    "\n",
    "vehicles=pd.concat([vehicles,vehicles_seniority],axis=1).reset_index()\n",
    "vehicles.to_csv(f'./data/vehicles{last_year}.csv',index=False)\n",
    "total= pd.merge(total,vehicles, how='left',on='num_incident')\n",
    "##I will input the most common one\n",
    "total=total.apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
    "\n",
    "total.to_csv(f'./data/accidents{last_year}.csv',index=False)\n",
    "#total.fillna(-1,inplace=True)\n",
    "print('vehicles: ', vehicles.shape, 'Total: ',total.shape)\n",
    "\n",
    "\n",
    "### NEXT STEP: What to do with the nulls in total after merging with people?WILL WAIT UNTIL FINAL TOTAL\n",
    "url = \"https://www.youtube.com/watch?v=Udt-9J8nzGE\"\n",
    "webbrowser.open(url,new=1)\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "bba90f8d-6ef5-42f4-a391-c72cf68f9ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['causes', 'persones', 'tipus', 'vehicles', '', 'causa_conductor'])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./data/dataframes_dict_files.pkl\", \"rb\" ) as f:\n",
    "    mydict=pickle.load(f)\n",
    "mydict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "6c92c9c5-aed4-4400-89d7-f59411a75c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Numero_expedient                0\n",
       "Codi_districte                  0\n",
       "Nom_districte                   0\n",
       "Codi_barri                      0\n",
       "Nom_barri                       0\n",
       "Codi_carrer                     0\n",
       "Nom_carrer                      0\n",
       "Num_postal                   2160\n",
       "Descripcio_dia_setmana          0\n",
       "NK_Any                          0\n",
       "Mes_any                         0\n",
       "Nom_mes                         0\n",
       "Dia_mes                         0\n",
       "Hora_dia                        0\n",
       "Descripcio_torn                 0\n",
       "Descripcio_causa_vianant     4843\n",
       "Numero_morts                 5150\n",
       "Numero_lesionats_lleus        691\n",
       "Numero_lesionats_greus       4994\n",
       "Numero_victimes               559\n",
       "Numero_vehicles_implicats       0\n",
       "Coordenada_UTM_Y_ED50           0\n",
       "Coordenada_UTM_X_ED50           0\n",
       "Longitud_WGS84                  0\n",
       "Latitud_WGS84                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict[''][0].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "45ad5128-4dd1-40ca-8ec3-b2a670dee13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numero_expedient</th>\n",
       "      <th>Codi_districte</th>\n",
       "      <th>Nom_districte</th>\n",
       "      <th>Codi_barri</th>\n",
       "      <th>Nom_barri</th>\n",
       "      <th>Codi_carrer</th>\n",
       "      <th>Nom_carrer</th>\n",
       "      <th>Num_postal</th>\n",
       "      <th>Descripcio_dia_setmana</th>\n",
       "      <th>NK_Any</th>\n",
       "      <th>...</th>\n",
       "      <th>Descripcio_causa_vianant</th>\n",
       "      <th>Numero_morts</th>\n",
       "      <th>Numero_lesionats_lleus</th>\n",
       "      <th>Numero_lesionats_greus</th>\n",
       "      <th>Numero_victimes</th>\n",
       "      <th>Numero_vehicles_implicats</th>\n",
       "      <th>Coordenada_UTM_Y_ED50</th>\n",
       "      <th>Coordenada_UTM_X_ED50</th>\n",
       "      <th>Longitud_WGS84</th>\n",
       "      <th>Latitud_WGS84</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4785</th>\n",
       "      <td>2024S004800</td>\n",
       "      <td>10</td>\n",
       "      <td>Sant Martí</td>\n",
       "      <td>66</td>\n",
       "      <td>el Parc i la Llacuna del Poblenou</td>\n",
       "      <td>286504</td>\n",
       "      <td>Roger de Flor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dimarts</td>\n",
       "      <td>2024</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>431736.825</td>\n",
       "      <td>4582736.655</td>\n",
       "      <td>2.182353</td>\n",
       "      <td>41.391419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>2024S000836</td>\n",
       "      <td>3</td>\n",
       "      <td>Sants-Montjuïc</td>\n",
       "      <td>12</td>\n",
       "      <td>la Marina del Prat Vermell</td>\n",
       "      <td>700134</td>\n",
       "      <td>Transversal 8</td>\n",
       "      <td>16</td>\n",
       "      <td>Dimarts</td>\n",
       "      <td>2024</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>426028.646</td>\n",
       "      <td>4576165.020</td>\n",
       "      <td>2.114884</td>\n",
       "      <td>41.331726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>2024S001510</td>\n",
       "      <td>10</td>\n",
       "      <td>Sant Martí</td>\n",
       "      <td>66</td>\n",
       "      <td>el Parc i la Llacuna del Poblenou</td>\n",
       "      <td>30500</td>\n",
       "      <td>Badajoz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dijous</td>\n",
       "      <td>2024</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>432609.473</td>\n",
       "      <td>4583758.694</td>\n",
       "      <td>2.192676</td>\n",
       "      <td>41.400698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>2024S004241</td>\n",
       "      <td>3</td>\n",
       "      <td>Sants-Montjuïc</td>\n",
       "      <td>13</td>\n",
       "      <td>la Marina de Port</td>\n",
       "      <td>369408</td>\n",
       "      <td>Zona Franca</td>\n",
       "      <td>123-133</td>\n",
       "      <td>Dijous</td>\n",
       "      <td>2024</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>428200.170</td>\n",
       "      <td>4579031.230</td>\n",
       "      <td>2.140493</td>\n",
       "      <td>41.357738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Numero_expedient  Codi_districte   Nom_districte  Codi_barri  \\\n",
       "4785      2024S004800              10      Sant Martí          66   \n",
       "832       2024S000836               3  Sants-Montjuïc          12   \n",
       "1505      2024S001510              10      Sant Martí          66   \n",
       "4226      2024S004241               3  Sants-Montjuïc          13   \n",
       "\n",
       "                              Nom_barri  Codi_carrer     Nom_carrer  \\\n",
       "4785  el Parc i la Llacuna del Poblenou       286504  Roger de Flor   \n",
       "832          la Marina del Prat Vermell       700134  Transversal 8   \n",
       "1505  el Parc i la Llacuna del Poblenou        30500        Badajoz   \n",
       "4226                  la Marina de Port       369408    Zona Franca   \n",
       "\n",
       "     Num_postal  Descripcio_dia_setmana  NK_Any  ...  \\\n",
       "4785         NaN                Dimarts    2024  ...   \n",
       "832           16                Dimarts    2024  ...   \n",
       "1505         NaN                 Dijous    2024  ...   \n",
       "4226     123-133                 Dijous    2024  ...   \n",
       "\n",
       "      Descripcio_causa_vianant Numero_morts  Numero_lesionats_lleus  \\\n",
       "4785                       NaN          NaN                     1.0   \n",
       "832                        NaN          NaN                     NaN   \n",
       "1505                       NaN          NaN                     1.0   \n",
       "4226                       NaN          NaN                     1.0   \n",
       "\n",
       "      Numero_lesionats_greus Numero_victimes Numero_vehicles_implicats  \\\n",
       "4785                     NaN             1.0                         2   \n",
       "832                      NaN             NaN                         1   \n",
       "1505                     NaN             1.0                         2   \n",
       "4226                     NaN             1.0                         2   \n",
       "\n",
       "      Coordenada_UTM_Y_ED50  Coordenada_UTM_X_ED50  Longitud_WGS84  \\\n",
       "4785             431736.825            4582736.655        2.182353   \n",
       "832              426028.646            4576165.020        2.114884   \n",
       "1505             432609.473            4583758.694        2.192676   \n",
       "4226             428200.170            4579031.230        2.140493   \n",
       "\n",
       "      Latitud_WGS84  \n",
       "4785      41.391419  \n",
       "832       41.331726  \n",
       "1505      41.400698  \n",
       "4226      41.357738  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict[''][0].sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1497c72f-ce9c-4d70-9e79-6a94582db35e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
